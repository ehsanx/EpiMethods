## Baron and Kenny {.unnumbered}

### Baron and Kenny (1986) approach 1

In Baron and Kenny approach 1 [@baron1986moderator], two regression models are fitted to estimate the total effect, direct effect, and indirect effect. 

$$ Y = \alpha_{0} + \beta_0 A + \gamma_0 M, $$
$$ Y = \alpha_{1} + \beta_1 A, $$
where $Y$ is the outcome, $A$ is the exposure, $M$ is the mediator, and $\alpha, \beta, \gamma$ are regression coefficients. The effects are then calculated as:

-   Total effect of A on Y: $\hat{\beta}_1$
-   Direct effect of A on Y: $\hat{\beta}_0$
-   Indirect effect of A on Y through M: $\hat{\beta}_1 - \hat{\beta}_0$, 

where $\hat{\beta}$ is estimated regression coefficient of $\beta$.

### Baron and Kenny (1986) approach 2
In the second approach, three models are fitted: 

$$ Y = \alpha_{0} + \beta_0 A + \gamma_0 M, $$
$$ Y = \alpha_{1} + \beta_1 A, $$
$$ M = \alpha_{2} + \beta_2 A, $$

The indirect effect of A on Y through M can be calculated as: $\hat{\beta}_2 \times \hat{\beta}_0$, where $\hat{\beta}$ is estimated regression coefficient of $\beta$. 


```{r setup, warning=FALSE, message=FALSE, cache=TRUE}
# Load required packages
require(simcausal)
```

Big data: **What if we had 1,000,000 (1 million) observations?**

Let us explore the mediation analysis using Baron and Kenny (1986) approaches. We first simulate a big dataset and then show the results from the mediation analysis.

### Continuous outcome, continuous mediator

-   True treatment effect = 1.3

#### Data generating process

```{r m11, cache= TRUE}
require(simcausal)
D <- DAG.empty()
D <- D + 
    node("A", distr = "rnorm", mean = 0, sd = 1) + 
    node("M", distr = "rnorm", mean = 0.5 * A, sd = 1) + 
    node("Y", distr = "rnorm", mean = 0.5 * M + 1.3 * A, sd = .1)
Dset <- set.DAG(D)
```

#### Generate DAG

```{r m12, cache= TRUE}
plotDAG(Dset, xjitter = 0.1, yjitter = .9,
        edge_attrs = list(width = 0.5, arrow.width = 0.4, arrow.size = 0.7),
        vertex_attrs = list(size = 12, label.cex = 0.8))
```

#### Generate Data

```{r m13, cache= TRUE}
Obs.Data <- sim(DAG = Dset, n = 1000000, rndseed = 123)
head(Obs.Data)
```

#### Estimate effect (beta-coef)

```{r m14, cache= TRUE}
fit <- glm(Y ~ A, family="gaussian", data=Obs.Data)
round(coef(fit),2)
fit.am <- glm(Y ~ A + M, family="gaussian", data=Obs.Data)
round(coef(fit.am),2)
fit.m <- glm(M ~ A, family="gaussian", data=Obs.Data)
round(coef(fit.m),2)
```

```{r m15, cache= TRUE}
# from 1st model
a.coef <- round(coef(fit),2)[2]
a.coef
# from 2nd (adjusted) model
am.coef <- round(coef(fit.am),2)[2]
am.coef
m.coef <- round(coef(fit.am),2)[3]
m.coef
# from 3rd (mediator) model
ma.coef <- round(coef(fit.m),2)[2]
ma.coef
```

#### Baron and Kenny (1986) approach 1

```{r m16, cache= TRUE}
# Direct effect
am.coef
# Total effect
a.coef
# Indirect effect
a.coef - am.coef
```

#### Baron and Kenny (1986) approach 2

```{r m17, cache= TRUE}
# Indirect effect
m.coef * ma.coef
```

### Binary outcome, continuous mediator

-   True treatment effect = 1.3

#### Data generating process

```{r m18, cache= TRUE}
require(simcausal)
D <- DAG.empty()
D <- D + 
  node("A", distr = "rnorm", mean = 0, sd = 1) + 
  node("M", distr = "rnorm", mean = 0.5 * A, sd = 1) + 
  node("Y", distr = "rbern", prob = plogis(0.5 * M + 1.3 * A)) 
Dset <- set.DAG(D)
```

#### Generate DAG

```{r m19, cache= TRUE}
plotDAG(Dset, xjitter = 0.1, yjitter = .9,
        edge_attrs = list(width = 0.5, arrow.width = 0.4, arrow.size = 0.7),
        vertex_attrs = list(size = 12, label.cex = 0.8))

```

#### Generate Data

```{r m20, cache= TRUE}
Obs.Data <- sim(DAG = Dset, n = 1000000, rndseed = 123)
head(Obs.Data)
```

#### Estimate effect (beta-coef)

```{r m21, cache= TRUE}
fit <- glm(Y ~ A, family=binomial(link = "logit"), data=Obs.Data)
round(coef(fit),2)
fit.am <- glm(Y ~ A + M, family=binomial(link = "logit"), data=Obs.Data)
round(coef(fit.am),2)
fit.m <- glm(M ~ A, family="gaussian", data=Obs.Data)
round(coef(fit.m),2)
```

```{r m22, cache= TRUE}
# from 1st model
a.coef <- round(coef(fit),2)[2]
a.coef
# from 2nd (adjusted) model
am.coef <- round(coef(fit.am),2)[2]
am.coef
m.coef <- round(coef(fit.am),2)[3]
m.coef
# from 3rd (mediator) model
ma.coef <- round(coef(fit.m),2)[2]
ma.coef
```

#### Baron and Kenny (1986) approach 1

```{r m23, cache= TRUE}
# Direct effect
am.coef
# Total effect
a.coef
# Indirect effect
a.coef - am.coef
```

#### Baron and Kenny (1986) approach 2

```{r m24, cache= TRUE}
# Indirect effect
m.coef * ma.coef
```

### Binary outcome, binary mediator

-   True treatment effect = 1.3

#### Data generating process

```{r m25, cache= TRUE}
require(simcausal)
D <- DAG.empty()
D <- D + 
  node("A", distr = "rnorm", mean = 0, sd = 1) + 
  node("M", distr = "rbern", prob = plogis(0.5 * A)) + 
  node("Y", distr = "rbern", prob = plogis(0.5 * M + 1.3 * A)) 
Dset <- set.DAG(D)
```

#### Generate DAG

```{r m26, cache= TRUE}
plotDAG(Dset, xjitter = 0.1, yjitter = .9,
        edge_attrs = list(width = 0.5, arrow.width = 0.4, arrow.size = 0.7),
        vertex_attrs = list(size = 12, label.cex = 0.8))

```

#### Generate Data

```{r m27, cache= TRUE}
Obs.Data <- sim(DAG = Dset, n = 1000000, rndseed = 123)
head(Obs.Data)
```

#### Estimate effect (beta-coef)

```{r m28, cache= TRUE}
fit <- glm(Y ~ A, family=binomial(link = "logit"), data=Obs.Data)
round(coef(fit),2)
fit.am <- glm(Y ~ A + M, family=binomial(link = "logit"), data=Obs.Data)
round(coef(fit.am),2)
fit.m <- glm(M ~ A, family=binomial(link = "logit"), data=Obs.Data)
round(coef(fit.m),2)
```


```{r m29, cache= TRUE}
# from 1st model
a.coef <- round(coef(fit),2)[2]
a.coef
# from 2nd (adjusted) model
am.coef <- round(coef(fit.am),2)[2]
am.coef
m.coef <- round(coef(fit.am),2)[3]
m.coef
# from 3rd (mediator) model
ma.coef <- round(coef(fit.m),2)[2]
ma.coef
```

#### Baron and Kenny (1986) approach 1

```{r m30, cache= TRUE}
# Direct effect
am.coef
# Total effect
a.coef
# Indirect effect
a.coef - am.coef
```

#### Baron and Kenny (1986) approach 2

```{r m31, cache= TRUE}
# Indirect effect
m.coef * ma.coef
```

As we can see, the estimated indirect effects are different from the two approaches. That means Baron and Kenny's (1986) approach doesn't work for a non-collapsible effect measure such as the odds ratio.  


### Video content (optional)

::: callout-tip
For those who prefer a video walkthrough, feel free to watch the video below, which offers a description of an earlier version of the above content.
:::

::: {style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;"}
<iframe src="https://www.youtube.com/embed/gdtBdvyVZYk" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen>

</iframe>
:::