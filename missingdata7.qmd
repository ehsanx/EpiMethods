## Effect modification {.unnumbered}

In this tutorial, we delve into the concept of effect modification. 

::: callout-important
**Effect modification** and **interaction** are two distinct concepts in epidemiology. Effect modification occurs when the causal effect of an exposure (A) on an outcome (Y) varies based on the levels of a third factor (B). In this scenario, the association between the exposure and the outcome differs within the strata of a second exposure, which acts as the effect modifier. For instance, the impact of alcohol (A) on oral cancer (Y) might differ based on tobacco smoking (B). On the other hand, interaction refers to the joint causal effect of two exposures (A and B) on an outcome (Y). It examines how the combination of multiple exposures influences the outcome, such as the combined effect of alcohol (A) and tobacco smoking (B) on oral cancer (Y). In essence, while effect modification looks at how a third factor influences the relationship between an exposure and an outcome, interaction focuses on the combined effect of two exposures on the outcome. To revisit or deepen your grasp of these two concepts, consider reviewing this [external tutorial](https://ehsanx.github.io/interaction/).
::: 

### Video content (optional)

::: callout-tip
For those who prefer a video walkthrough, feel free to watch the video below, which offers a description of an earlier version of the above content.
:::

::: {style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;"}
<iframe src="https://www.youtube.com/embed/cxfwqBD1M1c" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen>

</iframe>
:::

We start by loading the necessary packages that will aid in the analysis. We also define a function `tidy.pool_mi` to streamline the pooling process for multiple imputation results.
 
```{r setup, warning=FALSE, message=FALSE, cache=TRUE}
# Load required packages
library(survey)
require(interactions)
require(mitools)
require(mice)
require(miceadds)
library(modelsummary)

tidy.pool_mi <- function(x, ...) {
  msg <- capture.output(out <- summary(x, ...))
  out$term <- row.names(out)
  colnames(out) <- c("estimate", "std.error", "statistic", "p.value",
                     "conf.low", "conf.high", "miss", "term")
  return(out)
}
```

### Data

We load a dataset named `smi`. This dataset is a list of multiple imputed datasets, which is evident from the structure and the way we access its elements.

```{r data, cache=TRUE}
require(mitools)
data(smi)
length(smi)
length(smi[[1]])
head(smi[[1]][[1]])
```

### Model with interaction and ORs 

We're interested in understanding how the variable `wave` interacts with `sex` in predicting `drinkreg`. We fit two logistic regression models, one for each level of the `sex` variable, to understand this interaction. `wave` is exposure here.

For effect modifier sex = 0

```{r em0, cache=TRUE}
models <- with(smi, glm(drinkreg~ wave + sex + wave*sex, family = binomial()))
summary(pool(models, rule = "rubin1987"), conf.int = TRUE, exponentiate = TRUE)[2,]
```

For effect modifier sex = 1 (just changing reference)

```{r em1, cache=TRUE}
models2<-with(smi, glm(drinkreg~ wave + I(sex==0) + wave*I(sex==0),family=binomial()))
summary(pool(models2, rule = "rubin1987"),conf.int = TRUE, exponentiate = TRUE)[2,]
```

-   Notice the ORs for `wave` in the above 2 analyses. These are basically our target.
-   For proper survey data analysis, you will have to work with design and make sure you subset your subpopulation (those eligible) appropriately.

### Simple slopes analyses

We perform a simple slopes analysis for each imputed dataset. This analysis helps in understanding the relationship between the predictor and the outcome at specific levels of the moderator.

```{r em2, cache=TRUE}
a1 <- sim_slopes(models[[1]], pred = wave, modx = sex)
a2 <- sim_slopes(models[[2]], pred = wave, modx = sex)
a3 <- sim_slopes(models[[3]], pred = wave, modx = sex)
a4 <- sim_slopes(models[[4]], pred = wave, modx = sex)
a5 <- sim_slopes(models[[5]], pred = wave, modx = sex)
```

After obtaining the results from each imputed dataset, we pool them to get a consolidated result. This is done separately for each level of the `sex` variable.

### Pooled results for sex = 0

```{r em3, cache=TRUE}
# For sex = 0
ef.lev <- 1
est <- c(a1$slopes$Est.[ef.lev],
         a2$slopes$Est.[ef.lev],
         a3$slopes$Est.[ef.lev],
         a4$slopes$Est.[ef.lev],
         a5$slopes$Est.[ef.lev])
se <- c(a1$slopes$S.E.[ef.lev],
        a2$slopes$S.E.[ef.lev],
        a3$slopes$S.E.[ef.lev],
        a4$slopes$S.E.[ef.lev],
        a5$slopes$S.E.[ef.lev])
vr <- se^2
OR <- exp(est)
OR.se <- OR * se
OR.v <- OR.se^2

mod_pooled <- miceadds::pool_mi(qhat=OR, u=OR.v)
tidy.pool_mi(mod_pooled)
summary(MIcombine(as.list(OR), as.list(OR.v)))
```

### Pooled results for sex = 1

```{r em4, cache=TRUE}
# For sex = 1
ef.lev <- 2
est <- c(a1$slopes$Est.[ef.lev],
         a2$slopes$Est.[ef.lev],
         a3$slopes$Est.[ef.lev],
         a4$slopes$Est.[ef.lev],
         a5$slopes$Est.[ef.lev])
se <- c(a1$slopes$S.E.[ef.lev],
        a2$slopes$S.E.[ef.lev],
        a3$slopes$S.E.[ef.lev],
        a4$slopes$S.E.[ef.lev],
        a5$slopes$S.E.[ef.lev])
vr <- se^2
OR <- exp(est)
OR.se <- OR * se
OR.v <- OR.se^2

mod_pooled <- miceadds::pool_mi(qhat=OR, u=OR.v)
tidy.pool_mi(mod_pooled)
summary(MIcombine(as.list(OR), as.list(OR.v)))
```


```{r em5, include=FALSE, echo=FALSE, cache=TRUE}
# (Optional) log-odds
### Optional: Breakdown of results
mod_pooled <- miceadds::pool_mi(qhat=est, u=se)
tidy.pool_mi(mod_pooled)
summary(pool(models2, rule = "rubin1987"),conf.int = TRUE)[2,]
summary(MIcombine(models2))[2,]
# beta coef estimates
m.number <- length(models)
estimate <- mean(est)
estimate
ubar.var <- mean(se^2)
ubar.var
b.var <- var(est)
b.var
t.var <- ubar.var + b.var + b.var/m.number
t.var
riv = (b.var + b.var/m.number)/ubar.var
riv
lambda = (b.var + b.var/m.number)/t.var
lambda
dfcom <- nrow(smi[[1]][[1]]) - 4
dfcom
df.large.sample <- (m.number - 1)/lambda^2
df.large.sample
df.obs <- (dfcom + 1)/(dfcom + 3) * dfcom * (1 - lambda)
df.c <- df.large.sample * df.obs/(df.large.sample + df.obs)
df.c
fmi = (riv + 2/(df.c +3)) / (1 + riv)
fmi
# p-values (correction needed)
# https://stats.stackexchange.com/questions/69130/how-to-get-pooled-p-values-on-tests-done-in-multiple-imputed-datasets
# Licht and Rubin for one-sided tests
pv <- c(a1$slopes$p[1],a2$slopes$p[1],a3$slopes$p[1],a4$slopes$p[1],a5$slopes$p[1])
z <- qnorm(pv)  
num <- mean(z)
den <- sqrt(1 + var(z))
pnorm( num / den)
median(pv) # Eekhout et al (2017) 
```


