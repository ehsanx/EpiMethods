[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OER: Advanced Epidemiological Methods",
    "section": "",
    "text": "The Project\nWelcome to a place crafted to bridge a unique gap in the health research world. This website offers valuable resources for those who are taking their first steps into health research and advanced statistics. Even if you’re familiar with health research, but advanced statistical methods seem daunting, you’re in the right place. Here, we offer:\nThis hub is a part of an open educational initiative, meaning it’s available to everyone. We hope to uplift the standard of health research methodology through this endeavor.\nWe’re on a mission to:"
  },
  {
    "objectID": "index.html#dive-into-our-modules",
    "href": "index.html#dive-into-our-modules",
    "title": "OER: Advanced Epidemiological Methods",
    "section": "Dive into Our Modules",
    "text": "Dive into Our Modules\nEmbark on a journey through 10 core learning modules, including one introductory module about R:\n\n\n\n\n \n  \n    Module \n    Topics \n    Descriptions \n  \n \n\n  \n    0 \n    R Data Wrangling \n    Get to know R. \n  \n  \n    1 \n    Survey Data Resources \n    Understand and source reliable national survey data. \n  \n  \n    2 \n    Crafting Data for Research \n    Customize data to your research query. \n  \n  \n    3 \n    Grasping Confounding \n    Delve into the concept and its implications. \n  \n  \n    4 \n    Adjustment Techniques \n    Adjusting for covariates in a multivariate analysis. \n  \n  \n    5 \n    Complex Survey Analysis \n    Handle intricate data sets. \n  \n  \n    6 \n    Missing Data \n    Understand and tackle gaps in your data. \n  \n  \n    7 \n    Propensity Score Analysis \n    Dive deeper into advanced analyses. \n  \n  \n    8 \n    Reporting Your Analysis \n    Guidelines to share your findings. \n  \n  \n    9 \n    Machine Learning \n    Introduction to key concepts, algorithms, and applications. \n  \n  \n    10 \n    Role of Machine Learning in Causal Inference \n    Discusses the potential pitfalls and challenges in merging machine learning with causal inference, and a way forward."
  },
  {
    "objectID": "index.html#how-our-content-is-presented",
    "href": "index.html#how-our-content-is-presented",
    "title": "OER: Advanced Epidemiological Methods",
    "section": "How Our Content is Presented",
    "text": "How Our Content is Presented\nAll our resources are hosted on an easy-to-access GitHub page. The format? Engaging text, reproducible software codes, clear analysis outputs, and crisp videos that distill complex topics. And don’t miss our quiz section at the end of each module for a quick self-check on what you’ve learned."
  },
  {
    "objectID": "index.html#open-copyright-license",
    "href": "index.html#open-copyright-license",
    "title": "OER: Advanced Epidemiological Methods",
    "section": "Open Copyright License",
    "text": "Open Copyright License\nCC-BY"
  },
  {
    "objectID": "index.html#contributor-list",
    "href": "index.html#contributor-list",
    "title": "OER: Advanced Epidemiological Methods",
    "section": "Contributor list",
    "text": "Contributor list\n\n\n\n\n\n\nTip\n\n\n\nDive into this captivating content, brought to life with the generous support of the UBC OER Fund Implementation Grant and further supported by UBC SPPH. The foundation of this content traces back to the PI’s work over five years while instructing SPPH 604 (2018-2022). That knowledge have now transformed into an open educational resource, thanks to this grant. Meet the innovative minds behind the grant proposal below.\n\n\n\n\n\n\n \n  \n    Role \n    Team_Member \n    Affiliation \n  \n \n\n  \n    Principal Applicant (PI) \n    Mohammad Ehsanul Karim \n    UBC Department of Forest Resources Management \n  \n  \n    Co-applicant (Co-I) \n    Dr. Suborna Ahmed \n    UBC Department of Forest Resources Management \n  \n  \n    Trainee co-applicants \n    Belal Hossain \n    UBC School of Population and Public Health \n  \n  \n     \n    Fardowsa Yusuf \n    UBC School of Population and Public Health \n  \n  \n     \n    Hanna Frank \n    UBC School of Population and Public Health \n  \n  \n     \n    Dr. Michael Asamoah-Boaheng \n    UBC Department of Emergency Medicine \n  \n  \n     \n    Chuyi (Astra) Zheng \n    UBC Faculty of Arts"
  },
  {
    "objectID": "wrangling.html#description",
    "href": "wrangling.html#description",
    "title": "Data wrangling",
    "section": "Description",
    "text": "Description\nTutorials in this chapter offer step-by-step instructions and code examples to help you understand and implement various data manipulation and import techniques in R.\n\nR Basics\nThis tutorial introduces the basics of R programming. It covers topics such as setting up R and RStudio, using R as a calculator, creating variables, working with vectors, plotting data, and accessing help resources.\n\n\nR Data Types\nThis tutorial covers three primary data structures in R: matrices, lists, and data frames. Matrices are two-dimensional arrays with elements of the same type, and their manipulation includes reshaping and combining. Lists in R are versatile collections that can store various R objects, including matrices. Data frames, on the other hand, are akin to matrices but permit columns of diverse data types. The tutorial offers guidance on creating, modifying, and merging data frames and checking their dimensions.\n\n\nAutomating Tasks\nMedical data analysis often grapples with vast and intricate data sets. Manual handling isn’t just tedious; it’s error-prone, especially given the critical decisions hinging on the results. This tutorial introduces automation techniques in R, a leading language for statistical analysis. By learning to use loops and functions, you can automate repetitive tasks, minimize errors, and conduct analyses more efficiently. Dive in to enhance your data handling skills.\n\n\nImporting Dataset\nThis tutorial focuses on importing data into R. It demonstrates how to import data from CSV and SAS formats using functions like read.csv and sasxport.get. It also includes examples of loading specific variables, dropping variables, subsetting observations based on certain criteria, and handling missing values.\n\n\nData Manipulation\nThis tutorial explores various data manipulation techniques in R. It covers topics such as dropping variables from a dataset, keeping specific variables, subsetting observations based on specific criteria, converting variable types (e.g., factors, strings), and handling missing values.\n\n\nImport External Data\nThis tutorial provides examples of importing external data into R. It includes specific examples of importing a CSV file (Employee Salaries - 2017 data) and a SAS file (NHANES 2015-2016 data). It also demonstrates how to save a working dataset in different formats, such as CSV and RData.\n\n\nSummary Tables\nThis tutorial emphasizes the importance of data summarization in medical research and epidemiology, specifically how to summarize medical data using R. It demonstrates creating “Table 1”, a typical descriptive statistics table in research papers, with examples that use the built-in R functions and specialized packages to efficiently summarize and stratify data."
  },
  {
    "objectID": "wrangling1a.html",
    "href": "wrangling1a.html",
    "title": "R basics",
    "section": "",
    "text": "Start using R\nTo get started with R, follow these steps:\n\nDownload and Install R: Grab the newest version from the official R website. > Tip: Download from a Comprehensive R Archive Network (CRAN) server near your geographic location.\nDownload and Install RStudio: You can get it from this link. > Note: RStudio serves as an Integrated Development Environment (IDE) offering a user-friendly interface. It facilitates operations such as executing R commands, preserving scripts, inspecting results, managing data, and more.\nBegin with RStudio: Once you open RStudio, delve into using R. For starters, employ the R syntax for script preservation, allowing future code adjustments and additions.\n\n\n\nBasic syntax\n\n\n\n\n\n\nTip\n\n\n\nR, a versatile programming language for statistics and data analysis, can execute numerous tasks. Let’s break down some of the fundamental aspects of R’s syntax.\n\n\n\nUsing R as a Calculator\n\nSimilar to how you’d use a traditional calculator for basic arithmetic operations, R can perform these functions with ease. For instance:\n\n\nShow the code\n# Simple arithmetic\n1 + 1\n#> [1] 2\n\n\nThis is a basic addition, resulting in 2.\nA more intricate calculation:\n\n\nShow the code\n# Complex calculation involving \n# multiplication, subtraction, division, powers, and square root\n20 * 5 - 10 * (3/4) * (2^3) + sqrt(25)\n#> [1] 45\n\n\nThis demonstrates R’s capability to handle complex arithmetic operations.\n\nVariable Assignment in R\n\nR allows you to store values in variables, acting like labeled containers that can be recalled and manipulated later. For example,\n\n\nShow the code\n# Assigning a value of 2 to variable x1\nx1 <- 2\nprint(x1)\n#> [1] 2\n\n\nSimilarly:\n\n\nShow the code\nx2 <- 9\nx2\n#> [1] 9\n\n\n\nCreating New Variables Using Existing Ones\n\nYou can combine and manipulate previously assigned variables to create new ones.\n\n\nShow the code\n# Using variable x1 \n# to compute its square and assign to y1\ny1 <- x1^2\ny1\n#> [1] 4\n\n\nYou can also use multiple variables in a single expression:\n\n\nShow the code\ny2 <- 310 - x1 + 2*x2 - 5*y1^3\ny2\n#> [1] 6\n\n\n\nCreating Functions\n\nFunctions act as reusable blocks of code. Once defined, they can be called multiple times with different arguments. Here’s how to define a function that squares a number:\n\n\nShow the code\nz <- function(x) {x^2}\n\n\nR also comes with a plethora of built-in functions. Examples include exp (exponential function) and rnorm (random number generation from a normal distribution).\n\nUtilizing Built-In Functions\n\nFor instance, using the exponential function:\n\n\nShow the code\n# Calling functions\nexp(x1)\n#> [1] 7.389056\nlog(exp(x1))\n#> [1] 2\n\n\nThe rnorm function can generate random samples from a normal distribution: below we are generating 10 random sampling from the normal distribution with mean 0 and standard deviation 1:\n\n\nShow the code\nrnorm(n = 10, mean = 0, sd = 1)\n#>  [1] -0.11444828 -0.15943436  1.04037141 -0.23151050  0.33470273 -1.37626255\n#>  [7]  0.06806398  1.58666116  0.95818265 -0.11180281\n\n\nAs random number generation relies on algorithms, results will differ with each execution.\n\n\nShow the code\n# Random sampling (again)\nrnorm(n = 10, mean = 0, sd = 1)\n#>  [1]  0.775674423  0.531005929  0.034212450 -0.123882356  0.008818819\n#>  [6] -1.216887738 -0.997872827 -0.386573489  1.880882716 -1.031315985\n\n\nHowever, by setting a seed, we can reproduce identical random results:\n\n\nShow the code\n# Random sampling (again, but with a seed)\nset.seed(11)\nrnorm(n = 10, mean = 0, sd = 1)\n#>  [1] -0.59103110  0.02659437 -1.51655310 -1.36265335  1.17848916 -0.93415132\n#>  [7]  1.32360565  0.62491779 -0.04572296 -1.00412058\n\n\n\n\nShow the code\n# random sampling (reproducing the same numbers)\nset.seed(11)\nrnorm(n = 10, mean = 0, sd = 1)\n#>  [1] -0.59103110  0.02659437 -1.51655310 -1.36265335  1.17848916 -0.93415132\n#>  [7]  1.32360565  0.62491779 -0.04572296 -1.00412058\n\n\nAs we can see, when we set the same seed, we get exactly the same random number. This is very important for reproducing the same results. There are many other pre-exiting functions in R.\n\nSeeking Help in R\n\n\n\n\n\n\n\nTip\n\n\n\nR’s help function, invoked with ?function_name, provides detailed documentation on functions, assisting users with unclear or forgotten arguments:\n\n\n\n\nShow the code\n# Searching for help if you know \n# the exact name of the function with a question mark\n?curve\n\n\nBelow is an example of using the pre-exiting function for plotting a curve ranging from -10 to 10.\n\n\nShow the code\n# Plotting a function\ncurve(z, from = -10, to = 10, xlab = \"x\", ylab = \"Squared x\")\n\n\n\n\n\nIf some of the arguments are difficult to remember or what else could be done with that function, we could use the help function. For example, we can simply type help(curve) or ?curve to get help on the curve function:\n\n\n\n\n\n\nTip\n\n\n\nIf you’re uncertain about a function’s precise name, two question marks can assist in the search:\n\n\n\n\nShow the code\n# Searching for help if don't know \n# the exact name of the function\n??boxplot\n\n\n\nCreating Vectors\n\nVectors are sequences of data elements of the same basic type. Here are some methods to create them:\n\n\nShow the code\n# Creating vectors in different ways\nx3 <- c(1, 2, 3, 4, 5)\nprint(x3)\n#> [1] 1 2 3 4 5\n\nx4 <- 1:7\nprint(x4)\n#> [1] 1 2 3 4 5 6 7\n\nx5 <- seq(from = 0, to = 100, by = 10)\nprint(x5)\n#>  [1]   0  10  20  30  40  50  60  70  80  90 100\n\nx6 <- seq(10, 30, length = 7)\nx6\n#> [1] 10.00000 13.33333 16.66667 20.00000 23.33333 26.66667 30.00000\n\n\n\nPlotting in R\n\nR provides numerous plotting capabilities. For instance, the plot function can create scatter plots and line graphs:\n\n\nShow the code\n# Scatter plot\nplot(x5, type = \"p\", main = \"Scatter plot\")\n\n\n\n\n\n\n\nShow the code\n# Line graph\nplot(x = x6, y = x6^2, type = \"l\", main = \"Line graph\")\n\n\n\n\n\n\nCharacter Vectors Apart from numeric values, R also allows for character vectors. For example, we can create a sex variable coded as females, males and other.\n\n\n\nShow the code\n# Character vector\nsex <- c(\"females\", \"males\", \"other\")\nsex\n#> [1] \"females\" \"males\"   \"other\"\n\n\nTo determine a variable’s type, use the mode function:\n\n\nShow the code\n# Check data type\nmode(sex)\n#> [1] \"character\"\n\n\n\n\nPackage Management\nPackages in R are collections of functions and datasets developed by the community. They enhance the capability of R by adding new functions for data analysis, visualization, data import, and more. Understanding how to install and load packages is essential for effective R programming.\n\nInstalling Packages from CRAN\n\nThe CRAN is a major source of R packages. You can install them directly from within R using the install.packages() function.\n\n\nShow the code\n# Installing the 'ggplot2' package\ninstall.packages(\"ggplot2\")\n\n\n\nLoading a Package\n\nAfter a package is installed, it must be loaded to use its functions. This is done with the library() function.\n\n\nShow the code\n# Loading the 'ggplot2' package\nlibrary(ggplot2)\n\n\nYou only need to install a package once, but you’ll need to load it every time you start a new R session and want to use its functions.\n\nUpdating Packages\n\nR packages are frequently updated. To ensure you have the latest version of a package, use the update.packages() function.\n\n\nShow the code\n# Updating all installed packages\n# could be time consuming!\nupdate.packages(ask = FALSE)  \n# 'ask = FALSE' updates all without asking for confirmation\n\n\n\nListing Installed Packages\n\nYou can view all the installed packages on your R setup using the installed.packages() function.\n\n\nShow the code\n# Listing installed packages\ninstalled.packages()[, \"Package\"]\n\n\n\nRemoving a Package\n\nIf you no longer need a package, it can be removed using the remove.packages() function.\n\n\nShow the code\n# Removing the 'ggplot2' package\nremove.packages(\"ggplot2\")\n\n\n\nInstalling Packages from Other Sources\n\nWhile CRAN is the primary source, sometimes you might need to install packages from GitHub or other repositories. The devtools package provides a function for this.\n\n\nShow the code\n# Installing devtools first\ninstall.packages(\"devtools\")\n# Loading devtools\nlibrary(devtools)\n# Install a package from GitHub\n# https://github.com/ehsanx/simMSM\ninstall_github(\"ehsanx/simMSM\")\n\n\nWhen you are working on a project, it’s a good practice to list and install required packages at the beginning of your R script."
  },
  {
    "objectID": "wrangling1b.html",
    "href": "wrangling1b.html",
    "title": "Data types",
    "section": "",
    "text": "Matrix\n\n\n\n\n\n\nTip\n\n\n\nIn R, matrices are two-dimensional rectangular data sets, which can be created using the matrix() function. It’s essential to remember that all the elements of a matrix must be of the same type, such as all numeric or all character.\n\n\nTo construct a matrix, we often start with a vector and specify how we want to reshape it. For instance:\n\n\nShow the code\n# Matrix 1\nx <- 1:10\nmatrix1 <- matrix(x, nrow = 5, ncol = 2, byrow = TRUE)\nmatrix1\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#> [3,]    5    6\n#> [4,]    7    8\n#> [5,]    9   10\n\n\nHere, the vector x contains numbers from 1 to 10. We reshape it into a matrix with 5 rows and 2 columns. The byrow = TRUE argument means the matrix will be filled row-wise, with numbers from the vector.\nConversely, if you want the matrix to be filled column-wise, you’d set byrow = FALSE:\n\n\nShow the code\n# matrix 2\nmatrix2 <- matrix(x, nrow = 5, ncol = 2, byrow = FALSE)\nmatrix2\n#>      [,1] [,2]\n#> [1,]    1    6\n#> [2,]    2    7\n#> [3,]    3    8\n#> [4,]    4    9\n#> [5,]    5   10\n\n\nYou can also combine or concatenate matrices. cbind() joins matrices by columns while rbind() joins them by rows.\n\n\nShow the code\n# Merging 2 matrices\ncbind(matrix1, matrix2)\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    1    6\n#> [2,]    3    4    2    7\n#> [3,]    5    6    3    8\n#> [4,]    7    8    4    9\n#> [5,]    9   10    5   10\n\n\n\n\nShow the code\n# Appending 2 matrices\nrbind(matrix1, matrix2)\n#>       [,1] [,2]\n#>  [1,]    1    2\n#>  [2,]    3    4\n#>  [3,]    5    6\n#>  [4,]    7    8\n#>  [5,]    9   10\n#>  [6,]    1    6\n#>  [7,]    2    7\n#>  [8,]    3    8\n#>  [9,]    4    9\n#> [10,]    5   10\n\n\n\n\nList\n\n\n\n\n\n\nTip\n\n\n\nIn R, lists can be seen as a collection where you can store a variety of different objects under a single name. This includes vectors, matrices, or even other lists. It’s very versatile because its components can be of any type of R object.\n\n\nFor instance:\n\n\nShow the code\n# List of 2 matrices\nlist1 <- list(matrix1, matrix2)\nlist1\n#> [[1]]\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#> [3,]    5    6\n#> [4,]    7    8\n#> [5,]    9   10\n#> \n#> [[2]]\n#>      [,1] [,2]\n#> [1,]    1    6\n#> [2,]    2    7\n#> [3,]    3    8\n#> [4,]    4    9\n#> [5,]    5   10\n\n\nLists can also be expanded to include multiple items:\n\n\nShow the code\nx6 <- seq(10, 30, length = 7)\nsex <- c(\"females\", \"males\", \"other\")\n# Expanding list to include more items\nlist2 <- list(list1, x6, sex, matrix1)\nlist2 \n#> [[1]]\n#> [[1]][[1]]\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#> [3,]    5    6\n#> [4,]    7    8\n#> [5,]    9   10\n#> \n#> [[1]][[2]]\n#>      [,1] [,2]\n#> [1,]    1    6\n#> [2,]    2    7\n#> [3,]    3    8\n#> [4,]    4    9\n#> [5,]    5   10\n#> \n#> \n#> [[2]]\n#> [1] 10.00000 13.33333 16.66667 20.00000 23.33333 26.66667 30.00000\n#> \n#> [[3]]\n#> [1] \"females\" \"males\"   \"other\"  \n#> \n#> [[4]]\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#> [3,]    5    6\n#> [4,]    7    8\n#> [5,]    9   10\n\n\nCombining different types of data into a single matrix converts everything to a character type:\n\n\nShow the code\n# A matrix with numeric and character variables\nid <- c(1, 2)\nscore <- c(85, 85)\nsex <- c(\"M\", \"F\")\nnew.matrix <- cbind(id, score, sex)\nnew.matrix\n#>      id  score sex\n#> [1,] \"1\" \"85\"  \"M\"\n#> [2,] \"2\" \"85\"  \"F\"\n\n\nTo check the type of data in your matrix:\n\n\nShow the code\nmode(new.matrix)\n#> [1] \"character\"\n\n\n\n\nData frame\n\n\n\n\n\n\nTip\n\n\n\nAs we can see combining both numeric and character variables into a matrix ended up with a matrix of character values. To keep the numeric variables as numeric and character variables as character, we can use the data.frame function.\n\n\n\nCreating a data frame\n\n\n\nA data frame is similar to a matrix but allows for columns of different types (numeric, character, factor, etc.). It’s a standard format for storing data sets in R.\n\n\nShow the code\ndf <- data.frame(id, score, sex)\ndf\n\n\n\n\n  \n\n\n\nTo check the mode or type of your data frame:\n\n\nShow the code\nmode(df)\n#> [1] \"list\"\n\n\n\nExtract elements\n\nData frames allow easy extraction and modification of specific elements. For example, we can extract the values on the first row and first column as follow:\n\n\nShow the code\ndf[1,1]\n#> [1] 1\n\n\nSimilarly, the first column can be extracted as follows:\n\n\nShow the code\ndf[,1]\n#> [1] 1 2\n\n\nThe first row can be extracted as follows:\n\n\nShow the code\ndf[1,]\n\n\n\n\n  \n\n\n\n\nModifying values\n\nWe can edit the values in the data frame as well. For example, we can change the score from 85 to 90 for the id 1:\n\n\nShow the code\ndf$score[df$id == 1] <- 90\ndf\n\n\n\n\n  \n\n\n\nWe can also change the name of the variables/columns:\n\n\nShow the code\ncolnames(df) <- c(\"Studyid\", \"Grade\", \"Sex\")\ndf\n\n\n\n\n  \n\n\n\n\nCombining data frames\n\nWe can also merge another data frame with the same variables using the rbind function:\n\n\nShow the code\n# Create a new dataset\ndf2 <- data.frame(Studyid = c(10, 15, 50), Grade = c(75, 90, 65), Sex = c(\"F\", \"M\", \"M\"))\n\n# Combining two data frames\ndf.new <- rbind(df, df2)\n\n# Print the first 6 rows\nhead(df.new)\n\n\n\n\n  \n\n\n\n\nChecking the dimensions\n\nTo see the dimension of the data frame (i.e., number of rows and columns), we can use the dim function:\n\n\nShow the code\ndim(df.new)\n#> [1] 5 3\n\n\nAs we can see, we have 5 rows and 3 columns. We can use the nrow and ncol functions respectively for the same output:\n\n\nShow the code\nnrow(df.new)\n#> [1] 5\nncol(df.new)\n#> [1] 3"
  },
  {
    "objectID": "wrangling1c.html",
    "href": "wrangling1c.html",
    "title": "Automating tasks",
    "section": "",
    "text": "Repeating a task\n\n\n\n\n\n\nTip\n\n\n\nThe for loop is a control flow statement in R that lets you repeat a particular task multiple times. This repetition is based on a sequence of numbers or values in a vector.\n\n\nConsider a simple real-life analogy: Imagine you are filling water in 10 bottles, one by one. Instead of doing it manually 10 times, you can set a machine to do it in a loop until all 10 bottles are filled.\n\nExample 1\n\n\n\nShow the code\n# Looping and adding\nk <- 0\nfor (i in 1:10){\n  k <- k + 5\n  print(k)\n}\n#> [1] 5\n#> [1] 10\n#> [1] 15\n#> [1] 20\n#> [1] 25\n#> [1] 30\n#> [1] 35\n#> [1] 40\n#> [1] 45\n#> [1] 50\n\n\nHere, you’re initiating a counter k at 0. With each iteration of the loop (i.e., every time it “runs”), 5 is added to k. After 10 cycles, the loop will stop, but not before printing k in each cycle.\n\nExample 2\n\nWe create a variable x5 containing the values of 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, and 100. Let us print the first 5 values using the for loop function:\n\n\nShow the code\nx5 <- seq(from = 0, to = 100, by = 10)\n# Looping through a vector\nk <- 1:5\nfor (ii in k){\n  print(x5[ii])\n}\n#> [1] 0\n#> [1] 10\n#> [1] 20\n#> [1] 30\n#> [1] 40\n\n\nThis loop cycles through the first five values of a previously created variable x5 and prints them. Each value printed corresponds to the positions 1 to 5 in x5.\n\nExample 3\n\nLet us use the for loop in a more complicated scenario. First, we create a vector of numeric values and square it:\n\n\nShow the code\n# Create a vector\nk <- c(1, 3, 6, 2, 0)\nk^2\n#> [1]  1  9 36  4  0\n\n\nThis is just squaring each value in the vector k.\n\nExample 4\n\nWe create the same vector of square values using the for loop function. To do so, (i) we create a null object, (ii) use the loop for each of the elements in the vector (k), (iii) square each of the elements, and (iv) store each of the elements of the new vector. In the example below, the length of k is 5, and the loop will run from the first to the fifth element of k. Also, k.sq[1] is the first stored value for squared-k, and k.sq[2] is the second stored value for squared-k, and so on.\n\n\nShow the code\n# Looping through a vector with function\nk.sq <- NULL\nfor (i in 1:length(k)){\n  k.sq[i] <- k[i]^2\n}\n\n# Print the values\nk.sq\n#> [1]  1  9 36  4  0\n\n\nHere, we achieve the same result as the third example but use a for loop. We prepare an empty object k.sq and then use the loop to square each value in k, storing the result in k.sq.\n\nExample 5\n\n\n\nShow the code\ndf.new <- data.frame(\n  Studyid = c(1, 2, 10, 15, 50),\n  Grade = c(90, 85, 75, 90, 65),\n  Sex = c('M', 'F', 'F', 'M', 'M')\n)\n# Looping through a data frame\nfor (i in 1:nrow(df.new)){\n  print(df.new[i,\"Sex\"])\n}\n#> [1] \"M\"\n#> [1] \"F\"\n#> [1] \"F\"\n#> [1] \"M\"\n#> [1] \"M\"\n\n\nThis loop prints the “Sex” column value for each row in the df.new data frame.\n\n\nFunctions\n\n\n\n\n\n\nTip\n\n\n\nA function in R is a piece of code that can take inputs, process them, and return an output. There are functions built into R, like mean(), which calculates the average of a set of numbers.\n\n\n\nBuilt-in function\n\n\n\nShow the code\n# Calculating a mean from a vector\nVector <- 1:100\nmean(Vector)\n#> [1] 50.5\n\n\nHere, we’re using the built-in mean() function to find the average of numbers from 1 to 100.\n\nCustom-made function\n\nTo understand how functions work, sometimes it’s helpful to build our own. Now we will create our own function to calculate the mean, where we will use the following equation to calculate it:\n\\(\\text{Mean} = \\frac{\\sum_{i=1}^{n} x_i}{n},\\)\nwhere \\(x_1\\), \\(x_2\\),…, \\(x_n\\) are the values in the vector and \\(n\\) is the sample size. Let us create the function for calculation the mean:\nThis function, mean.own, calculates the average. We add up all the numbers in a vector (Sum <- sum(x)) and divide by the number of items in that vector (n <- length(x)). The result is then returned.\n\n\nShow the code\nmean.own <- function(x){\n  Sum <- sum(x)\n  n <- length(x)\n  return(Sum/n)\n}\n\n\nBy using our custom-made function, we calculate the mean of numbers from 1 to 100, getting the same result as the built-in mean() function.\n\n\nShow the code\nmean.own(Vector)\n#> [1] 50.5"
  },
  {
    "objectID": "wrangling2.html",
    "href": "wrangling2.html",
    "title": "Importing dataset",
    "section": "",
    "text": "Introduction to Data Importing\nBefore analyzing data in R, one of the first steps you’ll typically undertake is importing your dataset. R provides numerous methods to do this, depending on the format of your dataset.\nDatasets come in a variety of file formats, with .csv (Comma-Separated Values) and .txt (Text file) being among the most common. While R’s interface offers manual ways to load these datasets, knowing how to code this step ensures better reproducibility and automation.\n\n\nImporting .txt files\nA .txt data file can be imported using the read.table function. As an example, consider you have a dataset named grade in the specified path.\nLet’s briefly glance at the file without concerning ourselves with its formatting.\n\n\nShow the code\n# Read and print the content of the TXT file\ncontent <- readLines(\"Data/wrangling/grade.txt\")\ncat(content, sep = \"\\n\")\n#> Studyid Grade Sex\n#> 1    90   M\n#> 2    85   F\n#> 10    75   F\n#> 15    90   M\n#> 50    65   M\n\n\nUsing the read.table function, you can load this dataset in R properly. It’s important to specify header = TRUE if the first row of your dataset contains variable names.\n\nTip: Always ensure the header argument matches the structure of your dataset. If your dataset contains variable names, set header = TRUE.\n\n\n\nShow the code\n## Read a text dataset\ngrade <- read.table(\"Data/wrangling/grade.txt\", header = TRUE, sep = \"\\t\", quote = \"\\\"\")\n# Display the first few rows of the dataset\nhead(grade)\n\n\n\n\n  \n\n\n\n\n\nImporting .csv files\nSimilarly, .csv files can be loaded using the read.csv function. Here’s how you can load a .csv dataset named mpg:\n\n\nShow the code\n## Read a csv dataset\nmpg <- read.csv(\"Data/wrangling/mpg.csv\", header = TRUE)\n# Display the first few rows of the dataset\nhead(mpg)\n\n\n\n\n  \n\n\n\nWhile we’ve discussed two popular data formats, R can handle a plethora of other formats. For further details, refer to Quick-R (2023). Notably, some datasets come built-in with R packages, like the mpg dataset in the ggplot2 package. To load such a dataset:\n\n\nShow the code\ndata(mpg, package = \"ggplot2\")\nhead(mpg)\n\n\n\n\n  \n\n\n\nTo understand more about the variables and the dataset’s structure, you can consult the documentation:\n\n\nShow the code\n?mpg\n\n\n\n\nData Screening and Understanding Your Dataset\ndim(), nrow(), ncol(), and str() are incredibly handy functions when initially exploring your dataset.\nOnce your data is in R, the next logical step is to get familiar with it. Knowing the dimensions of your dataset, types of variables, and the first few entries can give you a quick sense of what you’re dealing with.\nFor instance, str (short for structure) is a concise way to display information about your data. It reveals the type of each variable, the first few entries, and the total number of observations:\n\n\nShow the code\nstr(mpg)\n#> tibble [234 × 11] (S3: tbl_df/tbl/data.frame)\n#>  $ manufacturer: chr [1:234] \"audi\" \"audi\" \"audi\" \"audi\" ...\n#>  $ model       : chr [1:234] \"a4\" \"a4\" \"a4\" \"a4\" ...\n#>  $ displ       : num [1:234] 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ...\n#>  $ year        : int [1:234] 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ...\n#>  $ cyl         : int [1:234] 4 4 4 4 6 6 6 4 4 4 ...\n#>  $ trans       : chr [1:234] \"auto(l5)\" \"manual(m5)\" \"manual(m6)\" \"auto(av)\" ...\n#>  $ drv         : chr [1:234] \"f\" \"f\" \"f\" \"f\" ...\n#>  $ cty         : int [1:234] 18 21 20 21 16 18 18 18 16 20 ...\n#>  $ hwy         : int [1:234] 29 29 31 30 26 26 27 26 25 28 ...\n#>  $ fl          : chr [1:234] \"p\" \"p\" \"p\" \"p\" ...\n#>  $ class       : chr [1:234] \"compact\" \"compact\" \"compact\" \"compact\" ...\n\n\nIn summary, becoming proficient in data importing and initial screening is a fundamental step in any data analysis process in R. It ensures that subsequent stages of data manipulation and analysis are based on a clear understanding of the dataset at hand.\n\n\nReferences\n\n\n\n\n\n\nQuick-R. 2023. “Importing Data.” https://www.statmethods.net/input/importingdata.html."
  },
  {
    "objectID": "wrangling3.html",
    "href": "wrangling3.html",
    "title": "Data manipulation",
    "section": "",
    "text": "Data manipulation is a foundational skill for data analysis. This guide introduces common methods for subsetting datasets, handling variable types, creating summary tables, and dealing with missing values using R.\n\nLoad dataset\nUnderstanding the dataset’s structure is the first step in data manipulation. Here, we’re using the mpg dataset, which provides information on various car models:\n\n\nShow the code\nmpg <- read.csv(\"Data/wrangling/mpg.csv\", header = TRUE)\n\n\n\n\nSubset\nOften, you’ll need to subset your data for analysis. Here, we’ll explore different methods to both drop unwanted variables and keep desired observations.\n\nDrop variables\nSometimes, only part of the variables will be used in your analysis. Therefore, you may want to drop the variables you do not need. There are multiple ways to drop variables from a dataset. Below are two examples without using any package and using the dplyr package.\n\n\n\n\n\n\nTip\n\n\n\nOption 1: No package needed\ndataset.name[, c(the columns you want to KEEP)]\n\n\nSay, we want to keep only three variables in the mpg dataset: manufacturer, model and cyl. For Option 1 (without package), we can use the following R codes to keep these three variables:\n\n\nShow the code\nmpg1 <- mpg[, c(\"manufacturer\", \"model\", \"cyl\")]\nhead(mpg1)\n\n\n\n\n  \n\n\n\nHere mpg1 is a new dataset containing only three variables (manufacturer, model and cyl).\n\n\n\n\n\n\nTip\n\n\n\nOption 2: use select in dplyr\nselect(dataset.name, …(columns names you want to KEEP))\n\n\nFor Option 2, the dplyr package offers the select function, which provides a more intuitive way to subset data.\n\n\nShow the code\nmpg2 <- select(mpg, c(\"manufacturer\", \"model\", \"cyl\"))\nhead(mpg2)\n\n\n\n\n  \n\n\n\nWe can also exclude any variables from the dataset by using the minus (-) sign with the select function. For example, we we want to drop trans, drv, and cty from the mpg dataset, we can use the following codes:\n\n\nShow the code\nmpg3 <- select(mpg, -c(\"trans\", \"drv\", \"cty\"))\nhead(mpg3)\n\n\n\n\n  \n\n\n\nThis mpg3 is a new dataset from mpg after dropping three variables (trans, drv, and cty).\n\n\nKeep observations\nIt often happens that we only want to investigate a subset of a population which only requires a subset of our dataset. In this case, we need to subset the dataset to meet certain requirements. Again, there are multiple ways to do this task. Below is an example without a package and with the dplyr package:\n\n\n\n\n\n\nTip\n\n\n\nOption 1: No package needed\ndataset.name[the rows you want to KEEP, ]\n\n\n\n\n\n\n\n\nTip\n\n\n\nOption 2: No package needed\nsubset(dataset.name, …(logical tests))\n\n\n\n\n\n\n\n\nTip\n\n\n\nOption 3: use select in dplyr\nfilter(dataset.name, …(logical tests))\n\n\n\n\n\n\n\n\nTip\n\n\n\nCommon logical tests are:\n\n\n\n\n \n  \n    Syntax \n    Meaning \n  \n \n\n  \n    X <(=) Y \n    Smaller (equal) than \n  \n  \n    X >(=) Y \n    Larger (equal) than \n  \n  \n    X == Y \n    Equal to \n  \n  \n    X != Y \n    Not equal to \n  \n  \n    is.na(X) \n    is NA/missing? \n  \n\n\n\n\n\n\n\nSay, we want to keep the observations for which cars are manufactured in 2008. We can use the following R codes to do it:\n\n\nShow the code\nmpg4 <- mpg[mpg$year == \"2008\",] # Option 1\nhead(mpg4)\n\n\n\n\n  \n\n\n\nThe following codes with the subset and filter function will do the same:\n\n\nShow the code\nmpg5 <- subset(mpg, year == \"2008\") # Option 1\nhead(mpg5)\n\n\n\n\n  \n\n\n\n\n\nShow the code\nmpg6 <- filter(mpg, year == \"2008\") # Option 3\nhead(mpg6)\n\n\n\n\n  \n\n\n\nThe filter function can also work when you have multiple criteria (i.e., multiple logical tests) to satisfy. Here, we need Boolean operators to connect different logical tests.\n\n\n\n\n\n\nTip\n\n\n\nCommon boolean operators are:\n\n\n\n\n \n  \n    Syntax \n    Meaning \n  \n \n\n  \n    & \n    and \n  \n  \n    | \n    or \n  \n  \n    ! \n    not \n  \n  \n    == \n    equals to \n  \n  \n    != \n    not equal to \n  \n  \n    > \n    greater than \n  \n  \n    < \n    less than \n  \n  \n    >= \n    greater than or equal to \n  \n  \n    <= \n    less than or equal to \n  \n\n\n\n\n\n\n\nSay, we want to keep the observations for 6 and 8 cylinders (cyl) and engine displacement (displ) greater than or equal to 4 litres. We can use the following codes to do the task:\n\n\nShow the code\nmpg7 <- filter(mpg, cyl %in% c(\"6\",\"8\") & displ >= 4)\nhead(mpg7)\n\n\n\n\n  \n\n\n\n\n\nThe %in% operator is used to determine whether the values of the first argument are present in the second argument.\n\n\nHandling Variable Types\n\n\n\n\n\n\nTip\n\n\n\nMost common types of variable in R are\n\nnumbers,\nfactors and\nstrings(or character).\n\nUnderstanding and manipulating these types are crucial for data analysis.\n\n\n\nIdentifying Variable Type\n\nWhen we analyze the data, we usually just deal with numbers and factors. If there are variables are strings, we could convert them to factors using as.factors(variable.name)\n\n\nShow the code\nmode(mpg$trans)\n#> [1] \"character\"\n\n\n\n\nShow the code\nstr(mpg$trans)\n#>  chr [1:234] \"auto(l5)\" \"manual(m5)\" \"manual(m6)\" \"auto(av)\" \"auto(l5)\" ...\n\n\n\nConverting Characters to Factors\n\nSometimes, it’s necessary to treat text data as categorical by converting them into factors. as.numeric() converts other types of variables to numbers. For a factor variable, we usually we want to access the categories (or levels) it has. We can use a build-in function to explore: levels(variable.name)\n\n\nShow the code\n# no levels for character\nlevels(mpg$trans)\n#> NULL\n\n\n\n\nShow the code\n## Ex check how many different trans the dataset has\nmpg$trans <- as.factor(mpg$trans)\nlevels(mpg$trans)\n#>  [1] \"auto(av)\"   \"auto(l3)\"   \"auto(l4)\"   \"auto(l5)\"   \"auto(l6)\"  \n#>  [6] \"auto(s4)\"   \"auto(s5)\"   \"auto(s6)\"   \"manual(m5)\" \"manual(m6)\"\n\n\nThe levels usually will be ordered alphabetically. The first level is called “baseline”. However, the users may/may not want to keep this baseline and want to relevel/change the reference group. We can do it using the relevel function:\nrelevel(variable.name, ref=)\n\n\nShow the code\nmpg$trans <- relevel(mpg$trans, ref = \"auto(s6)\")\nlevels(mpg$trans)\n#>  [1] \"auto(s6)\"   \"auto(av)\"   \"auto(l3)\"   \"auto(l4)\"   \"auto(l5)\"  \n#>  [6] \"auto(l6)\"   \"auto(s4)\"   \"auto(s5)\"   \"manual(m5)\" \"manual(m6)\"\nnlevels(mpg$trans)\n#> [1] 10\n\n\nfactor function can be also used to combine factors. If the user want to combine multiple factors to one factors\n\n\nShow the code\n## EX re-group trans to \"auto\" and \"manual\"\nlevels(mpg$trans) <- list(auto = c(\"auto(av)\", \"auto(l3)\", \"auto(l4)\", \"auto(l5)\", \"auto(l6)\", \n                                   \"auto(s4)\", \"auto(s5)\", \"auto(s6)\"), \n                          manual = c(\"manual(m5)\", \"manual(m6)\"))\nlevels(mpg$trans)\n#> [1] \"auto\"   \"manual\"\n\n\nYou can also change the order of all factors using the following code: factor(variable.name, levels = c(“new order”))\n\n\nShow the code\n## EX. Change the order of trans to manual\nmpg$trans <- factor(mpg$trans, levels = c(\"manual\", \"auto\"))\nlevels(mpg$trans)\n#> [1] \"manual\" \"auto\"\n\n\n\n\nConvert continuous variables to categorical variables\n\n\n\n\n\n\nTip\n\n\n\nifelse, cut, recode all are helpful functions to convert numerical variables to categorical variables.\n\n\nLet’s see the summary of the cty variable first.\n\n\nShow the code\nsummary(mpg$cty)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>    9.00   14.00   17.00   16.86   19.00   35.00\n\n\nsay, we may want to change continuous ‘cty’ into groups 0-14, 15-18, and 18-40. Below is an example with the cut function.\n\n\nShow the code\n## EX. change the cty into two categories (0,14], (14,18] and (18,40]\nmpg$cty.num <- cut(mpg$cty, c(0, 14, 18, 40), right = TRUE)\ntable(mpg$cty.num)\n#> \n#>  (0,14] (14,18] (18,40] \n#>      73      85      76\n\n\n\n\nShow the code\n## Try this: do you see a difference?: [0,14), [14,18) and [18,40)\nmpg$cty.num2 <- cut(mpg$cty, c(0, 14, 18, 40), right = FALSE)\ntable(mpg$cty.num2)\n#> \n#>  [0,14) [14,18) [18,40) \n#>      54      78     102\n\n\n\n\n] stands for closed interval, i.e., right = TRUE. On the other hand, ) means open interval. Hence, there will be a huge difference when setting right = TRUE vs. right = FALSE\n\n\n\nMissing value\n\n\n\n\n\n\nTip\n\n\n\nIncomplete datasets can distort analysis. Identifying and managing these missing values is thus crucial.\n\n\nWe can check how many missing values we have by: table(is.na(variable.name))\nLet’s us check whether the cty variable contains any missing values:\n\n\nShow the code\ntable(is.na(mpg$cty))\n#> \n#> FALSE \n#>   234\n\n\nIf you want to return all non-missing values, i.e., complete case values: na.omit(variable.name). For more extensive methods on handling missing values, see subsequent tutorials."
  },
  {
    "objectID": "wrangling4.html#youtube-videos",
    "href": "wrangling4.html#youtube-videos",
    "title": "Import external data",
    "section": "YouTube Videos",
    "text": "YouTube Videos\n\n\nSome helpful videos related to the R for wrangling chapter are added here as optional materials.\nYou could watch the videos describing R basics, R for loops and functions, and manipulating real datasets using R."
  },
  {
    "objectID": "wrangling5.html",
    "href": "wrangling5.html",
    "title": "Summary tables",
    "section": "",
    "text": "Medical research and epidemiology often involve large, complex datasets. Data summarization is a vital step that transforms these vast datasets into concise, understandable insights. In medical contexts, these summaries can highlight patterns, indicate data inconsistencies, and guide further research. This tutorial will teach you how to use R to efficiently summarize medical data.\nIn epidemiology and medical research, “Table 1” typically refers to the first table in a research paper or report that provides descriptive statistics of the study population. It offers a snapshot of the baseline characteristics of the study groups, whether in a cohort study, clinical trial, or any other study design.\n\n\nShow the code\nmpg <- read.csv(\"Data/wrangling/mpg.csv\", header = TRUE)\n## Ex create a summary table between manufacturer and drv\ntable(mpg$drv, mpg$manufacturer)\n#>    \n#>     audi chevrolet dodge ford honda hyundai jeep land rover lincoln mercury\n#>   4   11         4    26   13     0       0    8          4       0       4\n#>   f    7         5    11    0     9      14    0          0       0       0\n#>   r    0        10     0   12     0       0    0          0       3       0\n#>    \n#>     nissan pontiac subaru toyota volkswagen\n#>   4      4       0     14     15          0\n#>   f      9       5      0     19         27\n#>   r      0       0      0      0          0\n\n\nThe first line reads a CSV file. It uses the table() function to generate a contingency table (cross-tabulation) between two categorical variables: drv (drive) and manufacturer. It essentially counts how many times each combination of drv and manufacturer appears in the dataset.\n\n\nShow the code\n## Get the percentage summary using prop.table\nprop.table(table(mpg$drv, mpg$manufacturer), margin = 2)\n#>    \n#>          audi chevrolet     dodge      ford     honda   hyundai      jeep\n#>   4 0.6111111 0.2105263 0.7027027 0.5200000 0.0000000 0.0000000 1.0000000\n#>   f 0.3888889 0.2631579 0.2972973 0.0000000 1.0000000 1.0000000 0.0000000\n#>   r 0.0000000 0.5263158 0.0000000 0.4800000 0.0000000 0.0000000 0.0000000\n#>    \n#>     land rover   lincoln   mercury    nissan   pontiac    subaru    toyota\n#>   4  1.0000000 0.0000000 1.0000000 0.3076923 0.0000000 1.0000000 0.4411765\n#>   f  0.0000000 0.0000000 0.0000000 0.6923077 1.0000000 0.0000000 0.5588235\n#>   r  0.0000000 1.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\n#>    \n#>     volkswagen\n#>   4  0.0000000\n#>   f  1.0000000\n#>   r  0.0000000\n## margin = 1 sum across row, 2 across col\n\n\nThis code calculates the column-wise proportion (as percentages) for each combination of drv and manufacturer. The prop.table() function is used to compute the proportions. The margin = 2 argument indicates that the proportions are to be computed across columns (margin = 1 would compute them across rows).\n\ntableone package\n\n\n\n\n\n\nTip\n\n\n\nCreateTableOne function from tableone package could be a very useful function to see the summary table. Type ?tableone::CreateTableOne to see for more details.\n\n\nThis section introduces the tableone package, which offers the CreateTableOne function. This function helps in creating “Table 1” type summary tables, commonly used in epidemiological studies.\n\n\nShow the code\nrequire(tableone)\n#> Loading required package: tableone\nCreateTableOne(vars = c(\"cyl\", \"drv\", \"hwy\", \"cty\"), data = mpg, \n               strata = \"trans\", includeNA = TRUE, test = FALSE)\n#>                  Stratified by trans\n#>                   auto(av)       auto(l3)       auto(l4)      auto(l5)     \n#>   n                   5              2             83            39        \n#>   cyl (mean (SD))  5.20 (1.10)    4.00 (0.00)    6.14 (1.62)   6.56 (1.45) \n#>   drv (%)                                                                  \n#>      4                0 (  0.0)      0 (  0.0)     34 (41.0)     29 (74.4) \n#>      f                5 (100.0)      2 (100.0)     37 (44.6)      8 (20.5) \n#>      r                0 (  0.0)      0 (  0.0)     12 (14.5)      2 ( 5.1) \n#>   hwy (mean (SD)) 27.80 (2.59)   27.00 (4.24)   21.96 (5.64)  20.72 (6.04) \n#>   cty (mean (SD)) 20.00 (2.00)   21.00 (4.24)   15.94 (3.98)  14.72 (3.49) \n#>                  Stratified by trans\n#>                   auto(l6)      auto(s4)      auto(s5)      auto(s6)     \n#>   n                   6             3             3            16        \n#>   cyl (mean (SD))  7.33 (1.03)   5.33 (2.31)   6.00 (2.00)   6.00 (1.59) \n#>   drv (%)                                                                \n#>      4                2 (33.3)      2 (66.7)      1 (33.3)      7 (43.8) \n#>      f                2 (33.3)      1 (33.3)      2 (66.7)      8 (50.0) \n#>      r                2 (33.3)      0 ( 0.0)      0 ( 0.0)      1 ( 6.2) \n#>   hwy (mean (SD)) 20.00 (2.37)  25.67 (1.15)  25.33 (6.66)  25.19 (3.99) \n#>   cty (mean (SD)) 13.67 (1.86)  18.67 (2.31)  17.33 (5.03)  17.38 (3.22) \n#>                  Stratified by trans\n#>                   manual(m5)    manual(m6)   \n#>   n                  58            19        \n#>   cyl (mean (SD))  5.00 (1.30)   6.00 (1.76) \n#>   drv (%)                                    \n#>      4               21 (36.2)      7 (36.8) \n#>      f               33 (56.9)      8 (42.1) \n#>      r                4 ( 6.9)      4 (21.1) \n#>   hwy (mean (SD)) 26.29 (5.99)  24.21 (5.75) \n#>   cty (mean (SD)) 19.26 (4.56)  16.89 (3.83)\n\n\nThe CreateTableOne function is used to create a summary table for the variables cyl, drv, hwy, and cty from the mpg dataset. The strata = trans argument means that the summary is stratified by the trans variable. The includeNA = TRUE argument means that missing values (NAs) are included in the summary. The test = FALSE argument indicates that no statistical tests should be applied to the data (often tests are used to compare groups in the table).\n\n\ntable1 package\nThis section introduces another package, table1, which can also be used to create “Table 1” type summary tables.\n\n\nShow the code\nrequire(table1)\n#> Loading required package: table1\n#> \n#> Attaching package: 'table1'\n#> The following objects are masked from 'package:base':\n#> \n#>     units, units<-\ntable1(~ cyl + drv + hwy + cty | trans, data=mpg)\n\n\n\n\n\n\n\nauto(av)(N=5)\nauto(l3)(N=2)\nauto(l4)(N=83)\nauto(l5)(N=39)\nauto(l6)(N=6)\nauto(s4)(N=3)\nauto(s5)(N=3)\nauto(s6)(N=16)\nmanual(m5)(N=58)\nmanual(m6)(N=19)\nOverall(N=234)\n\n\n\n\ncyl\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n5.20 (1.10)\n4.00 (0)\n6.14 (1.62)\n6.56 (1.45)\n7.33 (1.03)\n5.33 (2.31)\n6.00 (2.00)\n6.00 (1.59)\n5.00 (1.30)\n6.00 (1.76)\n5.89 (1.61)\n\n\nMedian [Min, Max]\n6.00 [4.00, 6.00]\n4.00 [4.00, 4.00]\n6.00 [4.00, 8.00]\n6.00 [4.00, 8.00]\n8.00 [6.00, 8.00]\n4.00 [4.00, 8.00]\n6.00 [4.00, 8.00]\n6.00 [4.00, 8.00]\n4.00 [4.00, 8.00]\n6.00 [4.00, 8.00]\n6.00 [4.00, 8.00]\n\n\ndrv\n\n\n\n\n\n\n\n\n\n\n\n\n\nf\n5 (100%)\n2 (100%)\n37 (44.6%)\n8 (20.5%)\n2 (33.3%)\n1 (33.3%)\n2 (66.7%)\n8 (50.0%)\n33 (56.9%)\n8 (42.1%)\n106 (45.3%)\n\n\n4\n0 (0%)\n0 (0%)\n34 (41.0%)\n29 (74.4%)\n2 (33.3%)\n2 (66.7%)\n1 (33.3%)\n7 (43.8%)\n21 (36.2%)\n7 (36.8%)\n103 (44.0%)\n\n\nr\n0 (0%)\n0 (0%)\n12 (14.5%)\n2 (5.1%)\n2 (33.3%)\n0 (0%)\n0 (0%)\n1 (6.3%)\n4 (6.9%)\n4 (21.1%)\n25 (10.7%)\n\n\nhwy\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n27.8 (2.59)\n27.0 (4.24)\n22.0 (5.64)\n20.7 (6.04)\n20.0 (2.37)\n25.7 (1.15)\n25.3 (6.66)\n25.2 (3.99)\n26.3 (5.99)\n24.2 (5.75)\n23.4 (5.95)\n\n\nMedian [Min, Max]\n27.0 [25.0, 31.0]\n27.0 [24.0, 30.0]\n22.0 [14.0, 41.0]\n19.0 [12.0, 36.0]\n19.0 [18.0, 23.0]\n25.0 [25.0, 27.0]\n27.0 [18.0, 31.0]\n26.0 [18.0, 29.0]\n26.0 [16.0, 44.0]\n26.0 [12.0, 32.0]\n24.0 [12.0, 44.0]\n\n\ncty\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n20.0 (2.00)\n21.0 (4.24)\n15.9 (3.98)\n14.7 (3.49)\n13.7 (1.86)\n18.7 (2.31)\n17.3 (5.03)\n17.4 (3.22)\n19.3 (4.56)\n16.9 (3.83)\n16.9 (4.26)\n\n\nMedian [Min, Max]\n19.0 [18.0, 23.0]\n21.0 [18.0, 24.0]\n16.0 [11.0, 29.0]\n14.0 [9.00, 25.0]\n13.0 [12.0, 16.0]\n20.0 [16.0, 20.0]\n18.0 [12.0, 22.0]\n17.0 [12.0, 22.0]\n19.0 [11.0, 35.0]\n16.0 [9.00, 23.0]\n17.0 [9.00, 35.0]\n\n\n\n\n\n\nThe table1() function is used to generate a summary table for the specified variables. The formula-like syntax (~ cyl + drv + hwy + cty | trans) indicates that the summary should be stratified by the trans variable."
  },
  {
    "objectID": "wranglingF.html",
    "href": "wranglingF.html",
    "title": "Functions for wrangling",
    "section": "",
    "text": "This review page provides an extensive list of R functions tailored for data wrangling tasks that we have used in this chapter. Each function is systematically described, highlighting its primary package source and its specific utility.\nTo learn more about these functions, readers can:\n\nUse R’s Built-in Help System: For each function, access its documentation by prefixing the function name with a question mark in the R console, e.g., ?as.factor. This displays the function’s manual page with descriptions, usage, and examples.\nSearch Websites: Simply Google, or visit the CRAN website to search for specific function documentation. Websites like Stack Overflow and RStudio Community often have discussions related to R functions.\nTutorials and Online Courses: Platforms like DataCamp, Coursera, and edX offer R courses that cover many functions in depth. Also there are examples of dedicated R tutorial websites that you might find useful. One example is “Introduction to R for health data analysis” by Ehsan Karim, An Hoang and Qu.\nBooks: There are numerous R programming books, such as “R for Data Science” by Hadley Wickham and “The Art of R Programming” by Norman Matloff.\nWorkshops and Webinars: Institutions and organizations occasionally offer R programming workshops or webinars.\n\nWhenever in doubt, exploring existing resources can be highly beneficial.\n\n\n\n\n \n  \n    Function_name \n    Package_name \n    Use \n  \n \n\n  \n    as.factor \n    base \n    Converts a variable to factors. `as.factor` is a wrapper for the `factor` function. \n  \n  \n    cbind \n    base \n    Merges matrices. \n  \n  \n    CreateTableOne \n    tableone \n    Creates a frequency table. \n  \n  \n    data.frame \n    base \n    Creates a dataset with both numeric and character variables. Requires unique column names and equal length for all variables. \n  \n  \n    dim \n    base \n    Returns the dimensions of a data frame (rows x columns). \n  \n  \n    filter \n    dplyr \n    Subsets a dataset by selecting a sub-population. \n  \n  \n    function \n    base \n    Used to define custom functions, e.g., for calculating standard deviation. \n  \n  \n    head \n    base \n    Displays the first six elements of an object (e.g., a dataset). `tail` displays the last six. \n  \n  \n    is.na \n    base \n    Checks for missing values in a variable. \n  \n  \n    levels \n    base \n    Displays the levels of a factor variable. \n  \n  \n    list \n    base \n    Stores vectors, matrices, or lists of differing types. \n  \n  \n    mode \n    base \n    Determines the type of a variable. \n  \n  \n    na.omit \n    base/stats \n    Removes all rows with missing values from a dataset. \n  \n  \n    names \n    base \n    Displays names of objects, e.g., variable names of a data frame. \n  \n  \n    nlevels \n    base \n    Shows the number of levels in a factor variable. \n  \n  \n    nrow \n    base \n    Returns the dimensions of a data frame. `nrow` gives row count and `ncol` gives column count. \n  \n  \n    plot \n    base/graphics \n    Draws scatter plots or line graphs. \n  \n  \n    print \n    base \n    Prints the output to console. \n  \n  \n    prop.table \n    base \n    Displays percentage summary for a table. \n  \n  \n    rbind \n    base \n    Appends matrices row-wise. \n  \n  \n    read.csv \n    base/utils \n    Reads data from a CSV file. \n  \n  \n    relevel \n    base/stats \n    Changes the reference group of a factor variable. \n  \n  \n    sasxport.get \n    Hmisc \n    Loads data in the SAS format. \n  \n  \n    save \n    base \n    Saves R objects, such as datasets. \n  \n  \n    select \n    dplyr \n    Selects specified variables from a dataset. \n  \n  \n    set.seed \n    base \n    Sets a seed for random number generation ensuring reproducibility. \n  \n  \n    str \n    base/utils \n    Displays the structure of a dataset, including data type of variables. \n  \n  \n    subset \n    base, dplyr \n    Subsets a dataset by selecting a sub-population. \n  \n  \n    summary \n    base \n    Provides a summary of an object, like variable statistics. \n  \n  \n    table \n    base \n    Displays frequency counts for a variable. \n  \n  \n    write.csv \n    base/utils \n    Saves a data frame to a CSV file in a specified directory."
  },
  {
    "objectID": "wranglingQ.html",
    "href": "wranglingQ.html",
    "title": "Quiz on wrangling",
    "section": "",
    "text": "Downloading the File:\n\nNavigate to the link: See here.\nRight-click on the link and select “Save link as…” from the dropdown menu.\nAlternatively click here for downloading the quizzes on data wrangling.\nChoose a destination folder on your computer where you’d like to save the file (e.g., Desktop). Remember this location, as you’ll need to navigate to it later.\n\nSetting Up RStudio:\n\nIf you don’t have RStudio installed, see the download link in here.\nLaunch RStudio after installing.\n\nInstalling Necessary R Packages:\n\nBefore running the R Markdown file, ensure you have the required packages. In RStudio’s console (located at the bottom left by default), enter the following commands to install them:\ninstall.packages(\"learnr\")\ninstall.packages(\"xfun\")\n\nOpening and Running the File:\n\nIn RStudio, go to File > Open File....\nNavigate to the folder where you saved the Rmd file and select it to open.\nOnce the file is open in RStudio, you’ll see a “Run Document” button (green) at the top of the script editor. Click on it to run the R Markdown Quiz file."
  },
  {
    "objectID": "accessing.html#survey-data-sources",
    "href": "accessing.html#survey-data-sources",
    "title": "Data accessing",
    "section": "Survey data sources",
    "text": "Survey data sources\nThe tutorial lists primary complex survey data sources, including the Canadian Community Health Survey and National Health and Nutrition Examination Survey, with several offering dedicated R packages for data access."
  },
  {
    "objectID": "accessing.html#importing-cchs-to-r",
    "href": "accessing.html#importing-cchs-to-r",
    "title": "Data accessing",
    "section": "Importing CCHS to R",
    "text": "Importing CCHS to R\nThe section provides detailed steps for importing the Canadian Community Health Survey dataset from the UBC library into RStudio, with processing options using SAS, the free software PSPP, and directly in R."
  },
  {
    "objectID": "accessing.html#importing-nhanes-to-r",
    "href": "accessing.html#importing-nhanes-to-r",
    "title": "Data accessing",
    "section": "Importing NHANES to R",
    "text": "Importing NHANES to R\nThe tutorial guides users on how to access and import the NHANES dataset from the CDC website into RStudio, detailing the dataset’s structure and providing methods both manually and using an R package."
  },
  {
    "objectID": "accessing.html#reproducing-results",
    "href": "accessing.html#reproducing-results",
    "title": "Data accessing",
    "section": "Reproducing results",
    "text": "Reproducing results\nThe tutorial guides users through accessing, processing, and analyzing NHANES data to reproduce the results from a referenced article using R code."
  },
  {
    "objectID": "accessing1.html",
    "href": "accessing1.html",
    "title": "Survey data sources",
    "section": "",
    "text": "The tutorial discusses complex survey data and highlights potential data sources. Key datasets with survey features include the Canadian Community Health Survey (CCHS), the National Health and Nutrition Examination Survey (NHANES), and the European Social Survey (ESS), among others. Many of these sources, like NHANES and ESS, have specific R packages for data retrieval. In addition, there are other data sources such as the Vanderbilt Biostatistics Datasets and the World Bank Open Data, with the latter also offering dedicated R packages for data access.\n\nDataset with survey features\n\nCanadian Community Health Survey - Annual Component CCHS\n\nDownload link UBC library\n\nNational Health and Nutrition Examination Survey NHANES\n\nR packages to download data: nhanesA, RNHANES\n\nNational Longitudinal Study of Adolescent to Adult Health [Add Health], 1994-2008 ICPSR 21600\nEuropean Social Survey ESS\n\nR package to download data: essurvey\n\nBehavioral Risk Factor Surveillance System BRFSS\nBureau of Economic Analysis BEA\nUS National Vital Statistics System NVSS\nDemographic and Health Surveys DHS\n\n\n\nOthers\n\nVanderbilt Biostatistics Datasets link\nWorld Bank Open Data WBOD\n\nR packages to download data: wbstats, WDI"
  },
  {
    "objectID": "accessing2.html",
    "href": "accessing2.html",
    "title": "Importing CCHS to R",
    "section": "",
    "text": "Show the code\n# Load required packages\nlibrary(knitr)\n\n\nThis section provides comprehensive instructions on how to import the Canadian Community Health Survey (CCHS) dataset from the UBC library site to the RStudio environment. The process starts with downloading the CCHS data from the UBC library site and includes step-by-step visual guides for each stage. Three primary options are provided to process and format the data:\n\nUsing the commercial software SAS.\nUtilizing the free software PSPP, an alternative to SPSS.\nDirectly processing the data in R.\n\nFor each option, users are guided on how to download, install, access, read, save, and check the dataset. The objective is to help users acquire, visualize, and manipulate the CCHS dataset seamlessly using various software applications.\n\nDownloading CCHS data from UBC\n\nStep 1: Go to dvn.library.ubc.ca, and press ‘log-in’\n\n\n\n\n\n\n\nStep 2: Select ‘UBC’ from the dropdown menu\n\n\n\n\n\n\n\nStep 3: Enter your CWL or UBC library authentication information\n\n\n\n\n\n\n\nStep 4: Once you log-in, search the term ‘cchs’ in the search-box\n\n\n\n\n\n\n\nStep 5: For illustrative purposes, let us work with the Cycle 3.1 of the CCHS dataset from the list of results. In that case, type ‘cchs 3.1’\n\n\n\n\n\n\n\nStep 6: CCHS Cycle 3.1 information\n\n\n\n\n\n\n\nStep 7: Choose the ‘Data: CD’ from the menu\n\n\n\n\n\n\n\nStep 8: Download the entire data (about 159 MB) as a zip file\n\n\n\n\n\n\n\nStep 9: Accept the ‘terms of use’\n\n\n\n\n\n\n\nStep 10: Select a directory to download the zip file. The path of the download directory is important (we need to use this path exactly later). For example, below we are in \"C:\\CCHS\\\" folder, but we will create a “Data” folder there, so that the download path is \"C:\\CCHS\\Data\\\".\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 11: Extract the zip file\n\n\n\n\n\n\n\nStep 12: Be patient with the extraction\n\n\n\n\n\n\n\nStep 13: Once extraction is complete, take a look at the folders inside. You will see that there is a folder named ‘SAS_SPSS’\n\n\n\n\n\n\n\n\nReading and Formatting the data\n\nOption 1: Processing data using SAS\nSAS is a commercial software. You may be able to get access to educational version. In case you don’t have access to it, later we outline how to use free packages to read these datasets.\n\nStep 1: Inside that ‘SAS_SPSS’ folder, find the file hs_pfe.sas. It is a long file, but we are going to work on part of it. First thing we want to do it to change all the directory names to where you have unzipped the downloaded file (for example, here the zip file was extracted to C:/CCHS/Data/cchs_cycle3-1CD/). We only need the first part of the code (as shown below; only related to data ‘hs’). Delete the rest of the codes for now. The resulting code should like like this:\n\n\n\nShow the code\n%include \"C:\\CCHS\\Data\\cchs_cycle3-1CD\\SAS_SPSS\\Layouts\\hs\\hs_pfe.sas\";\n\ndata hs;\n        %let datafid=\"C:\\CCHS\\Data\\cchs_cycle3-1CD\\Data\\hs.txt\";\n        %include \"C:\\CCHS\\Data\\cchs_cycle3-1CD\\SAS_SPSS\\Layouts\\hs\\hs_i.sas\";\n        %include \"C:\\CCHS\\Data\\cchs_cycle3-1CD\\SAS_SPSS\\Layouts\\hs\\hs_fmt.sas\";\n        %include \"C:\\CCHS\\Data\\cchs_cycle3-1CD\\SAS_SPSS\\Layouts\\hs\\hs_lbe.sas\";\nrun;\n\n\nOnce the modifications are done, submit the codes in SAS. Note that, the name of the data is ‘hs’.\n\n\n\n\n\n\nStep 2: Once you submit the code, you can check the log window in SAS to see how the code submission went. It should tell you how many observations and variables were read.\n\n\n\n\n\n\n\nStep 3: If you one to view the dataset, you can go to ‘Explorer’ window within SAS.\n\n\n\n\n\n\n\nStep 4: Generally, if you haven’t specified where to load the files, SAS will by default save the data into a library called ‘Work’\n\n\n\n\n\n\n\nStep 5: Open that folder, and you will be able to find the dataset ‘Hs’.\n\n\n\n\n\n\n\nStep 6: Right click on the data, and click ‘open’ to view the datafile.\n\n\n\n\n\n\n\nStep 7: To export the data into a CSV format data (so that we can read this data into other software packages), ckick ‘Menu’.\n\n\n\n\n\n\n\nStep 8: then press ‘Export Data’.\n\n\n\n\n\n\n\nStep 9: choose the library and the data.\n\n\n\n\n\n\n\nStep 10: choose the format in which you may want to save the existing data.\n\n\n\n\n\n\n\nStep 11: also specify where you want to save the csv file and the name of that file (e.g., cchs3.csv).\n\n\n\n\n\n\n\nStep 12: go to that directory to see the file cchs3.csv\n\n\n\n\n\n\n\nStep 13: If you want to save the file in SAS format, you can do so by writing the following sas code into the ‘Editor’ window. Here we are saving the data Hs within the Work library in to a data called cchs3 within the SASLib library. Note that, the directory name has to be where you want to save the output file.\n\n\n\nShow the code\nLIBNAME SASLib \"C:\\CCHS\\Data\";\nDATA SASLib.cchs3;\n    set Work.Hs;\nrun;\n\n\nSubmit these codes into SAS:\n\n\n\n\n\n\nStep 13: go to that directory to see the file cchs3.sas7dbat\n\n\n\n\n\n\n\n\nOption 2: Processing data using PSPP (Free)\nPSPP is a free package; alternative to commercial software SPSS. We can use the same SPSS codes to read the datafile into PSPP, and save.\n\nStep 1: Get the free PSPP software from the website: www.gnu.org/software/pspp/\n\nPSPP is available for GNU/Hurd, GNU/Linux, Darwin (Mac OS X), OpenBSD, NetBSD, FreeBSD, and Windows\n\n\n\n\n\nFor windows, download appropriate version.\n\n\n\n\n\nDownload the file\n\n\n\n\n\nInstall\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClick the icon shorcut after installing\n\n\n\n\n\n\nStep 2: Open PSPP\n\n\n\n\n\n\n\nStep 3: Go to ‘file’ menu and click ‘open’\n\n\n\n\n\n\n\nStep 4: Specify the readfile.sps file from the ‘SAS_SPSS’ folder.\n\n\n\n\n\n\nYou will see the following file:\n\n\n\n\n\n\nStep 5: Similar to before, change the directories as appropriate. Get rid of the extra lines of codes. Resulting codes are as follows (you can copy and replace the code in the file with the following codes):\n\n\n\nShow the code\nfile handle infile/name = 'C:\\CCHS\\Data\\cchs_cycle3-1CD\\DATA\\hs.txt'.\ndata list file = infile notable/.\ninclude file = \"C:\\CCHS\\Data\\cchs_cycle3-1CD\\SAS_SPSS\\Layouts\\hs\\hs_i.sps\".\ninclude file = \"C:\\CCHS\\Data\\cchs_cycle3-1CD\\SAS_SPSS\\Layouts\\hs\\hsvale.sps\".\ninclude file = \"C:\\CCHS\\Data\\cchs_cycle3-1CD\\SAS_SPSS\\Layouts\\hs\\hsvare.sps\".\ninclude file = \"C:\\CCHS\\Data\\cchs_cycle3-1CD\\SAS_SPSS\\Layouts\\hs\\hsmiss.sps\".\nexecute.\n\n\n\n\n\n\n\nFor Mac users, it should be as follows (e.g., username should be your user name, if you are saving under the path \"/Users/username/CCHS/Data/\"):\n\n\nShow the code\nfile handle infile/name =\"/Users/username/CCHS/Data/cchs_cycle3-1CD/Data/hs.txt\".\ndata list file = infile notable/.\ninclude file = \"/Users/username/CCHS/Data/cchs_cycle3-1CD/SAS_SPSS/Layouts/hs/hs_i.sps\".\ninclude file = \"/Users/username/CCHS/Data/cchs_cycle3-1CD/SAS_SPSS/Layouts/hs/hsvale.sps\".\ninclude file = \"/Users/username/CCHS/Data/cchs_cycle3-1CD/SAS_SPSS/Layouts/hs/hsvare.sps\".\ninclude file = \"/Users/username/CCHS/Data/cchs_cycle3-1CD/SAS_SPSS/Layouts/hs/hsmiss.sps\".\n\nexecute.\n\n\n\nStep 6: Run the codes.\n\n\n\n\n\n\n\nStep 7: This is a large data, and will take some time to load the data into the PSPP data editor. Be patient.\n\n\n\n\n\n\nOnce loading is complete, it will show the ‘output’ and ‘data view’.\n\n\n\n\n\n\n\n\n\n\nNote that, you will get error message, if your files were not in the correct path. In our example, the path was \"C:\\CCHS\\Data\\\" for the zip file content (see the previous steps).\n\nStep 7: You can also check the ‘variable view’.\n\n\n\n\n\n\n\nStep 8: Save the data by clicking ‘File’ and then ‘save as …’\n\n\n\n\n\n\n\nStep 9: Specify the name of the datafile and the location / folder to save the data file.\n\n\n\n\n\n\n\nStep 10: See the SAV file saved in the directory.\n\n\n\n\n\n\n\nStep 11: To save CSV format data, use the following syntax.\n\n\n\nShow the code\nSAVE TRANSLATE\n  /OUTFILE=\"C:/CCHS/Data/cchs3b.csv\"  \n  /TYPE=CSV\n  /FIELDNAMES      \n  /CELLS=VALUES.\n\n\nNote that, for categorical data, you can either save values or labels. For our purpose, we prefer values, and hence saved with values here.\n\n\n\n\n\n\nStep 12: See the CSV file saved in the directory extracted from PSPP.\n\n\n\n\n\n\n\n\nOption 3: Processing data using SPSS\nLog into ubc.onthehub.com to download SPSS. With your CWL account, UBC students should be able to download it. UBC IT website for SPSS says:\nThe SPSS software license with UBC specifies that SPSS must only be used by UBC Faculty, Students, and Research Staff and only for Teaching and non-commercial Research purposes related to UBC.\nBoth network (for UBC owened devices) or standalone / home versions (for non-UBC owened devices) should be available. Once downloaded, same process of importing CCHS data in PSPP can also be applied on SPSS (same syntax files should work). Let me know if that is not the case.\n\n\n\nProcessing data in R\n\nDownload software\n\nStep 1: Download either ‘R’ from CRAN www.r-project.org or ‘R open’ from Microsoft mran.microsoft.com/open\n\n\n\n\n\n\n\n\n\n\n\n\nStep 2: Download RStudio from www.rstudio.com/\n\n\n\n\n\n\n\nStep 3: Open RStudio\n\n\n\n\n\n\n\n\nImport, export and load data into R\n\nStep 1: Set working directory\n\n\n\nShow the code\nsetwd(\"C:/CCHS/Data/\") # or something appropriate\n\n\n\nStep 2: Read the dataset created from PSPP with cell values. We can also do a small check to see if the cell values are visible. For example, we choose a variable ‘CCCE_05A’, and tabulate it.\n\n\n\nShow the code\nHs <- read.csv(\"cchs3b.csv\", header = TRUE)\ntable(Hs$CCCE_05A)\n\n\n\n\n\n\n\n\nStep 3: Save the RData file from R into a folder SurveyData:\n\n\n\nShow the code\nsave(Hs, file = \"SurveyData/cchs3.RData\")\n\n\n\nStep 4: See the RData file saved in the directory extracted from R.\n\n\n\n\n\n\n\nStep 5: Close R / RStudio and restart it. Environment window within RStudio should be empty.\n\n\n\n\n\n\n\nStep 6: Load the saved RData into R. Environment window within RStudio should have ‘Hs’ dataset.\n\n\n\nShow the code\nload(\"SurveyData/cchs3.RData\")"
  },
  {
    "objectID": "accessing3.html",
    "href": "accessing3.html",
    "title": "Importing NHANES to R",
    "section": "",
    "text": "This tutorial provides comprehensive instructions on accessing the National Health and Nutrition Examination Survey (NHANES) dataset from the US Centers for Disease Control and Prevention (CDC) website and importing it into the RStudio environment. It covers:\n\nIntroduction to the NHANES dataset, highlighting its significance in evaluating the health and nutritional status of U.S. adults and children.\nSampling Procedure details, explaining the multi-stage sampling strategy and emphasizing the importance of using survey features like weights, strata, and primary sampling units for population-level estimates.\nSurvey History with a visualization representing different NHANES survey cycles.\nNHANES Data Files and Documents:\n\n\nExplains the data’s file format, mostly in SAS transport file format (.xpt).\nBreaks down the NHANES components, which include demographics, dietary, examination, laboratory, and questionnaire data.\nProvides guidelines on combining data from different cycles and handling missing data or outliers.\n\n\nAccessing NHANES Data:\n\n\nDirectly from the CDC website: A step-by-step guide with accompanying images, illustrating how to navigate the CDC website, download the data, and interpret the accompanying codebook.\nUsing R packages, specifically the nhanesA package: A concise guide on how to download and get summaries of the NHANES data using this R package.\n\n\n\nShow the code\n# Load required packages\n#devtools::install_github(\"warnes/SASxport\")\nlibrary(SASxport)\nlibrary(foreign)\nlibrary(nhanesA)\nlibrary(knitr)\nrequire(DiagrammeR)\nrequire(DiagrammeRsvg)\nrequire(rsvg)\nlibrary(magrittr)\nlibrary(svglite)\nlibrary(png)\nuse.saved.chche <- TRUE\n\n\n\n\nBefore installing a package from GitHub, it’s better to check whether you installed the right version of Rtools\n\nOverview\nNational Center for Health Statistics (NCHS) conducts National Health and Nutrition Examination Survey (NHANES) (CDC,NCHS 2023). These surveys are designed to evaluate the health and nutritional status of U.S. adults and children. These surveys are being administered in two-year cycles or intervals starting from 1999-2000. Prior to 1999, a number of surveys were conducted (e.g., NHANES III), but in our discussion, we will mostly restrict our discussions to continuous NHANES (e.g., NHANES 1999-2000 to NHANES 2017-2018).\n\n\nCDC,NCHS (2023)\n\n\nSampling Procedure:\nIt is a probabilistic sample (we know probability of getting selected for all individuals). This sample is unlikely to be representative of the entire population, as some under/oversampling occurs (unlike SRS), and samples may be dependent (due to proximity of some samples). For example, household with the following characteristics may be oversampled in NHANES, e.g., African Americans, Mexican Americans, Low income White Americans, Persons age 60+ years.\n\n\nSampling Procedure:\n\nnot obtained via simple random sample\nmultistage sample designs\nA sample weight is assigned to each sample person where weight = the number of people in the target population represented by that sample person in NHANES\n\nNHANES used multistage sample designs:\n\nStage 1: PSU/clusters = geographically contiguous counties. 50 states - divided into ~3100 counties. Each PSU is assigned to a strata (e.g., urban/rural or PSU size etc.). The counties are randomly/PPS selected using a 2-per-stratum design. Complex sample variance estimation requires PSU + strata (masking involved).\nStage 2: each selected county is broken into segments (with at least ~50-100 housing units). Segments are randomly/PPS selected.\nStage 3: each selected segment is divided into households. Households are randomly selected.\nStage 4: Within each sampled household, an individual is randomly selected.\n\n\n\nTo obtain population-level estimate, we must utilize the survey features (weights, strata, PSU/cluster)\n\n\nSurvey history\nOverall NHANES survey history\n\n\n\n\n\n\n\n\n\n\nNHANES datafile and documents\n\nFile format\nThe Continuous NHANES files are stored in the NHANES website as SAS transport file formats (.xpt). You can import this data in any statistical package that supports this file format.\n\n\nContinuous NHANES Components\nContinuous NHANES components separated to reduce the amount of time to download and documentation size:\n\n\nNHANES Tutorials\n\n\n\n\n\n\n\n\n\n\nBroadly, continuous NHANES data are available in 5 categories:\n\nDemographics\nDietary\nExamination\nLaboratory\nQuestionnaire\n\n\n\nCombining data\n\nDifferent cycles\nIt is possible to combine datasets from different years/cycles together in NHANES. However, NHANES is a cross-sectional data, and identification of the same person accross different cycles is not possible in the public release datasets. For appending data from different cycles, please make sure that the variable names/labels are the same/identical in years under consideration (in some years, names and labels do change).\n\n\nThe following data have not been released on the NHANES website as public release files due to confidentiality concerns:\n\nadolescent data on alcohol use\nsmoking\nsexual behavior\nreproductive health and drug use\n\n\n\nWithin the same cycle\nWithin NHANES datasets in a given cycle, each sampled person has an unique identifier sequence number (variable SEQN).\n\n\n\nMissing data and outliers\nCDC (2023) recommends:\n\n\nCDC (2023)\n\n\n“As a general rule, if 10% or less of your data for a variable are missing from your analytic dataset, it is usually acceptable to continue your analysis without further evaluation or adjustment. However, if more than 10% of the data for a variable are missing, you may need to determine whether the missing values are distributed equally across socio-demographic characteristics, and decide whether further imputation of missing values or use of adjusted weights are necessary.”\n\n\n\n\n“If you fail to identify ‘refusal’ or ‘do not know’ as types of missing data, and treat the assigned values for ‘refused’ or ‘do not know’ as real values, you will get distorted results in your statistical analyses. Therefore, it is important to recode ‘refused’ or ‘don’t know’ responses as missing values (either as a period (.) for numeric variables or as a blank for character variables).”\n\n\n\n\n“Outliers with extremely large weights could have an influential impact on your estimates. You will have to decide whether to keep these influential outliers in your analysis or not. It is up to the analysts to make that decision.”\n\n\n\n\nNHANES documents\n\n\n\n\n\n\n\n\n\n\nThe following websites could be helpful: - For more information about NHANES design.\n\nVisit US CDC website and do a variable keyword search based on your research interest (e.g., arthritis).\n\n\n\n\nAccessing NHANES Data Directly from the CDC website\nIn the following example, we will see how to download ‘Demographics’ data, and check associated variable in that dataset.\n\n\n\n\n\n\n\nNHANES 1999-2000 and onward survey datasets are publicly available at wwwn.cdc.gov/nchs/nhanes/\n\nStep 1: Say, for example, we are interested about the NHANES 2015-2016 survey. Clicking the associated link in the above Figure gets us to the page for the corresponding cycle (see below).\n\n\n\n\n\n\n\nStep 2: There are various types of data available for this survey. Let’s explore the demographic information from this cycle. These data are mostly available in the form of SAS XPT format (see below).\n\n\n\n\n\n\n\nStep 3: We can download the XPT data in the local PC folder and read the data into R as as follows:\n\n\n\nShow the code\nDEMO <- read.xport(\"Data/accessing/DEMO_I.XPT\")\n\n\n\n\n\n\nStep 4: Once data is imported in RStudio, we will see the DEMO object listed under data window (see below):\n\n\n\n\n\n\n\nStep 5: We can also check the variable names in this DEMO dataset as follows:\n\n\n\nShow the code\nnames(DEMO)\n#>  [1] \"SEQN\"     \"SDDSRVYR\" \"RIDSTATR\" \"RIAGENDR\" \"RIDAGEYR\" \"RIDAGEMN\"\n#>  [7] \"RIDRETH1\" \"RIDRETH3\" \"RIDEXMON\" \"RIDEXAGM\" \"DMQMILIZ\" \"DMQADFC\" \n#> [13] \"DMDBORN4\" \"DMDCITZN\" \"DMDYRSUS\" \"DMDEDUC3\" \"DMDEDUC2\" \"DMDMARTL\"\n#> [19] \"RIDEXPRG\" \"SIALANG\"  \"SIAPROXY\" \"SIAINTRP\" \"FIALANG\"  \"FIAPROXY\"\n#> [25] \"FIAINTRP\" \"MIALANG\"  \"MIAPROXY\" \"MIAINTRP\" \"AIALANGA\" \"DMDHHSIZ\"\n#> [31] \"DMDFMSIZ\" \"DMDHHSZA\" \"DMDHHSZB\" \"DMDHHSZE\" \"DMDHRGND\" \"DMDHRAGE\"\n#> [37] \"DMDHRBR4\" \"DMDHREDU\" \"DMDHRMAR\" \"DMDHSEDU\" \"WTINT2YR\" \"WTMEC2YR\"\n#> [43] \"SDMVPSU\"  \"SDMVSTRA\" \"INDHHIN2\" \"INDFMIN2\" \"INDFMPIR\"\n\n\n\nStep 6: We can open the data in RStudio in the dataview window (by clicking the DEMO data from the data window). The next Figure shows only a few columns and rows from this large dataset. Note that there are some values marked as “NA”, which represents missing values.\n\n\n\n\n\n\n\nStep 7: There is a column name associated with each column, e.g., DMDHSEDU in the first column in the above Figure. To understand what the column names mean in this Figure, we need to take a look at the codebook. To access codebook, click the 'DEMO|Doc' link (in step 2). This will show the data documentation and associated codebook (see the next Figure).\n\n\n\n\n\n\n\nStep 8: We can see a link for the column or variable DMDHSEDU in the table of content (in the above Figure). Clicking that link will provide us further information about what this variable means (see the next Figure).\n\n\n\n\n\n\n\nStep 9: We can assess if the numbers reported under count and cumulative (from the above Figure) matches with what we get from the DEMO data we just imported (particularly, for the DMDHSEDU variable):\n\n\n\nShow the code\ntable(DEMO$DMDHSEDU) # Frequency table\n#> \n#>    1    2    3    4    5    7    9 \n#>  619  511  980 1462 1629    2   23\ncumsum(table(DEMO$DMDHSEDU)) # Cumulative frequency table\n#>    1    2    3    4    5    7    9 \n#>  619 1130 2110 3572 5201 5203 5226\nlength(is.na(DEMO$DMDHSEDU)) # Number of non-NA observations\n#> [1] 9971\n\n\n\n\nAccessing NHANES Data Using R Packages\n\nnhanesA package\n\n\nShow the code\nlibrary(nhanesA)\n\n\n\n\n\n\n\n\nTip\n\n\n\nR package nhanesA provides a convenient way to download and analyze NHANES survey data.\n\n\n\n\nRNHANES (Susmann 2016) is another packages for downloading the NHANES data easily.\n\nStep 1: Witin the CDC website, NHANES data are available in 5 categories\n\nDemographics (DEMO)\nDietary (DIET)\nExamination (EXAM)\nLaboratory (LAB)\nQuestionnaire (Q)\n\n\nTo get a list of available variables within a data file, we run the following command (e.g., we check variable names within DEMO data):\n\n\nShow the code\nnhanesTables(data_group='DEMO', year=2015)\n\n\n\n\n  \n\n\n\n\nStep 2: We can obtain the summaries of the downloaded data as follows (see below):\n\n\n\nShow the code\ndemo <- nhanes('DEMO_I')\nnames(demo)\n#>  [1] \"SEQN\"     \"SDDSRVYR\" \"RIDSTATR\" \"RIAGENDR\" \"RIDAGEYR\" \"RIDAGEMN\"\n#>  [7] \"RIDRETH1\" \"RIDRETH3\" \"RIDEXMON\" \"RIDEXAGM\" \"DMQMILIZ\" \"DMQADFC\" \n#> [13] \"DMDBORN4\" \"DMDCITZN\" \"DMDYRSUS\" \"DMDEDUC3\" \"DMDEDUC2\" \"DMDMARTL\"\n#> [19] \"RIDEXPRG\" \"SIALANG\"  \"SIAPROXY\" \"SIAINTRP\" \"FIALANG\"  \"FIAPROXY\"\n#> [25] \"FIAINTRP\" \"MIALANG\"  \"MIAPROXY\" \"MIAINTRP\" \"AIALANGA\" \"DMDHHSIZ\"\n#> [31] \"DMDFMSIZ\" \"DMDHHSZA\" \"DMDHHSZB\" \"DMDHHSZE\" \"DMDHRGND\" \"DMDHRAGE\"\n#> [37] \"DMDHRBR4\" \"DMDHREDU\" \"DMDHRMAR\" \"DMDHSEDU\" \"WTINT2YR\" \"WTMEC2YR\"\n#> [43] \"SDMVPSU\"  \"SDMVSTRA\" \"INDHHIN2\" \"INDFMIN2\" \"INDFMPIR\"\ntable(demo$DMDHSEDU) # Frequency table\n#> \n#>    1    2    3    4    5    7    9 \n#>  619  511  980 1462 1629    2   23\ncumsum(table(demo$DMDHSEDU)) # Cumulative frequency table\n#>    1    2    3    4    5    7    9 \n#>  619 1130 2110 3572 5201 5203 5226\nlength(is.na(demo$DMDHSEDU)) # Number of non-NA observations\n#> [1] 9971\n\n\n\n\n\nReferences\n\n\n\n\n\n\nCDC. 2023. “NHANES Web Tutorial Frequently Asked Questions (FAQs).” https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/faq.aspx.\n\n\nCDC,NCHS. 2023. “National Health and Nutrition Examination Survey Data.” https://wwwn.cdc.gov/nchs/nhanes/.\n\n\nSusmann, Herb. 2016. RNHANES: Facilitates Analysis of CDC NHANES Data. https://CRAN.R-project.org/package=RNHANES."
  },
  {
    "objectID": "accessing4.html#youtube-videos",
    "href": "accessing4.html#youtube-videos",
    "title": "Reproducing results",
    "section": "YouTube Videos",
    "text": "YouTube Videos\nYou could watch the videos describing how to create an analytic dataset from NHANES, and working with NHANES."
  },
  {
    "objectID": "accessing4.html#references",
    "href": "accessing4.html#references",
    "title": "Reproducing results",
    "section": "References",
    "text": "References\n\n\n\n\n\n\nDhana, A. 2023. “R & Python for Data Science.” https://datascienceplus.com/.\n\n\nFlegal, Katherine M, Deanna Kruszon-Moran, Margaret D Carroll, Cheryl D Fryar, and Cynthia L Ogden. 2016. “Trends in Obesity Among Adults in the United States, 2005 to 2014.” Jama 315 (21): 2284–91."
  },
  {
    "objectID": "accessingF.html",
    "href": "accessingF.html",
    "title": "Functions for data accessing",
    "section": "",
    "text": "The section introduces a set of R functions useful for accessing and processing complex survey data, providing their descriptions and the packages they belong to.\n\n\n\n\n \n  \n    Function_name \n    Package_name \n    Description \n  \n \n\n  \n    apply \n    base \n    Applies a function over an array or matrix. \n  \n  \n    cut \n    base \n    Converts a numeric variable to a factor variable. \n  \n  \n    merge \n    base/data.table \n    Merges multiple datasets. \n  \n  \n    names \n    base \n    Retrieves the names of an object. \n  \n  \n    nhanes \n    nhanesA \n    Downloads a NHANES datafile. \n  \n  \n    nhanesTables \n    nhanesA \n    Lists available variables within a datafile. \n  \n  \n    nhanesTranslate \n    nhanesA \n    Encodes categorical variables to match with certain standards, e.g., CDC website. \n  \n  \n    recode \n    car \n    Recodes a variable. \n  \n\n\n\n\n\nFor more information, visit the resources mentioned earlier."
  },
  {
    "objectID": "accessingQ.html",
    "href": "accessingQ.html",
    "title": "Quiz on accessing",
    "section": "",
    "text": "Downloading the File:\n\nNavigate to the link: See here.\nRight-click on the link and select “Save link as…” from the dropdown menu.\nAlternatively click here for downloading the quizzes on data wrangling.\nChoose a destination folder on your computer where you’d like to save the file (e.g., Desktop). Remember this location, as you’ll need to navigate to it later.\n\nSetting Up RStudio:\n\nIf you don’t have RStudio installed, see the download link in here.\nLaunch RStudio after installing.\n\nInstalling Necessary R Packages:\n\nBefore running the R Markdown file, ensure you have the required packages. In RStudio’s console (located at the bottom left by default), enter the following commands to install them:\ninstall.packages(\"learnr\")\ninstall.packages(\"xfun\")\n\nOpening and Running the File:\n\nIn RStudio, go to File > Open File....\nNavigate to the folder where you saved the Rmd file and select it to open.\nOnce the file is open in RStudio, you’ll see a “Run Document” button (green) at the top of the script editor. Click on it to run the R Markdown Quiz file."
  },
  {
    "objectID": "researchquestion.html#rhc-data",
    "href": "researchquestion.html#rhc-data",
    "title": "Research question",
    "section": "RHC data",
    "text": "RHC data\nThe tutorial serves to educate the user on how to utilize the RHC dataset to answer a research question: developing a prediction model for the length of stay. The tutorial equips users with the skills to clean and process raw data, transforming it into an analyzable format, and introduces concepts that will be foundational for subsequent analysis."
  },
  {
    "objectID": "researchquestion.html#nhanes-data",
    "href": "researchquestion.html#nhanes-data",
    "title": "Research question",
    "section": "NHANES data",
    "text": "NHANES data\nThe NHANES dataset was analyzed in this tutorial to explore the relationship between health predictors and cholesterol levels. After refining the survey design and handling missing data, regression models were built using varying predictors. Standard error computations and p-values were derived, adjusting for the survey’s unique structure."
  },
  {
    "objectID": "researchquestion1.html",
    "href": "researchquestion1.html",
    "title": "RHC data",
    "section": "",
    "text": "Show the code\n# Load required packages\nrequire(tableone)\nrequire(Publish)\nrequire(MatchIt)\nrequire(cobalt)\nrequire(ggplot2)\n\n\nThis tutorial delves into processing and understanding the RHC dataset, which pertains to patients in the intensive care unit. The dataset is particularly centered around the implications of using right heart catheterization (RHC) in the early phases of care, with a focus on comparing two patient groups: those who received the RHC procedure and those who did not. The key outcome being analyzed is the 30-day survival rate. We will use this as an example to explain how to work with a predictive research question to build the analytic data.\n\n\nLink for the RHC dataset\n(Connors et al. 1996) published an article in JAMA. The article is about managing or guiding therapy for the critically ill patients in the intensive care unit. They considered a number of health-outcomes such as\n\nlength of stay (hospital stay; measured continuously)\ndeath within certain period (death at any time up to 180 Days; measured as a binary variable)\n\nThe original article was concerned about the association of right heart catheterization (RHC) use during the first 24 hours of care in the intensive care unit and the health-outcomes mentioned above, but we will use this data as a case study for our prediction modelling. Traditional PICOT framework is designed primarily for clinical questions related to interventions, so when applying it to other areas like predictive modeling, some creative adaptation is needed.\n\n\n\n\n\n\n\nAspect\nDescription\n\n\n\n\nP\nPatients who are critically ill\n\n\nI\nNot applicable, as we are dealing with a prediction model here\n\n\nC\nNot applicable, as we are dealing with a prediction model here\n\n\nO\nin-hospital mortality\n\n\nT\nBetween 1989 to 1994 (see the JAMA paper)\n\n\n\n\n\nWe are interested in developing a prediction model for the length of stay.\nYou could watch the video describing this chapter \n\nData download\nData is freely available from Vanderbilt Biostatistics, variable list is available here, and the article is freely available from researchgate.\n\n\nRHC Data\n\nVariable list\n\nArticle\n\n\nLet us download the dataset and save it for later use.\n\n\nShow the code\n# Load the dataset\nObsData <- read.csv(\"https://hbiostat.org/data/repo/rhc.csv\", header = TRUE)\n\n# Save the dataset\nsaveRDS(ObsData, file = \"Data/researchquestion/rhc.RDS\")\n\n\n\n\nCreating analytic data\nNow, we show the process of preparing analytic data, so that the variables generally match with the way the authors were coded in the original article. Below we show the process of creating the analytic data.\n\nAdd column for outcome: length of stay\n\n\nShow the code\n# Length.of.Stay = date of discharge - study admission date\nObsData$Length.of.Stay <- ObsData$dschdte - ObsData$sadmdte\n\n# Length.of.Stay = date of death - study admission date if date of discharge not available\nObsData$Length.of.Stay[is.na(ObsData$Length.of.Stay)] <- \n  ObsData$dthdte[is.na(ObsData$Length.of.Stay)] - \n  ObsData$sadmdte[is.na(ObsData$Length.of.Stay)]\n\n\n\n\nRecoding column for outcome: death\n\n\n\n\n\n\nTip\n\n\n\nHere we use the ifelse function to create a categorical variable. Other related functions are cut, car.\n\n\nLet us recode our outcome variable as a binary variable:\n\n\nShow the code\nObsData$death <- ifelse(ObsData$death == \"Yes\", 1, 0)\n\n\n\n\nRemove unnecessary outcomes\nOur next task is to remove unnecessary outcomes:\n\n\n\n\n\n\nTip\n\n\n\nThere are multiple ways to drop variables from a dataset. E.g., without using any package and using the select function from the dplyr package.\n\n\n\n\nShow the code\nObsData <- dplyr::select(ObsData, !c(dthdte, lstctdte, dschdte, \n                            t3d30, dth30, surv2md1))\n\n\n\n\nRemove unnecessary and problematic variables\nNow we will drop unnecessary and problematic variables:\n\n\nShow the code\nObsData <- dplyr::select(ObsData, !c(sadmdte, ptid, X, adld3p, urin1, cat2))\n\n\n\n\nBasic data cleanup\nNow we will do some basic cleanup.\n\n\n\n\n\n\nTip\n\n\n\nWe an use the lapply function to convert all categorical variables to factors at once. Not that a similar function to lapply is sapply. The main difference is that sapply attempts to convert the result into a vector or matrix, while lapply returns a list.\n\n\n\n\nShow the code\n# convert all categorical variables to factors\nfactors <- c(\"cat1\", \"ca\", \"death\", \"cardiohx\", \"chfhx\", \n             \"dementhx\", \"psychhx\", \"chrpulhx\", \"renalhx\", \n             \"liverhx\", \"gibledhx\", \"malighx\", \"immunhx\", \n             \"transhx\", \"amihx\", \"sex\", \"dnr1\", \"ninsclas\", \n             \"resp\", \"card\", \"neuro\", \"gastr\", \"renal\", \"meta\", \n             \"hema\", \"seps\", \"trauma\", \"ortho\", \"race\", \n             \"income\")\nObsData[factors] <- lapply(ObsData[factors], as.factor)\n\n# convert RHC.use (RHC vs. No RHC) to a binary variable\nObsData$RHC.use <- ifelse(ObsData$swang1 == \"RHC\", 1, 0)\nObsData <- dplyr::select(ObsData, !swang1)\n\n# Categorize the variables to match with the original paper\nObsData$age <- cut(ObsData$age, breaks=c(-Inf, 50, 60, 70, 80, Inf),\n                   right=FALSE)\nObsData$race <- factor(ObsData$race, levels=c(\"white\",\"black\",\"other\"))\nObsData$sex <- as.factor(ObsData$sex)\nObsData$sex <- relevel(ObsData$sex, ref = \"Male\")\nObsData$cat1 <- as.factor(ObsData$cat1)\nlevels(ObsData$cat1) <- c(\"ARF\",\"CHF\",\"Other\",\"Other\",\"Other\",\n                          \"Other\",\"Other\",\"MOSF\",\"MOSF\")\nObsData$ca <- as.factor(ObsData$ca)\nlevels(ObsData$ca) <- c(\"Metastatic\",\"None\",\"Localized (Yes)\")\nObsData$ca <- factor(ObsData$ca, levels=c(\"None\", \"Localized (Yes)\",\n                                          \"Metastatic\"))\n\n\n\n\nRename variables\n\n\nShow the code\n# Rename the variables\nnames(ObsData) <- c(\"Disease.category\", \"Cancer\", \"Death\", \"Cardiovascular\", \n                    \"Congestive.HF\", \"Dementia\", \"Psychiatric\", \"Pulmonary\", \n                    \"Renal\", \"Hepatic\", \"GI.Bleed\", \"Tumor\", \n                    \"Immunosupperssion\", \"Transfer.hx\", \"MI\", \"age\", \"sex\", \n                    \"edu\", \"DASIndex\", \"APACHE.score\", \"Glasgow.Coma.Score\", \n                    \"blood.pressure\", \"WBC\", \"Heart.rate\", \"Respiratory.rate\", \n                    \"Temperature\", \"PaO2vs.FIO2\", \"Albumin\", \"Hematocrit\", \n                    \"Bilirubin\", \"Creatinine\", \"Sodium\", \"Potassium\", \"PaCo2\", \n                    \"PH\", \"Weight\", \"DNR.status\", \"Medical.insurance\", \n                    \"Respiratory.Diag\", \"Cardiovascular.Diag\", \n                    \"Neurological.Diag\", \"Gastrointestinal.Diag\", \"Renal.Diag\",\n                    \"Metabolic.Diag\", \"Hematologic.Diag\", \"Sepsis.Diag\", \n                    \"Trauma.Diag\", \"Orthopedic.Diag\", \"race\", \"income\", \n                    \"Length.of.Stay\", \"RHC.use\")\n\n# Save the dataset\nsaveRDS(ObsData, file = \"Data/researchquestion/rhcAnalytic.RDS\")\n\n\n\n\n\nNotations\nlet us introduce with some notations:\n\n\n\nNotations\nExample in RHC study\n\n\n\n\n\\(Y_1\\): Observed outcome\nlength of stay\n\n\n\\(Y_2\\): Observed outcome\ndeath within 3 months\n\n\n\\(L\\): Covariates\nSee below\n\n\n\n\n\nBasic data exploration\n\nDimension\nLet us the how many rows and columns we have:\n\n\nShow the code\ndim(ObsData)\n#> [1] 5735   52\n\n\n\n\nComprehensive summary\nLet us see the summary statistics of the variables:\n\n\n\n\n\n\nTip\n\n\n\nTo see the comprehensive summary of the variables, we can use the skim function form skimr package or describe function from rms package\n\n\n\n\nShow the code\nrequire(skimr)\n#> Loading required package: skimr\n#> Warning: package 'skimr' was built under R version 4.3.1\nskim(ObsData)\n\n\n\nData summary\n\n\nName\nObsData\n\n\nNumber of rows\n5735\n\n\nNumber of columns\n52\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n31\n\n\nnumeric\n21\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nDisease.category\n0\n1\nFALSE\n4\nARF: 2490, MOS: 1626, Oth: 1163, CHF: 456\n\n\nCancer\n0\n1\nFALSE\n3\nNon: 4379, Loc: 972, Met: 384\n\n\nDeath\n0\n1\nFALSE\n2\n1: 3722, 0: 2013\n\n\nCardiovascular\n0\n1\nFALSE\n2\n0: 4722, 1: 1013\n\n\nCongestive.HF\n0\n1\nFALSE\n2\n0: 4714, 1: 1021\n\n\nDementia\n0\n1\nFALSE\n2\n0: 5171, 1: 564\n\n\nPsychiatric\n0\n1\nFALSE\n2\n0: 5349, 1: 386\n\n\nPulmonary\n0\n1\nFALSE\n2\n0: 4646, 1: 1089\n\n\nRenal\n0\n1\nFALSE\n2\n0: 5480, 1: 255\n\n\nHepatic\n0\n1\nFALSE\n2\n0: 5334, 1: 401\n\n\nGI.Bleed\n0\n1\nFALSE\n2\n0: 5550, 1: 185\n\n\nTumor\n0\n1\nFALSE\n2\n0: 4419, 1: 1316\n\n\nImmunosupperssion\n0\n1\nFALSE\n2\n0: 4192, 1: 1543\n\n\nTransfer.hx\n0\n1\nFALSE\n2\n0: 5073, 1: 662\n\n\nMI\n0\n1\nFALSE\n2\n0: 5535, 1: 200\n\n\nage\n0\n1\nFALSE\n5\n[-I: 1424, [60: 1389, [70: 1338, [50: 917\n\n\nsex\n0\n1\nFALSE\n2\nMal: 3192, Fem: 2543\n\n\nDNR.status\n0\n1\nFALSE\n2\nNo: 5081, Yes: 654\n\n\nMedical.insurance\n0\n1\nFALSE\n6\nPri: 1698, Med: 1458, Pri: 1236, Med: 647\n\n\nRespiratory.Diag\n0\n1\nFALSE\n2\nNo: 3622, Yes: 2113\n\n\nCardiovascular.Diag\n0\n1\nFALSE\n2\nNo: 3804, Yes: 1931\n\n\nNeurological.Diag\n0\n1\nFALSE\n2\nNo: 5042, Yes: 693\n\n\nGastrointestinal.Diag\n0\n1\nFALSE\n2\nNo: 4793, Yes: 942\n\n\nRenal.Diag\n0\n1\nFALSE\n2\nNo: 5440, Yes: 295\n\n\nMetabolic.Diag\n0\n1\nFALSE\n2\nNo: 5470, Yes: 265\n\n\nHematologic.Diag\n0\n1\nFALSE\n2\nNo: 5381, Yes: 354\n\n\nSepsis.Diag\n0\n1\nFALSE\n2\nNo: 4704, Yes: 1031\n\n\nTrauma.Diag\n0\n1\nFALSE\n2\nNo: 5683, Yes: 52\n\n\nOrthopedic.Diag\n0\n1\nFALSE\n2\nNo: 5728, Yes: 7\n\n\nrace\n0\n1\nFALSE\n3\nwhi: 4460, bla: 920, oth: 355\n\n\nincome\n0\n1\nFALSE\n4\nUnd: 3226, $11: 1165, $25: 893, > $: 451\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nedu\n0\n1\n11.68\n3.15\n0.00\n10.00\n12.00\n13.00\n30.00\n▁▇▃▁▁\n\n\nDASIndex\n0\n1\n20.50\n5.32\n11.00\n16.06\n19.75\n23.43\n33.00\n▃▇▆▂▃\n\n\nAPACHE.score\n0\n1\n54.67\n19.96\n3.00\n41.00\n54.00\n67.00\n147.00\n▂▇▅▁▁\n\n\nGlasgow.Coma.Score\n0\n1\n21.00\n30.27\n0.00\n0.00\n0.00\n41.00\n100.00\n▇▂▂▁▁\n\n\nblood.pressure\n0\n1\n78.52\n38.05\n0.00\n50.00\n63.00\n115.00\n259.00\n▆▇▆▁▁\n\n\nWBC\n0\n1\n15.65\n11.87\n0.00\n8.40\n14.10\n20.05\n192.00\n▇▁▁▁▁\n\n\nHeart.rate\n0\n1\n115.18\n41.24\n0.00\n97.00\n124.00\n141.00\n250.00\n▁▂▇▂▁\n\n\nRespiratory.rate\n0\n1\n28.09\n14.08\n0.00\n14.00\n30.00\n38.00\n100.00\n▅▇▂▁▁\n\n\nTemperature\n0\n1\n37.62\n1.77\n27.00\n36.09\n38.09\n39.00\n43.00\n▁▁▅▇▁\n\n\nPaO2vs.FIO2\n0\n1\n222.27\n114.95\n11.60\n133.31\n202.50\n316.62\n937.50\n▇▇▁▁▁\n\n\nAlbumin\n0\n1\n3.09\n0.78\n0.30\n2.60\n3.50\n3.50\n29.00\n▇▁▁▁▁\n\n\nHematocrit\n0\n1\n31.87\n8.36\n2.00\n26.10\n30.00\n36.30\n66.19\n▁▆▇▃▁\n\n\nBilirubin\n0\n1\n2.27\n4.80\n0.10\n0.80\n1.01\n1.40\n58.20\n▇▁▁▁▁\n\n\nCreatinine\n0\n1\n2.13\n2.05\n0.10\n1.00\n1.50\n2.40\n25.10\n▇▁▁▁▁\n\n\nSodium\n0\n1\n136.77\n7.66\n101.00\n132.00\n136.00\n142.00\n178.00\n▁▂▇▁▁\n\n\nPotassium\n0\n1\n4.07\n1.03\n1.10\n3.40\n3.80\n4.60\n11.90\n▂▇▁▁▁\n\n\nPaCo2\n0\n1\n38.75\n13.18\n1.00\n31.00\n37.00\n42.00\n156.00\n▃▇▁▁▁\n\n\nPH\n0\n1\n7.39\n0.11\n6.58\n7.34\n7.40\n7.46\n7.77\n▁▁▂▇▁\n\n\nWeight\n0\n1\n67.83\n29.06\n0.00\n56.30\n70.00\n83.70\n244.00\n▂▇▁▁▁\n\n\nLength.of.Stay\n0\n1\n21.56\n25.87\n2.00\n7.00\n14.00\n25.00\n394.00\n▇▁▁▁▁\n\n\nRHC.use\n0\n1\n0.38\n0.49\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▅\n\n\n\n\n\n\n\n\nPredictive vs. causal models\nThe focus of current document is predictive models (e.g., predicting a health outcome).\n\n\n\n\n\nThe original article by Connors et al. (1996) focused on the association of\n\n\nConnors et al. (1996)\n\nright heart catheterization (RHC) use during the first 24 hours of care in the intensive care unit (exposure of primary interest) and\nthe health-outcomes (such as length of stay).\n\n\n\n\n\n\nThen the PICOT table changes as follows:\n\n\n\n\n\n\n\nAspect\nDescription\n\n\n\n\nP\nPatients who are critically ill\n\n\nI\nReceiving a right heart catheterization (RHC)\n\n\nC\nNot receiving a right heart catheterization (RHC)\n\n\nO\nlength of stay\n\n\nT\nBetween 1989 to 1994 (see the JAMA paper)\n\n\n\n\nIf the readers are interested about the causal models used in that article, they can refer to this tutorial.\nThis data has been used in other articles in the literature within the advanced causal modelling context; for example Keele and Small (2021) and Keele and Small (2018). Readers can further consult this tutorial to understand those methods.\n\n\n\nKeele and Small (2018)\n\nKeele and Small (2021)\n\n\n\nReferences\n\n\n\n\n\n\nConnors, Alfred F, Theodore Speroff, Neal V Dawson, Charles Thomas, Frank E Harrell, Douglas Wagner, Norman Desbiens, et al. 1996. “The Effectiveness of Right Heart Catheterization in the Initial Care of Critically III Patients.” Jama 276 (11): 889–97. https://tinyurl.com/Connors1996.\n\n\nKeele, Luke, and Dylan S Small. 2018. “Pre-Analysis Plan for a Comparison of Matching and Black Box-Based Covariate Adjustment.” Observational Studies 4 (1): 97–110.\n\n\n———. 2021. “Comparing Covariate Prioritization via Matching to Machine Learning Methods for Causal Inference Using Five Empirical Applications.” The American Statistician 75 (4): 355–63."
  },
  {
    "objectID": "researchquestion2.html",
    "href": "researchquestion2.html",
    "title": "NHANES data",
    "section": "",
    "text": "Working with a causal question\nWe are interested in exploring the relationship between diabetes (binary exposure variable defined as whether the doctor ever told the participant has diabetes) and cholesterol (binary outcome variable defined as whether total cholesterol is more than 200 mg/dL). Below is the PICOT:\n\n\n\nPICOT element\nDescription\n\n\n\n\nP\nUS adults\n\n\nI\nDiabetes\n\n\nC\nNo diabetes\n\n\nO\nTotal cholesterol > 200 mg/dL\n\n\nT\n2017–2018\n\n\n\nFirst, we will prepare the analytic dataset from NHANES 2017–2018.\nSecond, we will work with subset of data to assess the association between diabetes and cholesterol, and to get proper SE and 95% CI for the estimate. We emphasize the correct usage of the survey’s design features (correct handling of survey design elements, such as stratification, clustering, and weighting) to obtain accurate population-level estimates.\n\n\nShow the code\n# Load required packages\nrequire(SASxport)\nrequire(DiagrammeR)\nrequire(DiagrammeRsvg)\nrequire(rsvg)\nlibrary(magrittr)\nlibrary(svglite)\nlibrary(png)\nrequire(nhanesA)\nrequire(survey)\nrequire(Publish)\nrequire(jtools)\n\n\n\n\nSteps for creating analytic dataset\nWe will combine multiple components (e.g., demographic, blood pressure) using the unique identifier to create our analytic dataset.\n\n\nWithin NHANES datasets in a given cycle, each sampled person has an unique identifier sequence number (variable SEQN).\n\n\n\n\n\n\n\n\n\nDownload and Subsetting to retain only the useful variables\nSearch literature for the relevant variables, e.g., Peters, Fabian, and Levy (2014), and then see if some of them are available in the NHANES data.\n\n\nPeters, Fabian, and Levy (2014)\n\n\nShow the code\ndemo <- nhanes('DEMO_J') # Both males and females 0 YEARS - 150 YEARS\ndemo <- demo[c(\"SEQN\", # Respondent sequence number\n                 \"RIAGENDR\", # gender\n                 \"RIDAGEYR\", # Age in years at screening\n                 \"DMDBORN4\", # Country of birth\n                 \"RIDRETH3\", # Race/Hispanic origin w/ NH Asian\n                 \"DMDEDUC3\", # Education level - Children/Youth 6-19\n                 \"DMDEDUC2\", # Education level - Adults 20+\n                 \"DMDMARTL\", # Marital status: 20 YEARS - 150 YEARS\n                 \"INDHHIN2\", # Total household income\n                 \"WTMEC2YR\", \"SDMVPSU\", \"SDMVSTRA\")]\ndemo_vars <- names(demo) # nhanesTableVars('DEMO', 'DEMO_J', namesonly=TRUE)\ndemo1 <- nhanesTranslate('DEMO_J', demo_vars, data=demo)\n#> Translated columns: RIAGENDR DMDBORN4 RIDRETH3 DMDEDUC3 DMDEDUC2 DMDMARTL INDHHIN2\n\n\n\n\nShow the code\nbpx <- nhanes('BPX_J')\nbpx <- bpx[c(\"SEQN\", # Respondent sequence number\n             \"BPXDI1\", #Diastolic: Blood pres (1st rdg) mm Hg\n             \"BPXSY1\" # Systolic: Blood pres (1st rdg) mm Hg\n             )]\nbpx_vars <- names(bpx) \nbpx1 <- nhanesTranslate('BPX_J', bpx_vars, data=bpx)\n#> Warning in nhanesTranslate(\"BPX_J\", bpx_vars, data = bpx): No columns were\n#> translated\n\n\n\n\nShow the code\nbmi <- nhanes('BMX_J')\nbmi <- bmi[c(\"SEQN\", # Respondent sequence number\n               \"BMXWT\", # Weight (kg) \n               \"BMXHT\", # Standing Height (cm)\n               \"BMXBMI\", # Body Mass Index (kg/m**2): 2 YEARS - 150 YEARS\n               #\"BMDBMIC\", # BMI Category - Children/Youth # 2 YEARS - 19 YEARS\n               \"BMXWAIST\" # Waist Circumference (cm): 2 YEARS - 150 YEARS\n               )]\nbmi_vars <- names(bmi) \nbmi1 <- nhanesTranslate('BMX_J', bmi_vars, data=bmi)\n#> Warning in nhanesTranslate(\"BMX_J\", bmi_vars, data = bmi): No columns were\n#> translated\n\n\n\n\nShow the code\nsmq <- nhanes('SMQ_J')\nsmq <- smq[c(\"SEQN\", # Respondent sequence number\n               \"SMQ040\" # Do you now smoke cigarettes?: 18 YEARS - 150 YEARS\n               )]\nsmq_vars <- names(smq) \nsmq1 <- nhanesTranslate('SMQ_J', smq_vars, data=smq)\n#> Translated columns: SMQ040\n\n\n\n\nShow the code\n# alq <- nhanes('ALQ_J')\n# alq <- alq[c(\"SEQN\", # Respondent sequence number\n#                \"ALQ130\" # Avg # alcoholic drinks/day - past 12 mos\n#                # 18 YEARS - 150 YEARS\n#                )]\n# alq_vars <- names(alq) \n# alq1 <- nhanesTranslate('ALQ_J', alq_vars, data=alq)\n\n\n\n\nShow the code\nchl <- nhanes('TCHOL_J') # 6 YEARS - 150 YEARS\nchl <- chl[c(\"SEQN\", # Respondent sequence number\n               \"LBXTC\", # Total Cholesterol (mg/dL)\n               \"LBDTCSI\" # Total Cholesterol (mmol/L)\n               )]\nchl_vars <- names(chl) \nchl1 <- nhanesTranslate('TCHOL_J', chl_vars, data=chl)\n#> Warning in nhanesTranslate(\"TCHOL_J\", chl_vars, data = chl): No columns were\n#> translated\n\n\n\n\nShow the code\ntri <- nhanes('BIOPRO_J') # 12 YEARS - 150 YEARS\ntri <- tri[c(\"SEQN\", # Respondent sequence number\n               \"LBXSTR\", # Triglycerides, refrig serum (mg/dL)\n               \"LBXSUA\", # Uric acid\n               \"LBXSTP\", # total Protein (g/dL)\n               \"LBXSTB\", # Total Bilirubin (mg/dL)\n               \"LBXSPH\", # Phosphorus (mg/dL)\n               \"LBXSNASI\", # Sodium (mmol/L)\n               \"LBXSKSI\", # Potassium (mmol/L)\n               \"LBXSGB\", # Globulin (g/dL)\n               \"LBXSCA\" # Total Calcium (mg/dL)\n               )]\ntri_vars <- names(tri) \ntri1 <- nhanesTranslate('BIOPRO_J', tri_vars, data=tri)\n#> Warning in nhanesTranslate(\"BIOPRO_J\", tri_vars, data = tri): No columns were\n#> translated\n\n\n\n\nShow the code\npaq <- nhanes('PAQ_J')\npaq <- paq[c(\"SEQN\", # Respondent sequence number\n               \"PAQ605\", # Vigorous work activity \n               \"PAQ650\" # Vigorous recreational activities\n               )]\npaq_vars <- names(paq) \npaq1 <- nhanesTranslate('PAQ_J', paq_vars, data=paq)\n#> Translated columns: PAQ605 PAQ650\n\n\n\n\nShow the code\ndiq <- nhanes('DIQ_J')\ndiq <- diq[c(\"SEQN\", # Respondent sequence number\n               \"DIQ010\" # Doctor told you have diabetes\n               )]\ndiq_vars <- names(diq) \ndiq1 <- nhanesTranslate('DIQ_J', diq_vars, data=diq)\n#> Translated columns: DIQ010\n\n\n\n\nMerging all the datasets\n\n\n\n\n\n\nTip\n\n\n\nWe can use the merge or Reduce function to combine the datasets\n\n\n\n\nShow the code\nanalytic.data7 <- Reduce(function(x,y) merge(x,y,by=\"SEQN\",all=TRUE) ,\n       list(demo1,bpx1,bmi1,smq1,chl1,tri1,paq1,diq1))\ndim(analytic.data7)\n#> [1] 9254   33\n\n\n\n\nShow the code\n# Merging one by one\n# analytic.data0 <- merge(demo1, bpx1, by = c(\"SEQN\"), all=TRUE)\n# analytic.data1 <- merge(analytic.data0, bmi1, by = c(\"SEQN\"), all=TRUE)\n# analytic.data2 <- merge(analytic.data1, smq1, by = c(\"SEQN\"), all=TRUE)\n# analytic.data3 <- merge(analytic.data2, alq1, by = c(\"SEQN\"), all=TRUE)\n# analytic.data4 <- merge(analytic.data3, chl1, by = c(\"SEQN\"), all=TRUE)\n# analytic.data5 <- merge(analytic.data4, tri1, by = c(\"SEQN\"), all=TRUE)\n# analytic.data6 <- merge(analytic.data5, paq1, by = c(\"SEQN\"), all=TRUE)\n# analytic.data7 <- merge(analytic.data6, diq1, by = c(\"SEQN\"), all=TRUE)\n# dim(analytic.data7)\n\n\n\n\nCheck Target population and avoid zero-cell cross-tabulation\nSee that marital status variable was restricted to 20 YEARS - 150 YEARS.\n\n\nShow the code\nstr(analytic.data7)\n#> 'data.frame':    9254 obs. of  33 variables:\n#>  $ SEQN    : num  93703 93704 93705 93706 93707 ...\n#>  $ RIAGENDR: Factor w/ 2 levels \"Male\",\"Female\": 2 1 2 1 1 2 2 2 1 1 ...\n#>  $ RIDAGEYR: num  2 2 66 18 13 66 75 0 56 18 ...\n#>  $ DMDBORN4: Factor w/ 4 levels \"Born in 50 US states or Washingt\",..: 1 1 1 1 1 2 1 1 2 2 ...\n#>  $ RIDRETH3: Factor w/ 6 levels \"Mexican American\",..: 5 3 4 5 6 5 4 3 5 1 ...\n#>  $ DMDEDUC3: Factor w/ 17 levels \"Never attended / kindergarten on\",..: NA NA NA 16 7 NA NA NA NA 13 ...\n#>  $ DMDEDUC2: Factor w/ 7 levels \"Less than 9th grade\",..: NA NA 2 NA NA 1 4 NA 5 NA ...\n#>  $ DMDMARTL: Factor w/ 7 levels \"Married\",\"Widowed\",..: NA NA 3 NA NA 1 2 NA 1 NA ...\n#>  $ INDHHIN2: Factor w/ 16 levels \"$ 0 to $ 4,999\",..: 14 14 3 NA 10 6 2 14 14 4 ...\n#>  $ WTMEC2YR: num  8540 42567 8338 8723 7065 ...\n#>  $ SDMVPSU : num  2 1 2 2 1 2 1 1 2 2 ...\n#>  $ SDMVSTRA: num  145 143 145 134 138 138 136 134 134 147 ...\n#>  $ BPXDI1  : num  NA NA NA 74 38 NA 66 NA 68 68 ...\n#>  $ BPXSY1  : num  NA NA NA 112 128 NA 120 NA 108 112 ...\n#>  $ BMXWT   : num  13.7 13.9 79.5 66.3 45.4 53.5 88.8 10.2 62.1 58.9 ...\n#>  $ BMXHT   : num  88.6 94.2 158.3 175.7 158.4 ...\n#>  $ BMXBMI  : num  17.5 15.7 31.7 21.5 18.1 23.7 38.9 NA 21.3 19.7 ...\n#>  $ BMXWAIST: num  48.2 50 101.8 79.3 64.1 ...\n#>  $ SMQ040  : Factor w/ 3 levels \"Every day\",\"Some days\",..: NA NA 3 NA NA NA 1 NA NA 2 ...\n#>  $ LBXTC   : num  NA NA 157 148 189 209 176 NA 238 182 ...\n#>  $ LBDTCSI : num  NA NA 4.06 3.83 4.89 5.4 4.55 NA 6.15 4.71 ...\n#>  $ LBXSTR  : num  NA NA 95 92 110 72 132 NA 59 124 ...\n#>  $ LBXSUA  : num  NA NA 5.8 8 5.5 4.5 6.2 NA 4.2 5.8 ...\n#>  $ LBXSTP  : num  NA NA 7.3 7.1 8 7.1 7 NA 7.1 8.1 ...\n#>  $ LBXSTB  : num  NA NA 0.6 0.7 0.7 0.5 0.3 NA 0.3 0.8 ...\n#>  $ LBXSPH  : num  NA NA 4 4 4.3 3.3 3.5 NA 3.4 5.1 ...\n#>  $ LBXSNASI: num  NA NA 141 144 137 144 141 NA 140 141 ...\n#>  $ LBXSKSI : num  NA NA 4 4.4 3.3 4.4 4.1 NA 4.9 4.3 ...\n#>  $ LBXSGB  : num  NA NA 2.9 2.7 2.8 3.2 3.3 NA 3.1 3.3 ...\n#>  $ LBXSCA  : num  NA NA 9.2 9.6 10.1 9.5 9.9 NA 9.4 9.6 ...\n#>  $ PAQ605  : Factor w/ 3 levels \"Yes\",\"No\",\"Don't know\": NA NA 2 2 NA 2 2 NA 2 1 ...\n#>  $ PAQ650  : Factor w/ 2 levels \"Yes\",\"No\": NA NA 2 2 NA 2 2 NA 1 1 ...\n#>  $ DIQ010  : Factor w/ 4 levels \"Yes\",\"No\",\"Borderline\",..: 2 2 2 2 2 3 2 NA 2 2 ...\nhead(analytic.data7)\n\n\n\n\n  \n\n\n\nShow the code\nsummary(analytic.data7$RIDAGEYR)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>    0.00   11.00   31.00   34.33   58.00   80.00\n\n\n\n\nShow the code\ndim(analytic.data7)\n#> [1] 9254   33\nanalytic.data8 <- analytic.data7\nanalytic.data8$RIDAGEYR[analytic.data8$RIDAGEYR < 20] <- NA\n#analytic.data8 <- subset(analytic.data7, RIDAGEYR >= 20)\ndim(analytic.data8)\n#> [1] 9254   33\n\n\nGet rid of variables where target was less than 20 years of age accordingly.\n\n\nShow the code\nanalytic.data8$DMDEDUC3 <- NULL # not relevant for adults\n#analytic.data8$BMDBMIC <- NULL # not relevant for adults\n\n\n\n\nGet rid of invalid responses\n\n\nShow the code\nfactor.names <- c(\"RIAGENDR\",\"DMDBORN4\",\"RIDRETH3\",\n                  \"DMDEDUC2\",\"DMDMARTL\",\"INDHHIN2\", \n                  \"SMQ040\", \"PAQ605\", \"PAQ650\", \"DIQ010\")\nnumeric.names <- c(\"SEQN\",\"RIDAGEYR\",\"WTMEC2YR\",\n                   \"SDMVPSU\", \"SDMVSTRA\",\n                   \"BPXDI1\", \"BPXSY1\", \"BMXWT\", \"BMXHT\",\n                   \"BMXBMI\", \"BMXWAIST\",\n                   \"ALQ130\", \"LBXTC\", \"LBDTCSI\", \n                   \"LBXSTR\", \"LBXSUA\", \"LBXSTP\", \"LBXSTB\", \n                   \"LBXSPH\", \"LBXSNASI\", \"LBXSKSI\",\n                   \"LBXSGB\",\"LBXSCA\")\nanalytic.data8[factor.names] <- apply(X = analytic.data8[factor.names], \n                                      MARGIN = 2, FUN = as.factor)\n# analytic.data8[numeric.names] <- apply(X = analytic.data8[numeric.names], \n#                                        MARGIN = 2, FUN = \n#                                          function (x) as.numeric(as.character(x)))\n\n\n\n\nShow the code\nanalytic.data9 <- analytic.data8\nanalytic.data9$DMDBORN4[analytic.data9$DMDBORN4 == \"Don't Know\"] <- NA\n#analytic.data9 <- subset(analytic.data8, DMDBORN4 != \"Don't Know\")\ndim(analytic.data9)\n#> [1] 9254   32\n\nanalytic.data10 <- analytic.data9\nanalytic.data10$DMDEDUC2[analytic.data10$DMDEDUC2 == \"Don't Know\"] <- NA\n#analytic.data10 <- subset(analytic.data9, DMDEDUC2 != \"Don't Know\")\ndim(analytic.data10)\n#> [1] 9254   32\n\nanalytic.data11 <- analytic.data10\nanalytic.data11$DMDMARTL[analytic.data11$DMDMARTL == \"Don't Know\"] <- NA\nanalytic.data11$DMDMARTL[analytic.data11$DMDMARTL == \"Refused\"] <- NA\n# analytic.data11 <- subset(analytic.data10, DMDMARTL != \"Don't Know\" & DMDMARTL != \"Refused\")\ndim(analytic.data11)\n#> [1] 9254   32\n\n\nanalytic.data12 <- analytic.data11\nanalytic.data12$INDHHIN2[analytic.data12$INDHHIN2 == \"Don't Know\"] <- NA\nanalytic.data12$INDHHIN2[analytic.data12$INDHHIN2 == \"Refused\"] <- NA\nanalytic.data12$INDHHIN2[analytic.data12$INDHHIN2 == \"Under $20,000\"] <- NA\nanalytic.data12$INDHHIN2[analytic.data12$INDHHIN2 == \"$20,000 and Over\"] <- NA\n# analytic.data12 <- subset(analytic.data11, INDHHIN2 != \"Don't know\" & INDHHIN2 !=  \"Refused\" & INDHHIN2 != \"Under $20,000\" & INDHHIN2 != \"$20,000 and Over\" )\ndim(analytic.data12)\n#> [1] 9254   32\n\n#analytic.data11 <- subset(analytic.data10, ALQ130 != 777 & ALQ130 != 999 )\n#dim(analytic.data11) # this are listed as NA anyway\n\nanalytic.data13 <- analytic.data12\nanalytic.data13$PAQ605[analytic.data13$PAQ605 == \"Don't know\"] <- NA\nanalytic.data13$PAQ605[analytic.data13$PAQ605 == \"Refused\"] <- NA\n# analytic.data13 <- subset(analytic.data12, PAQ605 != \"Don't know\" & PAQ605 != \"Refused\")\ndim(analytic.data13)\n#> [1] 9254   32\n\nanalytic.data14 <- analytic.data13\nanalytic.data14$PAQ650[analytic.data14$PAQ650 == \"Don't know\"] <- NA\nanalytic.data14$PAQ650[analytic.data14$PAQ650 == \"Refused\"] <- NA\n# analytic.data14 <- subset(analytic.data13, PAQ650 != \"Don't Know\" & PAQ650 != \"Refused\")\ndim(analytic.data14)\n#> [1] 9254   32\n\nanalytic.data15 <- analytic.data14\nanalytic.data15$DIQ010[analytic.data15$DIQ010 == \"Don't know\"] <- NA\nanalytic.data15$DIQ010[analytic.data15$DIQ010 == \"Refused\"] <- NA\n# analytic.data15 <- subset(analytic.data14, DIQ010 != \"Don't Know\" & DIQ010 != \"Refused\")\ndim(analytic.data15)\n#> [1] 9254   32\n\n\n# analytic.data15$ALQ130[analytic.data15$ALQ130 > 100] <- NA\n# summary(analytic.data15$ALQ130)\ntable(analytic.data15$SMQ040,useNA = \"always\")\n#> \n#>  Every day Not at all  Some days       <NA> \n#>        805       1338        216       6895\ntable(analytic.data15$PAQ605,useNA = \"always\")\n#> \n#>   No  Yes <NA> \n#> 4461 1389 3404\ntable(analytic.data15$PAQ650,useNA = \"always\")\n#> \n#>   No  Yes <NA> \n#> 4422 1434 3398\ntable(analytic.data15$PAQ650,useNA = \"always\")\n#> \n#>   No  Yes <NA> \n#> 4422 1434 3398\n\n\n\n\nRecode values\nLet us recode the variables using the recode function:\n\n\nShow the code\nrequire(car)\n#> Loading required package: car\n#> Loading required package: carData\nanalytic.data15$RIDRETH3 <- recode(analytic.data15$RIDRETH3, \n                            \"c('Mexican American','Other Hispanic')='Hispanic'; \n                            'Non-Hispanic White'='White'; \n                            'Non-Hispanic Black'='Black';\n                            c('Non-Hispanic Asian',\n                               'Other Race - Including Multi-Rac')='Other';\n                               else=NA\")\nanalytic.data15$DMDEDUC2 <- recode(analytic.data15$DMDEDUC2, \n                            \"c('Some college or AA degree',\n                             'College graduate or above')='College'; \n                            c('9-11th grade (Includes 12th grad', \n                              'High school graduate/GED or equi')\n                               ='High.School'; \n                            'Less than 9th grade'='School';\n                               else=NA\")\nanalytic.data15$DMDMARTL <- recode(analytic.data15$DMDMARTL, \n                            \"c('Divorced','Separated','Widowed')\n                                ='Previously.married'; \n                            c('Living with partner', 'Married')\n                                ='Married'; \n                            'Never married'='Never.married';\n                               else=NA\")\nanalytic.data15$INDHHIN2 <- recode(analytic.data15$INDHHIN2, \n                            \"c('$ 0 to $ 4,999', '$ 5,000 to $ 9,999', \n                                 '$10,000 to $14,999', '$15,000 to $19,999', \n                                 '$20,000 to $24,999')='<25k';\n                            c('$25,000 to $34,999', '$35,000 to $44,999', \n                                 '$45,000 to $54,999') = 'Between.25kto54k';\n                            c('$55,000 to $64,999', '$65,000 to $74,999',\n                                 '$75,000 to $99,999')='Between.55kto99k';\n                            '$100,000 and Over'= 'Over100k';\n                               else=NA\")\nanalytic.data15$SMQ040 <- recode(analytic.data15$SMQ040, \n                            \"'Every day'='Every.day';\n                            'Not at all'='Not.at.all';\n                            'Some days'='Some.days';\n                               else=NA\")\nanalytic.data15$DIQ010 <- recode(analytic.data15$DIQ010, \n                            \"'No'='No';\n                            c('Yes', 'Borderline')='Yes';\n                               else=NA\")\n\n\n\n\nCheck missingness\n\n\n\n\n\n\nTip\n\n\n\nWe can use the plot_missing function to plot the profile of missing values, e.g., the percentage of missing per variable\n\n\n\n\nShow the code\nrequire(DataExplorer)\n#> Loading required package: DataExplorer\n#> Warning: package 'DataExplorer' was built under R version 4.3.1\nplot_missing(analytic.data15)\n\n\n\n\n\n\n\nCheck data summaries\n\n\nShow the code\nnames(analytic.data15)\n#>  [1] \"SEQN\"     \"RIAGENDR\" \"RIDAGEYR\" \"DMDBORN4\" \"RIDRETH3\" \"DMDEDUC2\"\n#>  [7] \"DMDMARTL\" \"INDHHIN2\" \"WTMEC2YR\" \"SDMVPSU\"  \"SDMVSTRA\" \"BPXDI1\"  \n#> [13] \"BPXSY1\"   \"BMXWT\"    \"BMXHT\"    \"BMXBMI\"   \"BMXWAIST\" \"SMQ040\"  \n#> [19] \"LBXTC\"    \"LBDTCSI\"  \"LBXSTR\"   \"LBXSUA\"   \"LBXSTP\"   \"LBXSTB\"  \n#> [25] \"LBXSPH\"   \"LBXSNASI\" \"LBXSKSI\"  \"LBXSGB\"   \"LBXSCA\"   \"PAQ605\"  \n#> [31] \"PAQ650\"   \"DIQ010\"\nnames(analytic.data15) <- c(\"ID\", \"gender\", \"age\", \"born\", \"race\", \"education\", \n\"married\", \"income\", \"weight\", \"psu\", \"strata\", \"diastolicBP\", \n\"systolicBP\", \"bodyweight\", \"bodyheight\", \"bmi\", \"waist\", \"smoke\", \n\"cholesterol\", \"cholesterolM2\", \"triglycerides\", \n\"uric.acid\", \"protein\", \"bilirubin\", \"phosphorus\", \"sodium\", \n\"potassium\", \"globulin\", \"calcium\", \"physical.work\", \n\"physical.recreational\",\"diabetes\")\nrequire(\"tableone\")\n#> Loading required package: tableone\nCreateTableOne(data = analytic.data15, includeNA = TRUE)\n#>                                      \n#>                                       Overall            \n#>   n                                       9254           \n#>   ID (mean (SD))                      98329.50 (2671.54) \n#>   gender = Male (%)                       4557 (49.2)    \n#>   age (mean (SD))                        51.50 (17.81)   \n#>   born (%)                                               \n#>      Born in 50 US states or Washingt     7303 (78.9)    \n#>      Others                               1948 (21.1)    \n#>      Refused                                 2 ( 0.0)    \n#>      NA                                      1 ( 0.0)    \n#>   race (%)                                               \n#>      Black                                2115 (22.9)    \n#>      Hispanic                             2187 (23.6)    \n#>      Other                                1802 (19.5)    \n#>      White                                3150 (34.0)    \n#>   education (%)                                          \n#>      College                              3114 (33.7)    \n#>      High.School                          1963 (21.2)    \n#>      School                                479 ( 5.2)    \n#>      NA                                   3698 (40.0)    \n#>   married (%)                                            \n#>      Married                              3252 (35.1)    \n#>      Never.married                        1006 (10.9)    \n#>      Previously.married                   1305 (14.1)    \n#>      NA                                   3691 (39.9)    \n#>   income (%)                                             \n#>      <25k                                 1998 (21.6)    \n#>      Between.25kto54k                     2460 (26.6)    \n#>      Between.55kto99k                     1843 (19.9)    \n#>      Over100k                             1624 (17.5)    \n#>      NA                                   1329 (14.4)    \n#>   weight (mean (SD))                  34670.71 (43344.00)\n#>   psu (mean (SD))                         1.52 (0.50)    \n#>   strata (mean (SD))                    140.97 (4.20)    \n#>   diastolicBP (mean (SD))                67.84 (16.36)   \n#>   systolicBP (mean (SD))                121.33 (19.98)   \n#>   bodyweight (mean (SD))                 65.14 (32.89)   \n#>   bodyheight (mean (SD))                156.59 (22.26)   \n#>   bmi (mean (SD))                        26.58 (8.26)    \n#>   waist (mean (SD))                      89.93 (22.81)   \n#>   smoke (%)                                              \n#>      Every.day                             805 ( 8.7)    \n#>      Not.at.all                           1338 (14.5)    \n#>      Some.days                             216 ( 2.3)    \n#>      NA                                   6895 (74.5)    \n#>   cholesterol (mean (SD))               179.89 (40.60)   \n#>   cholesterolM2 (mean (SD))               4.65 (1.05)    \n#>   triglycerides (mean (SD))             137.44 (109.13)  \n#>   uric.acid (mean (SD))                   5.40 (1.48)    \n#>   protein (mean (SD))                     7.17 (0.44)    \n#>   bilirubin (mean (SD))                   0.46 (0.28)    \n#>   phosphorus (mean (SD))                  3.66 (0.59)    \n#>   sodium (mean (SD))                    140.32 (2.75)    \n#>   potassium (mean (SD))                   4.09 (0.36)    \n#>   globulin (mean (SD))                    3.09 (0.43)    \n#>   calcium (mean (SD))                     9.32 (0.37)    \n#>   physical.work (%)                                      \n#>      No                                   4461 (48.2)    \n#>      Yes                                  1389 (15.0)    \n#>      NA                                   3404 (36.8)    \n#>   physical.recreational (%)                              \n#>      No                                   4422 (47.8)    \n#>      Yes                                  1434 (15.5)    \n#>      NA                                   3398 (36.7)    \n#>   diabetes (%)                                           \n#>      No                                   7816 (84.5)    \n#>      Yes                                  1077 (11.6)    \n#>      NA                                    361 ( 3.9)\n\n\n\n\nCreate fictitious data (missing = ‘No’)\n\n\nShow the code\nfictitious.data <- analytic.data15\n# the following is the worst possible solution!\nfictitious.data$smoke[is.na(fictitious.data$smoke)] <- \"Not.at.all\"\n#fictitious.data$alcohol[is.na(fictitious.data$alcohol)] <- 0\ntable(fictitious.data$smoke)\n#> \n#>  Every.day Not.at.all  Some.days \n#>        805       8233        216\n#summary(fictitious.data$alcohol)\nfictitious.data <- as.data.frame(na.omit(fictitious.data))\ndim(fictitious.data)\n#> [1] 3617   32\n\n\n\n\nCreate complete case data (for now)\n\n\nShow the code\nanalytic.with.miss <- analytic.data15\nanalytic.with.miss$cholesterol.bin <- ifelse(analytic.with.miss$cholesterol <200, 1,0)\nanalytic <- as.data.frame(na.omit(analytic.with.miss))\ndim(analytic)\n#> [1] 1562   33\n\n\n\n\nShow the code\n# removing values with excessive missing values\n# analytic.data15$ALQ130 <- NULL\n# analytic1 <- as.data.frame(na.omit(analytic.data15))\n# dim(analytic1)\n# analytic.data15$smoke <- NULL\n# analytic2 <- as.data.frame(na.omit(analytic.data15))\n# dim(analytic2)\n\n\n\n\nShow the code\nrequire(\"tableone\")\nCreateTableOne(data = analytic, includeNA = TRUE)\n#>                                  \n#>                                   Overall            \n#>   n                                   1562           \n#>   ID (mean (SD))                  98344.21 (2697.76) \n#>   gender = Male (%)                    959 (61.4)    \n#>   age (mean (SD))                    53.18 (17.18)   \n#>   born = Others (%)                    299 (19.1)    \n#>   race (%)                                           \n#>      Black                             324 (20.7)    \n#>      Hispanic                          284 (18.2)    \n#>      Other                             228 (14.6)    \n#>      White                             726 (46.5)    \n#>   education (%)                                      \n#>      College                           806 (51.6)    \n#>      High.School                       658 (42.1)    \n#>      School                             98 ( 6.3)    \n#>   married (%)                                        \n#>      Married                           921 (59.0)    \n#>      Never.married                     228 (14.6)    \n#>      Previously.married                413 (26.4)    \n#>   income (%)                                         \n#>      <25k                              484 (31.0)    \n#>      Between.25kto54k                  520 (33.3)    \n#>      Between.55kto99k                  331 (21.2)    \n#>      Over100k                          227 (14.5)    \n#>   weight (mean (SD))              48538.53 (54106.24)\n#>   psu (mean (SD))                     1.48 (0.50)    \n#>   strata (mean (SD))                141.18 (4.07)    \n#>   diastolicBP (mean (SD))            72.06 (14.17)   \n#>   systolicBP (mean (SD))            127.06 (19.11)   \n#>   bodyweight (mean (SD))             85.66 (22.41)   \n#>   bodyheight (mean (SD))            168.96 (9.30)    \n#>   bmi (mean (SD))                    29.96 (7.33)    \n#>   waist (mean (SD))                 102.98 (17.15)   \n#>   smoke (%)                                          \n#>      Every.day                         530 (33.9)    \n#>      Not.at.all                        903 (57.8)    \n#>      Some.days                         129 ( 8.3)    \n#>   cholesterol (mean (SD))           188.77 (43.51)   \n#>   cholesterolM2 (mean (SD))           4.88 (1.13)    \n#>   triglycerides (mean (SD))         154.71 (123.00)  \n#>   uric.acid (mean (SD))               5.62 (1.53)    \n#>   protein (mean (SD))                 7.09 (0.43)    \n#>   bilirubin (mean (SD))               0.46 (0.27)    \n#>   phosphorus (mean (SD))              3.53 (0.54)    \n#>   sodium (mean (SD))                140.14 (2.83)    \n#>   potassium (mean (SD))               4.10 (0.38)    \n#>   globulin (mean (SD))                3.03 (0.44)    \n#>   calcium (mean (SD))                 9.29 (0.37)    \n#>   physical.work = Yes (%)              476 (30.5)    \n#>   physical.recreational = Yes (%)      290 (18.6)    \n#>   diabetes = Yes (%)                   330 (21.1)    \n#>   cholesterol.bin (mean (SD))         0.63 (0.48)\n\n\n\n\n\nRegression\n\nWrong way to define design\n\n\nTo get population-level estimate, we must appropriately utilize the survey features.\nSee the section on Analyzing Subgroups in NHANES\n\n\nShow the code\nw.design.wrong <- svydesign(id=~psu, \n                       strata=~strata, \n                       weights=~weight, \n                      data=analytic, # already subsetted data\n                      nest = TRUE)\nsummary(weights(w.design.wrong))\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>    4580   16038   29032   48539   55585  419763\n\n\n\n\nWrong analysis\n\n\nShow the code\nout.formula <- as.formula(cholesterol.bin ~ diabetes + \n                            gender + race + education + \n                            married + income + age + \n                            diastolicBP + systolicBP + bmi)\nfit.wrong <- svyglm(out.formula,\n               design = w.design.wrong, \n               family = binomial(logit))\n#> Warning in eval(family$initialize): non-integer #successes in a binomial glm!\npublish(fit.wrong)\n#>     Variable              Units OddsRatio       CI.95 p-value \n#>     diabetes                 No       Ref                     \n#>                             Yes      1.97 [1.19;3.28]      NA \n#>       gender             Female       Ref                     \n#>                            Male      1.57 [1.15;2.16]      NA \n#>         race              Black       Ref                     \n#>                        Hispanic      0.77 [0.53;1.12]      NA \n#>                           Other      0.76 [0.51;1.14]      NA \n#>                           White      0.91 [0.59;1.41]      NA \n#>    education            College       Ref                     \n#>                     High.School      1.12 [0.89;1.42]      NA \n#>                          School      0.88 [0.48;1.64]      NA \n#>      married            Married       Ref                     \n#>                   Never.married      1.38 [0.83;2.31]      NA \n#>              Previously.married      1.17 [1.01;1.37]      NA \n#>       income               <25k       Ref                     \n#>                Between.25kto54k      0.93 [0.65;1.34]      NA \n#>                Between.55kto99k      0.91 [0.56;1.46]      NA \n#>                        Over100k      0.58 [0.37;0.91]      NA \n#>          age                         0.99 [0.98;1.00]      NA \n#>  diastolicBP                         0.99 [0.97;1.00]      NA \n#>   systolicBP                         0.99 [0.98;1.00]      NA \n#>          bmi                         0.99 [0.97;1.01]      NA\n\n\n\n\nDefine design and subset\n\nSee the section on How to Request Taylor Series Linearization to Calculate Variance in NHANES using R\n\n\n\nShow the code\nanalytic.data <- analytic\nanalytic.with.miss$miss <- 1\nanalytic.with.miss$ID[1:10] # full data\n#>  [1] 93703 93704 93705 93706 93707 93708 93709 93710 93711 93712\nanalytic.data$ID[1:10] # complete case\n#>  [1] 93709 93713 93715 93716 93726 93729 93738 93742 93752 93755\nanalytic.with.miss$ID[analytic.with.miss$ID %in% analytic.data$ID][1:10]\n#>  [1] 93709 93713 93715 93716 93726 93729 93738 93742 93752 93755\nanalytic.with.miss$miss[analytic.with.miss$ID %in% analytic.data$ID] <- 0\ntable(analytic.with.miss$miss)\n#> \n#>    0    1 \n#> 1562 7692\n\n\n\n\nShow the code\nanalytic.with.miss$strata<- as.factor(analytic.with.miss$strata)\nanalytic.with.miss$psu<- as.factor(analytic.with.miss$psu)\nw.design0 <- svydesign(id=~psu, \n                       strata=~strata, \n                       weights=~weight, \n                      data=analytic.with.miss,\n                      nest = TRUE)\nsummary(weights(w.design0))\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>       0   12347   21060   34671   37562  419763\nw.designX <- subset(w.design0, miss == 0)\nsummary(weights(w.designX))\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>    4580   16038   29032   48539   55585  419763\nw.designX$df.residual\n#> NULL\nnames(w.designX)\n#> [1] \"cluster\"    \"strata\"     \"has.strata\" \"prob\"       \"allprob\"   \n#> [6] \"call\"       \"variables\"  \"fpc\"        \"pps\"\n\n\n\n\nRegression analysis\n\n\nShow the code\nout.formula <- as.formula(cholesterol.bin ~ diabetes + \n                            gender + race + education + \n                            married + income + age)\nfit1 <- svyglm(out.formula,\n               design = w.designX, \n               family = binomial(logit))\n# default = denominator degrees of freedom for Wald tests?\n\n\n\n\nShow the code\nrequire(Publish)\n# notice that the conclusion from CI.95  p-value are contradictory\n# For example: gender/Male OR 1.51 [95% CI: 1.10;2.07] but p-value is 0.1233\npublish(fit1)\n#>   Variable              Units OddsRatio       CI.95  p-value \n#>   diabetes                 No       Ref                      \n#>                           Yes      1.93 [1.19;3.11]   0.1156 \n#>     gender             Female       Ref                      \n#>                          Male      1.51 [1.10;2.07]   0.1233 \n#>       race              Black       Ref                      \n#>                      Hispanic      0.81 [0.58;1.14]   0.3492 \n#>                         Other      0.84 [0.56;1.25]   0.4792 \n#>                         White      1.01 [0.65;1.57]   0.9626 \n#>  education            College       Ref                      \n#>                   High.School      1.08 [0.87;1.34]   0.5533 \n#>                        School      0.94 [0.51;1.71]   0.8524 \n#>    married            Married       Ref                      \n#>                 Never.married      1.27 [0.74;2.17]   0.4759 \n#>            Previously.married      1.22 [1.04;1.45]   0.1416 \n#>     income               <25k       Ref                      \n#>              Between.25kto54k      0.96 [0.69;1.35]   0.8523 \n#>              Between.55kto99k      0.96 [0.60;1.53]   0.8833 \n#>                      Over100k      0.63 [0.42;0.94]   0.1534 \n#>        age                         0.99 [0.98;1.00]   0.1430\n\n\n\n\nRegression analysis with more covariates\n\n\nShow the code\nout.formula <- as.formula(cholesterol.bin ~ diabetes + \n                            gender + race + education + \n                            married + income + age + \n                            diastolicBP + systolicBP + bmi)\nfit1 <- svyglm(out.formula,\n               design = w.designX, \n               family = binomial(logit))\n# default = denominator degrees of freedom for Wald tests?\n\n\n\n\nShow the code\nsummary(fit1)$coefficients\n#>                               Estimate  Std. Error    t value Pr(>|t|)\n#> (Intercept)                3.106465338 0.697974276  4.4506874      NaN\n#> diabetesYes                0.678604077 0.259437156  2.6156781      NaN\n#> genderMale                 0.453611261 0.160323265  2.8293539      NaN\n#> raceHispanic              -0.258611734 0.188973280 -1.3685095      NaN\n#> raceOther                 -0.270817665 0.204596301 -1.3236684      NaN\n#> raceWhite                 -0.090932728 0.222375697 -0.4089149      NaN\n#> educationHigh.School       0.116945105 0.120722635  0.9687090      NaN\n#> educationSchool           -0.122709225 0.314595121 -0.3900544      NaN\n#> marriedNever.married       0.324280209 0.261001765  1.2424445      NaN\n#> marriedPreviously.married  0.160482971 0.077029207  2.0834042      NaN\n#> incomeBetween.25kto54k    -0.071657706 0.186094076 -0.3850617      NaN\n#> incomeBetween.55kto99k    -0.095827891 0.243278646 -0.3939018      NaN\n#> incomeOver100k            -0.543216076 0.227983240 -2.3827018      NaN\n#> age                       -0.008356187 0.006120448 -1.3652901      NaN\n#> diastolicBP               -0.011117437 0.007638687 -1.4554121      NaN\n#> systolicBP                -0.011209437 0.005535507 -2.0250065      NaN\n#> bmi                       -0.007001220 0.010786766 -0.6490564      NaN\nrequire(Publish)\npublish(fit1)\n#>     Variable              Units OddsRatio       CI.95 p-value \n#>     diabetes                 No       Ref                     \n#>                             Yes      1.97 [1.19;3.28]      NA \n#>       gender             Female       Ref                     \n#>                            Male      1.57 [1.15;2.16]      NA \n#>         race              Black       Ref                     \n#>                        Hispanic      0.77 [0.53;1.12]      NA \n#>                           Other      0.76 [0.51;1.14]      NA \n#>                           White      0.91 [0.59;1.41]      NA \n#>    education            College       Ref                     \n#>                     High.School      1.12 [0.89;1.42]      NA \n#>                          School      0.88 [0.48;1.64]      NA \n#>      married            Married       Ref                     \n#>                   Never.married      1.38 [0.83;2.31]      NA \n#>              Previously.married      1.17 [1.01;1.37]      NA \n#>       income               <25k       Ref                     \n#>                Between.25kto54k      0.93 [0.65;1.34]      NA \n#>                Between.55kto99k      0.91 [0.56;1.46]      NA \n#>                        Over100k      0.58 [0.37;0.91]      NA \n#>          age                         0.99 [0.98;1.00]      NA \n#>  diastolicBP                         0.99 [0.97;1.00]      NA \n#>   systolicBP                         0.99 [0.98;1.00]      NA \n#>          bmi                         0.99 [0.97;1.01]      NA\n\n\n\n\n\nSE calculation\n\nCurrent default option\n\n\nShow the code\nsummary(fit1)$coefficients\n#>                               Estimate  Std. Error    t value Pr(>|t|)\n#> (Intercept)                3.106465338 0.697974276  4.4506874      NaN\n#> diabetesYes                0.678604077 0.259437156  2.6156781      NaN\n#> genderMale                 0.453611261 0.160323265  2.8293539      NaN\n#> raceHispanic              -0.258611734 0.188973280 -1.3685095      NaN\n#> raceOther                 -0.270817665 0.204596301 -1.3236684      NaN\n#> raceWhite                 -0.090932728 0.222375697 -0.4089149      NaN\n#> educationHigh.School       0.116945105 0.120722635  0.9687090      NaN\n#> educationSchool           -0.122709225 0.314595121 -0.3900544      NaN\n#> marriedNever.married       0.324280209 0.261001765  1.2424445      NaN\n#> marriedPreviously.married  0.160482971 0.077029207  2.0834042      NaN\n#> incomeBetween.25kto54k    -0.071657706 0.186094076 -0.3850617      NaN\n#> incomeBetween.55kto99k    -0.095827891 0.243278646 -0.3939018      NaN\n#> incomeOver100k            -0.543216076 0.227983240 -2.3827018      NaN\n#> age                       -0.008356187 0.006120448 -1.3652901      NaN\n#> diastolicBP               -0.011117437 0.007638687 -1.4554121      NaN\n#> systolicBP                -0.011209437 0.005535507 -2.0250065      NaN\n#> bmi                       -0.007001220 0.010786766 -0.6490564      NaN\n\n\nAs we can see no p-values for the coefficients. Let us estimate the p-values based on the Normal distribution.\n\n\nTests based on a Normal distribution\n\n\nShow the code\n# p-value\nsummary(fit1, df.resid = Inf)\n#> \n#> Call:\n#> svyglm(formula = out.formula, design = w.designX, family = binomial(logit))\n#> \n#> Survey design:\n#> subset(w.design0, miss == 0)\n#> \n#> Coefficients:\n#>                            Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)                3.106465   0.697974   4.451 8.56e-06 ***\n#> diabetesYes                0.678604   0.259437   2.616  0.00891 ** \n#> genderMale                 0.453611   0.160323   2.829  0.00466 ** \n#> raceHispanic              -0.258612   0.188973  -1.369  0.17115    \n#> raceOther                 -0.270818   0.204596  -1.324  0.18561    \n#> raceWhite                 -0.090933   0.222376  -0.409  0.68260    \n#> educationHigh.School       0.116945   0.120723   0.969  0.33269    \n#> educationSchool           -0.122709   0.314595  -0.390  0.69650    \n#> marriedNever.married       0.324280   0.261002   1.242  0.21407    \n#> marriedPreviously.married  0.160483   0.077029   2.083  0.03721 *  \n#> incomeBetween.25kto54k    -0.071658   0.186094  -0.385  0.70019    \n#> incomeBetween.55kto99k    -0.095828   0.243279  -0.394  0.69365    \n#> incomeOver100k            -0.543216   0.227983  -2.383  0.01719 *  \n#> age                       -0.008356   0.006120  -1.365  0.17216    \n#> diastolicBP               -0.011117   0.007639  -1.455  0.14556    \n#> systolicBP                -0.011209   0.005536  -2.025  0.04287 *  \n#> bmi                       -0.007001   0.010787  -0.649  0.51630    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Zero or negative residual df; p-values not defined\n#> \n#> (Dispersion parameter for binomial family taken to be 1.000944)\n#> \n#> Number of Fisher Scoring iterations: 4\nround(summary(fit1, df.resid = Inf)$coefficients[,4] ,3)  \n#>               (Intercept)               diabetesYes                genderMale \n#>                     0.000                     0.009                     0.005 \n#>              raceHispanic                 raceOther                 raceWhite \n#>                     0.171                     0.186                     0.683 \n#>      educationHigh.School           educationSchool      marriedNever.married \n#>                     0.333                     0.696                     0.214 \n#> marriedPreviously.married    incomeBetween.25kto54k    incomeBetween.55kto99k \n#>                     0.037                     0.700                     0.694 \n#>            incomeOver100k                       age               diastolicBP \n#>                     0.017                     0.172                     0.146 \n#>                systolicBP                       bmi \n#>                     0.043                     0.516\n# CI\nround(exp(confint(fit1, ddf = Inf)),2)\n#>                           2.5 % 97.5 %\n#> (Intercept)                5.69  87.75\n#> diabetesYes                1.19   3.28\n#> genderMale                 1.15   2.16\n#> raceHispanic               0.53   1.12\n#> raceOther                  0.51   1.14\n#> raceWhite                  0.59   1.41\n#> educationHigh.School       0.89   1.42\n#> educationSchool            0.48   1.64\n#> marriedNever.married       0.83   2.31\n#> marriedPreviously.married  1.01   1.37\n#> incomeBetween.25kto54k     0.65   1.34\n#> incomeBetween.55kto99k     0.56   1.46\n#> incomeOver100k             0.37   0.91\n#> age                        0.98   1.00\n#> diastolicBP                0.97   1.00\n#> systolicBP                 0.98   1.00\n#> bmi                        0.97   1.01\n\n\n\n\n\nResidual df = PSUs count - strata count\n\nSee section 3.1 of Lumley and Scott (2017)\nSee NHANES Linked Data Tutorial (CDC 2023)\n\n\n\nLumley and Scott (2017)\n\nCDC (2023)\n\n\n\nShow the code\nns <- length(unique(analytic.with.miss$strata)) # number of strata\nlength(unique(analytic.with.miss$psu)) # number of clusters per strata\n#> [1] 2\nnc <- length(unique(analytic.with.miss$strata))*\n  length(unique(analytic.with.miss$psu)) # number of clusters in total\nnc - ns\n#> [1] 15\ndegf(w.designX)\n#> [1] 15\n# p-value\nsummary(fit1, df.resid = degf(w.designX))\n#> \n#> Call:\n#> svyglm(formula = out.formula, design = w.designX, family = binomial(logit))\n#> \n#> Survey design:\n#> subset(w.design0, miss == 0)\n#> \n#> Coefficients:\n#>                            Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)                3.106465   0.697974   4.451 0.000467 ***\n#> diabetesYes                0.678604   0.259437   2.616 0.019481 *  \n#> genderMale                 0.453611   0.160323   2.829 0.012685 *  \n#> raceHispanic              -0.258612   0.188973  -1.369 0.191301    \n#> raceOther                 -0.270818   0.204596  -1.324 0.205433    \n#> raceWhite                 -0.090933   0.222376  -0.409 0.688381    \n#> educationHigh.School       0.116945   0.120723   0.969 0.348052    \n#> educationSchool           -0.122709   0.314595  -0.390 0.701979    \n#> marriedNever.married       0.324280   0.261002   1.242 0.233146    \n#> marriedPreviously.married  0.160483   0.077029   2.083 0.054736 .  \n#> incomeBetween.25kto54k    -0.071658   0.186094  -0.385 0.705597    \n#> incomeBetween.55kto99k    -0.095828   0.243279  -0.394 0.699196    \n#> incomeOver100k            -0.543216   0.227983  -2.383 0.030850 *  \n#> age                       -0.008356   0.006120  -1.365 0.192289    \n#> diastolicBP               -0.011117   0.007639  -1.455 0.166164    \n#> systolicBP                -0.011209   0.005536  -2.025 0.061045 .  \n#> bmi                       -0.007001   0.010787  -0.649 0.526116    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Zero or negative residual df; p-values not defined\n#> \n#> (Dispersion parameter for binomial family taken to be 1.000944)\n#> \n#> Number of Fisher Scoring iterations: 4\nround(summary(fit1, \n              df.resid = degf(w.designX))$coefficients[,4] ,3)  \n#>               (Intercept)               diabetesYes                genderMale \n#>                     0.000                     0.019                     0.013 \n#>              raceHispanic                 raceOther                 raceWhite \n#>                     0.191                     0.205                     0.688 \n#>      educationHigh.School           educationSchool      marriedNever.married \n#>                     0.348                     0.702                     0.233 \n#> marriedPreviously.married    incomeBetween.25kto54k    incomeBetween.55kto99k \n#>                     0.055                     0.706                     0.699 \n#>            incomeOver100k                       age               diastolicBP \n#>                     0.031                     0.192                     0.166 \n#>                systolicBP                       bmi \n#>                     0.061                     0.526\n# CI\nround(exp(confint(fit1, ddf = degf(w.designX))),2)\n#>                           2.5 % 97.5 %\n#> (Intercept)                5.05  98.91\n#> diabetesYes                1.13   3.43\n#> genderMale                 1.12   2.22\n#> raceHispanic               0.52   1.16\n#> raceOther                  0.49   1.18\n#> raceWhite                  0.57   1.47\n#> educationHigh.School       0.87   1.45\n#> educationSchool            0.45   1.73\n#> marriedNever.married       0.79   2.41\n#> marriedPreviously.married  1.00   1.38\n#> incomeBetween.25kto54k     0.63   1.38\n#> incomeBetween.55kto99k     0.54   1.53\n#> incomeOver100k             0.36   0.94\n#> age                        0.98   1.00\n#> diastolicBP                0.97   1.01\n#> systolicBP                 0.98   1.00\n#> bmi                        0.97   1.02\n\n\n\n\nSaving data\n\n\nShow the code\n# getwd()\nsave(analytic.with.miss, analytic, file=\"Data/researchquestion/NHANES17.RData\")\n\n\n\n\nReferences\n\n\n\n\n\n\nCDC. 2023. “Estimating Variance, Analyzing Subgroups and Calculating Degrees of Freedom for Performing Statistical Tests and Calculating Confidence Intervals.” https://www.cdc.gov/nchs/tutorials/nhanes-cms/variance/variance/index.htm.\n\n\nLumley, Thomas, and Alastair Scott. 2017. “Fitting Regression Models to Survey Data.” Statistical Science, 265–78.\n\n\nPeters, Junenette L, M Patricia Fabian, and Jonathan I Levy. 2014. “Combined Impact of Lead, Cadmium, Polychlorinated Biphenyls and Non-Chemical Risk Factors on Blood Pressure in NHANES.” Environmental Research 132: 93–99."
  },
  {
    "objectID": "researchquestionF.html",
    "href": "researchquestionF.html",
    "title": "Functions for research question",
    "section": "",
    "text": "The list of new R functions introduced in this Research question lab component are below:\n\n\n\n\n \n  \n    Function_name \n    Package_name \n    Use \n  \n \n\n  \n    as.data.frame \n    base \n    To force an object to a data frame \n  \n  \n    as.formula \n    base/stats \n    To specify a model formula, e.g., formula for an outcome model \n  \n  \n    confint \n    base/stats \n    To estimate the confidence interval for model parameters \n  \n  \n    degf \n    survey \n    To see the degrees of freedom for a survey design object \n  \n  \n    describe \n    DescTools \n    To see the summary statistics of variables \n  \n  \n    exp \n    base \n    Exponentials \n  \n  \n    lapply \n    base \n    To apply a function over a list, e.g., to see the summary of a list of variables or to convert a list of categorical variables to factor variables. A similar function is `sapply`. lapply and sapply have the same functionality. The main difference is that sapply attempts to convert the result into a vector or matrix, while lapply returns a list. \n  \n  \n    length \n    base \n    To see the length of an object, e.g., number of elements/observations of a variable \n  \n  \n    plot_missing \n    DataExplorer \n    To plot the profile of missing values, e.g., the percentage of missing per variable \n  \n  \n    publish \n    Publish \n    To show/publish regression tables \n  \n  \n    Reduce \n    base \n    To combine multiple objects, e.g., datasets \n  \n  \n    round \n    base \n    To round numeric values \n  \n  \n    saveRDS \n    base \n    To save a single R object. Similarly, readDRS will read an R object \n  \n  \n    skim \n    skimr \n    To see the summary statistics of variables \n  \n  \n    svydesign \n    survey \n    To create a design for the survey data analysis \n  \n  \n    svyglm \n    survey \n    To run design-adjusted generalized linear models \n  \n  \n    unique \n    base \n    To see the number of unique elements \n  \n  \n    weights \n    base/stats \n    To extract model weights, e.g., see the weights from a pre-specified survey design \n  \n\n\n\n\n\nFor more information, visit the resources mentioned earlier."
  },
  {
    "objectID": "researchquestionQ.html",
    "href": "researchquestionQ.html",
    "title": "Quiz on research question",
    "section": "",
    "text": "Downloading the File:\n\nNavigate to the link: See here.\nRight-click on the link and select “Save link as…” from the dropdown menu.\nAlternatively click here for downloading the quizzes on data wrangling.\nChoose a destination folder on your computer where you’d like to save the file (e.g., Desktop). Remember this location, as you’ll need to navigate to it later.\n\nSetting Up RStudio:\n\nIf you don’t have RStudio installed, see the download link in here.\nLaunch RStudio after installing.\n\nInstalling Necessary R Packages:\n\nBefore running the R Markdown file, ensure you have the required packages. In RStudio’s console (located at the bottom left by default), enter the following commands to install them:\ninstall.packages(\"learnr\")\ninstall.packages(\"xfun\")\n\nOpening and Running the File:\n\nIn RStudio, go to File > Open File....\nNavigate to the folder where you saved the Rmd file and select it to open.\nOnce the file is open in RStudio, you’ll see a “Run Document” button (green) at the top of the script editor. Click on it to run the R Markdown Quiz file."
  }
]