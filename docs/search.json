[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OER: Advanced Epidemiological Methods",
    "section": "",
    "text": "The Project\nWelcome to a place crafted to bridge a unique gap in the health research world. This website offers valuable resources for those who are taking their first steps into health research and advanced statistics. Even if you’re familiar with health research, but advanced statistical methods seem daunting, you’re in the right place. Here, we offer:\nThis hub is a part of an open educational initiative, meaning it’s available to everyone. We hope to uplift the standard of health research methodology through this endeavor.\nWe’re on a mission to:"
  },
  {
    "objectID": "index.html#dive-into-our-modules",
    "href": "index.html#dive-into-our-modules",
    "title": "OER: Advanced Epidemiological Methods",
    "section": "Dive into Our Modules",
    "text": "Dive into Our Modules\nEmbark on a journey through 10 core learning modules, including one introductory module about R:\n\n\n\n\n \n  \n    Module \n    Topics \n    Descriptions \n  \n \n\n  \n    0 \n    R Data Wrangling \n    Get to know R. \n  \n  \n    1 \n    Survey Data Resources \n    Understand and source reliable national survey data. \n  \n  \n    2 \n    Crafting Data for Research \n    Customize data to your research query. \n  \n  \n    3 \n    Grasping Confounding \n    Delve into the concept and its implications. \n  \n  \n    4 \n    Adjustment Techniques \n    Adjusting for covariates in a multivariate analysis. \n  \n  \n    5 \n    Complex Survey Analysis \n    Handle intricate data sets. \n  \n  \n    6 \n    Missing Data \n    Understand and tackle gaps in your data. \n  \n  \n    7 \n    Propensity Score Analysis \n    Dive deeper into advanced analyses. \n  \n  \n    8 \n    Reporting Your Analysis \n    Guidelines to share your findings. \n  \n  \n    9 \n    Machine Learning \n    Introduction to key concepts, algorithms, and applications. \n  \n  \n    10 \n    Role of Machine Learning in Causal Inference \n    Discusses the potential pitfalls and challenges in merging machine learning with causal inference, and a way forward."
  },
  {
    "objectID": "index.html#how-our-content-is-presented",
    "href": "index.html#how-our-content-is-presented",
    "title": "OER: Advanced Epidemiological Methods",
    "section": "How Our Content is Presented",
    "text": "How Our Content is Presented\nAll our resources are hosted on an easy-to-access GitHub page. The format? Engaging text, reproducible software codes, clear analysis outputs, and crisp videos that distill complex topics. And don’t miss our quiz section at the end of each module for a quick self-check on what you’ve learned."
  },
  {
    "objectID": "index.html#open-copyright-license",
    "href": "index.html#open-copyright-license",
    "title": "OER: Advanced Epidemiological Methods",
    "section": "Open Copyright License",
    "text": "Open Copyright License\nCC-BY"
  },
  {
    "objectID": "index.html#contributor-list",
    "href": "index.html#contributor-list",
    "title": "OER: Advanced Epidemiological Methods",
    "section": "Contributor list",
    "text": "Contributor list\n\n\n\n\n\n\nTip\n\n\n\nDive into this captivating content, brought to life with the generous support of the UBC OER Fund Implementation Grant and further supported by UBC SPPH. The foundation of this content traces back to the PI’s work over five years while instructing SPPH 604 (2018-2022). That knowledge have now transformed into an open educational resource, thanks to this grant. Meet the innovative minds behind the grant proposal below.\n\n\n\n\n\n\n \n  \n    Role \n    Team_Member \n    Affiliation \n  \n \n\n  \n    Principal Applicant (PI) \n    Mohammad Ehsanul Karim \n    UBC Department of Forest Resources Management \n  \n  \n    Co-applicant (Co-I) \n    Dr. Suborna Ahmed \n    UBC Department of Forest Resources Management \n  \n  \n    Trainee co-applicants \n    Belal Hossain \n    UBC School of Population and Public Health \n  \n  \n     \n    Fardowsa Yusuf \n    UBC School of Population and Public Health \n  \n  \n     \n    Hanna Frank \n    UBC School of Population and Public Health \n  \n  \n     \n    Dr. Michael Asamoah-Boaheng \n    UBC Department of Emergency Medicine \n  \n  \n     \n    Chuyi (Astra) Zheng \n    UBC Faculty of Arts"
  },
  {
    "objectID": "wrangling.html#description",
    "href": "wrangling.html#description",
    "title": "Data wrangling",
    "section": "Description",
    "text": "Description\nTutorials in this chapter offer step-by-step instructions and code examples to help you understand and implement various data manipulation and import techniques in R.\n\nR Basics\nThis tutorial introduces the basics of R programming. It covers topics such as setting up R and RStudio, using R as a calculator, creating variables, working with vectors, plotting data, and accessing help resources.\n\n\nR Data Types\nThis tutorial covers three primary data structures in R: matrices, lists, and data frames. Matrices are two-dimensional arrays with elements of the same type, and their manipulation includes reshaping and combining. Lists in R are versatile collections that can store various R objects, including matrices. Data frames, on the other hand, are akin to matrices but permit columns of diverse data types. The tutorial offers guidance on creating, modifying, and merging data frames and checking their dimensions.\n\n\nAutomating Tasks\nMedical data analysis often grapples with vast and intricate data sets. Manual handling isn’t just tedious; it’s error-prone, especially given the critical decisions hinging on the results. This tutorial introduces automation techniques in R, a leading language for statistical analysis. By learning to use loops and functions, you can automate repetitive tasks, minimize errors, and conduct analyses more efficiently. Dive in to enhance your data handling skills.\n\n\nImporting Dataset\nThis tutorial focuses on importing data into R. It demonstrates how to import data from CSV and SAS formats using functions like read.csv and sasxport.get. It also includes examples of loading specific variables, dropping variables, subsetting observations based on certain criteria, and handling missing values.\n\n\nData Manipulation\nThis tutorial explores various data manipulation techniques in R. It covers topics such as dropping variables from a dataset, keeping specific variables, subsetting observations based on specific criteria, converting variable types (e.g., factors, strings), and handling missing values.\n\n\nImport External Data\nThis tutorial provides examples of importing external data into R. It includes specific examples of importing a CSV file (Employee Salaries - 2017 data) and a SAS file (NHANES 2015-2016 data). It also demonstrates how to save a working dataset in different formats, such as CSV and RData.\n\n\nSummary Tables\nThis tutorial emphasizes the importance of data summarization in medical research and epidemiology, specifically how to summarize medical data using R. It demonstrates creating “Table 1”, a typical descriptive statistics table in research papers, with examples that use the built-in R functions and specialized packages to efficiently summarize and stratify data."
  },
  {
    "objectID": "wrangling1a.html",
    "href": "wrangling1a.html",
    "title": "R basics",
    "section": "",
    "text": "Start using R\nTo get started with R, follow these steps:\n\nDownload and Install R: Grab the newest version from the official R website. > Tip: Download from a Comprehensive R Archive Network (CRAN) server near your geographic location.\nDownload and Install RStudio: You can get it from this link. > Note: RStudio serves as an Integrated Development Environment (IDE) offering a user-friendly interface. It facilitates operations such as executing R commands, preserving scripts, inspecting results, managing data, and more.\nBegin with RStudio: Once you open RStudio, delve into using R. For starters, employ the R syntax for script preservation, allowing future code adjustments and additions.\n\n\n\nBasic syntax\n\n\n\n\n\n\nTip\n\n\n\nR, a versatile programming language for statistics and data analysis, can execute numerous tasks. Let’s break down some of the fundamental aspects of R’s syntax.\n\n\n\nUsing R as a Calculator\n\nSimilar to how you’d use a traditional calculator for basic arithmetic operations, R can perform these functions with ease. For instance:\n\n\nShow the code\n# Simple arithmetic\n1 + 1\n#> [1] 2\n\n\nThis is a basic addition, resulting in 2.\nA more intricate calculation:\n\n\nShow the code\n# Complex calculation involving \n# multiplication, subtraction, division, powers, and square root\n20 * 5 - 10 * (3/4) * (2^3) + sqrt(25)\n#> [1] 45\n\n\nThis demonstrates R’s capability to handle complex arithmetic operations.\n\nVariable Assignment in R\n\nR allows you to store values in variables, acting like labeled containers that can be recalled and manipulated later. For example,\n\n\nShow the code\n# Assigning a value of 2 to variable x1\nx1 <- 2\nprint(x1)\n#> [1] 2\n\n\nSimilarly:\n\n\nShow the code\nx2 <- 9\nx2\n#> [1] 9\n\n\n\nCreating New Variables Using Existing Ones\n\nYou can combine and manipulate previously assigned variables to create new ones.\n\n\nShow the code\n# Using variable x1 \n# to compute its square and assign to y1\ny1 <- x1^2\ny1\n#> [1] 4\n\n\nYou can also use multiple variables in a single expression:\n\n\nShow the code\ny2 <- 310 - x1 + 2*x2 - 5*y1^3\ny2\n#> [1] 6\n\n\n\nCreating Functions\n\nFunctions act as reusable blocks of code. Once defined, they can be called multiple times with different arguments. Here’s how to define a function that squares a number:\n\n\nShow the code\nz <- function(x) {x^2}\n\n\nR also comes with a plethora of built-in functions. Examples include exp (exponential function) and rnorm (random number generation from a normal distribution).\n\nUtilizing Built-In Functions\n\nFor instance, using the exponential function:\n\n\nShow the code\n# Calling functions\nexp(x1)\n#> [1] 7.389056\nlog(exp(x1))\n#> [1] 2\n\n\nThe rnorm function can generate random samples from a normal distribution: below we are generating 10 random sampling from the normal distribution with mean 0 and standard deviation 1:\n\n\nShow the code\nrnorm(n = 10, mean = 0, sd = 1)\n#>  [1] -0.11444828 -0.15943436  1.04037141 -0.23151050  0.33470273 -1.37626255\n#>  [7]  0.06806398  1.58666116  0.95818265 -0.11180281\n\n\nAs random number generation relies on algorithms, results will differ with each execution.\n\n\nShow the code\n# Random sampling (again)\nrnorm(n = 10, mean = 0, sd = 1)\n#>  [1]  0.775674423  0.531005929  0.034212450 -0.123882356  0.008818819\n#>  [6] -1.216887738 -0.997872827 -0.386573489  1.880882716 -1.031315985\n\n\nHowever, by setting a seed, we can reproduce identical random results:\n\n\nShow the code\n# Random sampling (again, but with a seed)\nset.seed(11)\nrnorm(n = 10, mean = 0, sd = 1)\n#>  [1] -0.59103110  0.02659437 -1.51655310 -1.36265335  1.17848916 -0.93415132\n#>  [7]  1.32360565  0.62491779 -0.04572296 -1.00412058\n\n\n\n\nShow the code\n# random sampling (reproducing the same numbers)\nset.seed(11)\nrnorm(n = 10, mean = 0, sd = 1)\n#>  [1] -0.59103110  0.02659437 -1.51655310 -1.36265335  1.17848916 -0.93415132\n#>  [7]  1.32360565  0.62491779 -0.04572296 -1.00412058\n\n\nAs we can see, when we set the same seed, we get exactly the same random number. This is very important for reproducing the same results. There are many other pre-exiting functions in R.\n\nSeeking Help in R\n\n\n\n\n\n\n\nTip\n\n\n\nR’s help function, invoked with ?function_name, provides detailed documentation on functions, assisting users with unclear or forgotten arguments:\n\n\n\n\nShow the code\n# Searching for help if you know \n# the exact name of the function with a question mark\n?curve\n\n\nBelow is an example of using the pre-exiting function for plotting a curve ranging from -10 to 10.\n\n\nShow the code\n# Plotting a function\ncurve(z, from = -10, to = 10, xlab = \"x\", ylab = \"Squared x\")\n\n\n\n\n\nIf some of the arguments are difficult to remember or what else could be done with that function, we could use the help function. For example, we can simply type help(curve) or ?curve to get help on the curve function:\n\n\n\n\n\n\nTip\n\n\n\nIf you’re uncertain about a function’s precise name, two question marks can assist in the search:\n\n\n\n\nShow the code\n# Searching for help if don't know \n# the exact name of the function\n??boxplot\n\n\n\nCreating Vectors\n\nVectors are sequences of data elements of the same basic type. Here are some methods to create them:\n\n\nShow the code\n# Creating vectors in different ways\nx3 <- c(1, 2, 3, 4, 5)\nprint(x3)\n#> [1] 1 2 3 4 5\n\nx4 <- 1:7\nprint(x4)\n#> [1] 1 2 3 4 5 6 7\n\nx5 <- seq(from = 0, to = 100, by = 10)\nprint(x5)\n#>  [1]   0  10  20  30  40  50  60  70  80  90 100\n\nx6 <- seq(10, 30, length = 7)\nx6\n#> [1] 10.00000 13.33333 16.66667 20.00000 23.33333 26.66667 30.00000\n\n\n\nPlotting in R\n\nR provides numerous plotting capabilities. For instance, the plot function can create scatter plots and line graphs:\n\n\nShow the code\n# Scatter plot\nplot(x5, type = \"p\", main = \"Scatter plot\")\n\n\n\n\n\n\n\nShow the code\n# Line graph\nplot(x = x6, y = x6^2, type = \"l\", main = \"Line graph\")\n\n\n\n\n\n\nCharacter Vectors Apart from numeric values, R also allows for character vectors. For example, we can create a sex variable coded as females, males and other.\n\n\n\nShow the code\n# Character vector\nsex <- c(\"females\", \"males\", \"other\")\nsex\n#> [1] \"females\" \"males\"   \"other\"\n\n\nTo determine a variable’s type, use the mode function:\n\n\nShow the code\n# Check data type\nmode(sex)\n#> [1] \"character\""
  },
  {
    "objectID": "wrangling1b.html",
    "href": "wrangling1b.html",
    "title": "Data types",
    "section": "",
    "text": "Matrix\n\n\n\n\n\n\nTip\n\n\n\nIn R, matrices are two-dimensional rectangular data sets, which can be created using the matrix() function. It’s essential to remember that all the elements of a matrix must be of the same type, such as all numeric or all character.\n\n\nTo construct a matrix, we often start with a vector and specify how we want to reshape it. For instance:\n\n\nShow the code\n# Matrix 1\nx <- 1:10\nmatrix1 <- matrix(x, nrow = 5, ncol = 2, byrow = TRUE)\nmatrix1\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#> [3,]    5    6\n#> [4,]    7    8\n#> [5,]    9   10\n\n\nHere, the vector x contains numbers from 1 to 10. We reshape it into a matrix with 5 rows and 2 columns. The byrow = TRUE argument means the matrix will be filled row-wise, with numbers from the vector.\nConversely, if you want the matrix to be filled column-wise, you’d set byrow = FALSE:\n\n\nShow the code\n# matrix 2\nmatrix2 <- matrix(x, nrow = 5, ncol = 2, byrow = FALSE)\nmatrix2\n#>      [,1] [,2]\n#> [1,]    1    6\n#> [2,]    2    7\n#> [3,]    3    8\n#> [4,]    4    9\n#> [5,]    5   10\n\n\nYou can also combine or concatenate matrices. cbind() joins matrices by columns while rbind() joins them by rows.\n\n\nShow the code\n# Merging 2 matrices\ncbind(matrix1, matrix2)\n#>      [,1] [,2] [,3] [,4]\n#> [1,]    1    2    1    6\n#> [2,]    3    4    2    7\n#> [3,]    5    6    3    8\n#> [4,]    7    8    4    9\n#> [5,]    9   10    5   10\n\n\n\n\nShow the code\n# Appending 2 matrices\nrbind(matrix1, matrix2)\n#>       [,1] [,2]\n#>  [1,]    1    2\n#>  [2,]    3    4\n#>  [3,]    5    6\n#>  [4,]    7    8\n#>  [5,]    9   10\n#>  [6,]    1    6\n#>  [7,]    2    7\n#>  [8,]    3    8\n#>  [9,]    4    9\n#> [10,]    5   10\n\n\n\n\nList\n\n\n\n\n\n\nTip\n\n\n\nIn R, lists can be seen as a collection where you can store a variety of different objects under a single name. This includes vectors, matrices, or even other lists. It’s very versatile because its components can be of any type of R object.\n\n\nFor instance:\n\n\nShow the code\n# List of 2 matrices\nlist1 <- list(matrix1, matrix2)\nlist1\n#> [[1]]\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#> [3,]    5    6\n#> [4,]    7    8\n#> [5,]    9   10\n#> \n#> [[2]]\n#>      [,1] [,2]\n#> [1,]    1    6\n#> [2,]    2    7\n#> [3,]    3    8\n#> [4,]    4    9\n#> [5,]    5   10\n\n\nLists can also be expanded to include multiple items:\n\n\nShow the code\nx6 <- seq(10, 30, length = 7)\nsex <- c(\"females\", \"males\", \"other\")\n# Expanding list to include more items\nlist2 <- list(list1, x6, sex, matrix1)\nlist2 \n#> [[1]]\n#> [[1]][[1]]\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#> [3,]    5    6\n#> [4,]    7    8\n#> [5,]    9   10\n#> \n#> [[1]][[2]]\n#>      [,1] [,2]\n#> [1,]    1    6\n#> [2,]    2    7\n#> [3,]    3    8\n#> [4,]    4    9\n#> [5,]    5   10\n#> \n#> \n#> [[2]]\n#> [1] 10.00000 13.33333 16.66667 20.00000 23.33333 26.66667 30.00000\n#> \n#> [[3]]\n#> [1] \"females\" \"males\"   \"other\"  \n#> \n#> [[4]]\n#>      [,1] [,2]\n#> [1,]    1    2\n#> [2,]    3    4\n#> [3,]    5    6\n#> [4,]    7    8\n#> [5,]    9   10\n\n\nCombining different types of data into a single matrix converts everything to a character type:\n\n\nShow the code\n# A matrix with numeric and character variables\nid <- c(1, 2)\nscore <- c(85, 85)\nsex <- c(\"M\", \"F\")\nnew.matrix <- cbind(id, score, sex)\nnew.matrix\n#>      id  score sex\n#> [1,] \"1\" \"85\"  \"M\"\n#> [2,] \"2\" \"85\"  \"F\"\n\n\nTo check the type of data in your matrix:\n\n\nShow the code\nmode(new.matrix)\n#> [1] \"character\"\n\n\n\n\nData frame\n\n\n\n\n\n\nTip\n\n\n\nAs we can see combining both numeric and character variables into a matrix ended up with a matrix of character values. To keep the numeric variables as numeric and character variables as character, we can use the data.frame function.\n\n\n\nCreating a data frame\n\n\n\nA data frame is similar to a matrix but allows for columns of different types (numeric, character, factor, etc.). It’s a standard format for storing data sets in R.\n\n\nShow the code\ndf <- data.frame(id, score, sex)\ndf\n\n\n\n\n  \n\n\n\nTo check the mode or type of your data frame:\n\n\nShow the code\nmode(df)\n#> [1] \"list\"\n\n\n\nExtract elements\n\nData frames allow easy extraction and modification of specific elements. For example, we can extract the values on the first row and first column as follow:\n\n\nShow the code\ndf[1,1]\n#> [1] 1\n\n\nSimilarly, the first column can be extracted as follows:\n\n\nShow the code\ndf[,1]\n#> [1] 1 2\n\n\nThe first row can be extracted as follows:\n\n\nShow the code\ndf[1,]\n\n\n\n\n  \n\n\n\n\nModifying values\n\nWe can edit the values in the data frame as well. For example, we can change the score from 85 to 90 for the id 1:\n\n\nShow the code\ndf$score[df$id == 1] <- 90\ndf\n\n\n\n\n  \n\n\n\nWe can also change the name of the variables/columns:\n\n\nShow the code\ncolnames(df) <- c(\"Studyid\", \"Grade\", \"Sex\")\ndf\n\n\n\n\n  \n\n\n\n\nCombining data frames\n\nWe can also merge another data frame with the same variables using the rbind function:\n\n\nShow the code\n# Create a new dataset\ndf2 <- data.frame(Studyid = c(10, 15, 50), Grade = c(75, 90, 65), Sex = c(\"F\", \"M\", \"M\"))\n\n# Combining two data frames\ndf.new <- rbind(df, df2)\n\n# Print the first 6 rows\nhead(df.new)\n\n\n\n\n  \n\n\n\n\nChecking the dimensions\n\nTo see the dimension of the data frame (i.e., number of rows and columns), we can use the dim function:\n\n\nShow the code\ndim(df.new)\n#> [1] 5 3\n\n\nAs we can see, we have 5 rows and 3 columns. We can use the nrow and ncol functions respectively for the same output:\n\n\nShow the code\nnrow(df.new)\n#> [1] 5\nncol(df.new)\n#> [1] 3"
  },
  {
    "objectID": "wrangling1c.html",
    "href": "wrangling1c.html",
    "title": "Automating tasks",
    "section": "",
    "text": "Repeating a task\n\n\n\n\n\n\nTip\n\n\n\nThe for loop is a control flow statement in R that lets you repeat a particular task multiple times. This repetition is based on a sequence of numbers or values in a vector.\n\n\nConsider a simple real-life analogy: Imagine you are filling water in 10 bottles, one by one. Instead of doing it manually 10 times, you can set a machine to do it in a loop until all 10 bottles are filled.\n\nExample 1\n\n\n\nShow the code\n# Looping and adding\nk <- 0\nfor (i in 1:10){\n  k <- k + 5\n  print(k)\n}\n#> [1] 5\n#> [1] 10\n#> [1] 15\n#> [1] 20\n#> [1] 25\n#> [1] 30\n#> [1] 35\n#> [1] 40\n#> [1] 45\n#> [1] 50\n\n\nHere, you’re initiating a counter k at 0. With each iteration of the loop (i.e., every time it “runs”), 5 is added to k. After 10 cycles, the loop will stop, but not before printing k in each cycle.\n\nExample 2\n\nWe create a variable x5 containing the values of 0, 10, 20, 30, 40, 50, 60, 70, 80, 90, and 100. Let us print the first 5 values using the for loop function:\n\n\nShow the code\nx5 <- seq(from = 0, to = 100, by = 10)\n# Looping through a vector\nk <- 1:5\nfor (ii in k){\n  print(x5[ii])\n}\n#> [1] 0\n#> [1] 10\n#> [1] 20\n#> [1] 30\n#> [1] 40\n\n\nThis loop cycles through the first five values of a previously created variable x5 and prints them. Each value printed corresponds to the positions 1 to 5 in x5.\n\nExample 3\n\nLet us use the for loop in a more complicated scenario. First, we create a vector of numeric values and square it:\n\n\nShow the code\n# Create a vector\nk <- c(1, 3, 6, 2, 0)\nk^2\n#> [1]  1  9 36  4  0\n\n\nThis is just squaring each value in the vector k.\n\nExample 4\n\nWe create the same vector of square values using the for loop function. To do so, (i) we create a null object, (ii) use the loop for each of the elements in the vector (k), (iii) square each of the elements, and (iv) store each of the elements of the new vector. In the example below, the length of k is 5, and the loop will run from the first to the fifth element of k. Also, k.sq[1] is the first stored value for squared-k, and k.sq[2] is the second stored value for squared-k, and so on.\n\n\nShow the code\n# Looping through a vector with function\nk.sq <- NULL\nfor (i in 1:length(k)){\n  k.sq[i] <- k[i]^2\n}\n\n# Print the values\nk.sq\n#> [1]  1  9 36  4  0\n\n\nHere, we achieve the same result as the third example but use a for loop. We prepare an empty object k.sq and then use the loop to square each value in k, storing the result in k.sq.\n\nExample 5\n\n\n\nShow the code\ndf.new <- data.frame(\n  Studyid = c(1, 2, 10, 15, 50),\n  Grade = c(90, 85, 75, 90, 65),\n  Sex = c('M', 'F', 'F', 'M', 'M')\n)\n# Looping through a data frame\nfor (i in 1:nrow(df.new)){\n  print(df.new[i,\"Sex\"])\n}\n#> [1] \"M\"\n#> [1] \"F\"\n#> [1] \"F\"\n#> [1] \"M\"\n#> [1] \"M\"\n\n\nThis loop prints the “Sex” column value for each row in the df.new data frame.\n\n\nFunctions\n\n\n\n\n\n\nTip\n\n\n\nA function in R is a piece of code that can take inputs, process them, and return an output. There are functions built into R, like mean(), which calculates the average of a set of numbers.\n\n\n\nBuilt-in function\n\n\n\nShow the code\n# Calculating a mean from a vector\nVector <- 1:100\nmean(Vector)\n#> [1] 50.5\n\n\nHere, we’re using the built-in mean() function to find the average of numbers from 1 to 100.\n\nCustom-made function\n\nTo understand how functions work, sometimes it’s helpful to build our own. Now we will create our own function to calculate the mean, where we will use the following equation to calculate it:\n\\(\\text{Mean} = \\frac{\\sum_{i=1}^{n} x_i}{n},\\)\nwhere \\(x_1\\), \\(x_2\\),…, \\(x_n\\) are the values in the vector and \\(n\\) is the sample size. Let us create the function for calculation the mean:\nThis function, mean.own, calculates the average. We add up all the numbers in a vector (Sum <- sum(x)) and divide by the number of items in that vector (n <- length(x)). The result is then returned.\n\n\nShow the code\nmean.own <- function(x){\n  Sum <- sum(x)\n  n <- length(x)\n  return(Sum/n)\n}\n\n\nBy using our custom-made function, we calculate the mean of numbers from 1 to 100, getting the same result as the built-in mean() function.\n\n\nShow the code\nmean.own(Vector)\n#> [1] 50.5"
  },
  {
    "objectID": "wrangling2.html",
    "href": "wrangling2.html",
    "title": "Importing dataset",
    "section": "",
    "text": "Introduction to Data Importing\nBefore analyzing data in R, one of the first steps you’ll typically undertake is importing your dataset. R provides numerous methods to do this, depending on the format of your dataset.\nDatasets come in a variety of file formats, with .csv (Comma-Separated Values) and .txt (Text file) being among the most common. While R’s interface offers manual ways to load these datasets, knowing how to code this step ensures better reproducibility and automation.\n\n\nImporting .txt files\nA .txt data file can be imported using the read.table function. As an example, consider you have a dataset named grade in the specified path.\nLet’s briefly glance at the file without concerning ourselves with its formatting.\n\n\nShow the code\n# Read and print the content of the TXT file\ncontent <- readLines(\"Data/wrangling/grade.txt\")\ncat(content, sep = \"\\n\")\n#> Studyid Grade Sex\n#> 1    90   M\n#> 2    85   F\n#> 10    75   F\n#> 15    90   M\n#> 50    65   M\n\n\nUsing the read.table function, you can load this dataset in R properly. It’s important to specify header = TRUE if the first row of your dataset contains variable names.\n\nTip: Always ensure the header argument matches the structure of your dataset. If your dataset contains variable names, set header = TRUE.\n\n\n\nShow the code\n## Read a text dataset\ngrade <- read.table(\"Data/wrangling/grade.txt\", header = TRUE, sep = \"\\t\", quote = \"\\\"\")\n# Display the first few rows of the dataset\nhead(grade)\n\n\n\n\n  \n\n\n\n\n\nImporting .csv files\nSimilarly, .csv files can be loaded using the read.csv function. Here’s how you can load a .csv dataset named mpg:\n\n\nShow the code\n## Read a csv dataset\nmpg <- read.csv(\"Data/wrangling/mpg.csv\", header = TRUE)\n# Display the first few rows of the dataset\nhead(mpg)\n\n\n\n\n  \n\n\n\nWhile we’ve discussed two popular data formats, R can handle a plethora of other formats. For further details, refer to Quick-R (2023). Notably, some datasets come built-in with R packages, like the mpg dataset in the ggplot2 package. To load such a dataset:\n\n\nShow the code\ndata(mpg, package = \"ggplot2\")\nhead(mpg)\n\n\n\n\n  \n\n\n\nTo understand more about the variables and the dataset’s structure, you can consult the documentation:\n\n\nShow the code\n?mpg\n\n\n\n\nData Screening and Understanding Your Dataset\ndim(), nrow(), ncol(), and str() are incredibly handy functions when initially exploring your dataset.\nOnce your data is in R, the next logical step is to get familiar with it. Knowing the dimensions of your dataset, types of variables, and the first few entries can give you a quick sense of what you’re dealing with.\nFor instance, str (short for structure) is a concise way to display information about your data. It reveals the type of each variable, the first few entries, and the total number of observations:\n\n\nShow the code\nstr(mpg)\n#> tibble [234 × 11] (S3: tbl_df/tbl/data.frame)\n#>  $ manufacturer: chr [1:234] \"audi\" \"audi\" \"audi\" \"audi\" ...\n#>  $ model       : chr [1:234] \"a4\" \"a4\" \"a4\" \"a4\" ...\n#>  $ displ       : num [1:234] 1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ...\n#>  $ year        : int [1:234] 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ...\n#>  $ cyl         : int [1:234] 4 4 4 4 6 6 6 4 4 4 ...\n#>  $ trans       : chr [1:234] \"auto(l5)\" \"manual(m5)\" \"manual(m6)\" \"auto(av)\" ...\n#>  $ drv         : chr [1:234] \"f\" \"f\" \"f\" \"f\" ...\n#>  $ cty         : int [1:234] 18 21 20 21 16 18 18 18 16 20 ...\n#>  $ hwy         : int [1:234] 29 29 31 30 26 26 27 26 25 28 ...\n#>  $ fl          : chr [1:234] \"p\" \"p\" \"p\" \"p\" ...\n#>  $ class       : chr [1:234] \"compact\" \"compact\" \"compact\" \"compact\" ...\n\n\nIn summary, becoming proficient in data importing and initial screening is a fundamental step in any data analysis process in R. It ensures that subsequent stages of data manipulation and analysis are based on a clear understanding of the dataset at hand.\n\n\nReferences\n\n\n\n\n\n\nQuick-R. 2023. “Importing Data.” https://www.statmethods.net/input/importingdata.html."
  },
  {
    "objectID": "wrangling3.html",
    "href": "wrangling3.html",
    "title": "Data manipulation",
    "section": "",
    "text": "Data manipulation is a foundational skill for data analysis. This guide introduces common methods for subsetting datasets, handling variable types, creating summary tables, and dealing with missing values using R.\n\nLoad dataset\nUnderstanding the dataset’s structure is the first step in data manipulation. Here, we’re using the mpg dataset, which provides information on various car models:\n\n\nShow the code\nmpg <- read.csv(\"Data/wrangling/mpg.csv\", header = TRUE)\n\n\n\n\nSubset\nOften, you’ll need to subset your data for analysis. Here, we’ll explore different methods to both drop unwanted variables and keep desired observations.\n\nDrop variables\nSometimes, only part of the variables will be used in your analysis. Therefore, you may want to drop the variables you do not need. There are multiple ways to drop variables from a dataset. Below are two examples without using any package and using the dplyr package.\n\n\n\n\n\n\nTip\n\n\n\nOption 1: No package needed\ndataset.name[, c(the columns you want to KEEP)]\n\n\nSay, we want to keep only three variables in the mpg dataset: manufacturer, model and cyl. For Option 1 (without package), we can use the following R codes to keep these three variables:\n\n\nShow the code\nmpg1 <- mpg[, c(\"manufacturer\", \"model\", \"cyl\")]\nhead(mpg1)\n\n\n\n\n  \n\n\n\nHere mpg1 is a new dataset containing only three variables (manufacturer, model and cyl).\n\n\n\n\n\n\nTip\n\n\n\nOption 2: use select in dplyr\nselect(dataset.name, …(columns names you want to KEEP))\n\n\nFor Option 2, the dplyr package offers the select function, which provides a more intuitive way to subset data.\n\n\nShow the code\nmpg2 <- select(mpg, c(\"manufacturer\", \"model\", \"cyl\"))\nhead(mpg2)\n\n\n\n\n  \n\n\n\nWe can also exclude any variables from the dataset by using the minus (-) sign with the select function. For example, we we want to drop trans, drv, and cty from the mpg dataset, we can use the following codes:\n\n\nShow the code\nmpg3 <- select(mpg, -c(\"trans\", \"drv\", \"cty\"))\nhead(mpg3)\n\n\n\n\n  \n\n\n\nThis mpg3 is a new dataset from mpg after dropping three variables (trans, drv, and cty).\n\n\nKeep observations\nIt often happens that we only want to investigate a subset of a population which only requires a subset of our dataset. In this case, we need to subset the dataset to meet certain requirements. Again, there are multiple ways to do this task. Below is an example without a package and with the dplyr package:\n\n\n\n\n\n\nTip\n\n\n\nOption 1: No package needed\ndataset.name[the rows you want to KEEP, ]\n\n\n\n\n\n\n\n\nTip\n\n\n\nOption 2: No package needed\nsubset(dataset.name, …(logical tests))\n\n\n\n\n\n\n\n\nTip\n\n\n\nOption 3: use select in dplyr\nfilter(dataset.name, …(logical tests))\n\n\n\n\n\n\n\n\nTip\n\n\n\nCommon logical tests are:\n\n\n\n\n \n  \n    Syntax \n    Meaning \n  \n \n\n  \n    X <(=) Y \n    Smaller (equal) than \n  \n  \n    X >(=) Y \n    Larger (equal) than \n  \n  \n    X == Y \n    Equal to \n  \n  \n    X != Y \n    Not equal to \n  \n  \n    is.na(X) \n    is NA/missing? \n  \n\n\n\n\n\n\n\nSay, we want to keep the observations for which cars are manufactured in 2008. We can use the following R codes to do it:\n\n\nShow the code\nmpg4 <- mpg[mpg$year == \"2008\",] # Option 1\nhead(mpg4)\n\n\n\n\n  \n\n\n\nThe following codes with the subset and filter function will do the same:\n\n\nShow the code\nmpg5 <- subset(mpg, year == \"2008\") # Option 1\nhead(mpg5)\n\n\n\n\n  \n\n\n\n\n\nShow the code\nmpg6 <- filter(mpg, year == \"2008\") # Option 3\nhead(mpg6)\n\n\n\n\n  \n\n\n\nThe filter function can also work when you have multiple criteria (i.e., multiple logical tests) to satisfy. Here, we need Boolean operators to connect different logical tests.\n\n\n\n\n\n\nTip\n\n\n\nCommon boolean operators are:\n\n\n\n\n \n  \n    Syntax \n    Meaning \n  \n \n\n  \n    & \n    and \n  \n  \n    | \n    or \n  \n  \n    ! \n    not \n  \n  \n    == \n    equals to \n  \n  \n    != \n    not equal to \n  \n  \n    > \n    greater than \n  \n  \n    < \n    less than \n  \n  \n    >= \n    greater than or equal to \n  \n  \n    <= \n    less than or equal to \n  \n\n\n\n\n\n\n\nSay, we want to keep the observations for 6 and 8 cylinders (cyl) and engine displacement (displ) greater than or equal to 4 litres. We can use the following codes to do the task:\n\n\nShow the code\nmpg7 <- filter(mpg, cyl %in% c(\"6\",\"8\") & displ >= 4)\nhead(mpg7)\n\n\n\n\n  \n\n\n\n\n\nThe %in% operator is used to determine whether the values of the first argument are present in the second argument.\n\n\nHandling Variable Types\n\n\n\n\n\n\nTip\n\n\n\nMost common types of variable in R are\n\nnumbers,\nfactors and\nstrings(or character).\n\nUnderstanding and manipulating these types are crucial for data analysis.\n\n\n\nIdentifying Variable Type\n\nWhen we analyze the data, we usually just deal with numbers and factors. If there are variables are strings, we could convert them to factors using as.factors(variable.name)\n\n\nShow the code\nmode(mpg$trans)\n#> [1] \"character\"\n\n\n\n\nShow the code\nstr(mpg$trans)\n#>  chr [1:234] \"auto(l5)\" \"manual(m5)\" \"manual(m6)\" \"auto(av)\" \"auto(l5)\" ...\n\n\n\nConverting Characters to Factors\n\nSometimes, it’s necessary to treat text data as categorical by converting them into factors. as.numeric() converts other types of variables to numbers. For a factor variable, we usually we want to access the categories (or levels) it has. We can use a build-in function to explore: levels(variable.name)\n\n\nShow the code\n# no levels for character\nlevels(mpg$trans)\n#> NULL\n\n\n\n\nShow the code\n## Ex check how many different trans the dataset has\nmpg$trans <- as.factor(mpg$trans)\nlevels(mpg$trans)\n#>  [1] \"auto(av)\"   \"auto(l3)\"   \"auto(l4)\"   \"auto(l5)\"   \"auto(l6)\"  \n#>  [6] \"auto(s4)\"   \"auto(s5)\"   \"auto(s6)\"   \"manual(m5)\" \"manual(m6)\"\n\n\nThe levels usually will be ordered alphabetically. The first level is called “baseline”. However, the users may/may not want to keep this baseline and want to relevel/change the reference group. We can do it using the relevel function:\nrelevel(variable.name, ref=)\n\n\nShow the code\nmpg$trans <- relevel(mpg$trans, ref = \"auto(s6)\")\nlevels(mpg$trans)\n#>  [1] \"auto(s6)\"   \"auto(av)\"   \"auto(l3)\"   \"auto(l4)\"   \"auto(l5)\"  \n#>  [6] \"auto(l6)\"   \"auto(s4)\"   \"auto(s5)\"   \"manual(m5)\" \"manual(m6)\"\nnlevels(mpg$trans)\n#> [1] 10\n\n\nfactor function can be also used to combine factors. If the user want to combine multiple factors to one factors\n\n\nShow the code\n## EX re-group trans to \"auto\" and \"manual\"\nlevels(mpg$trans) <- list(auto = c(\"auto(av)\", \"auto(l3)\", \"auto(l4)\", \"auto(l5)\", \"auto(l6)\", \n                                   \"auto(s4)\", \"auto(s5)\", \"auto(s6)\"), \n                          manual = c(\"manual(m5)\", \"manual(m6)\"))\nlevels(mpg$trans)\n#> [1] \"auto\"   \"manual\"\n\n\nYou can also change the order of all factors using the following code: factor(variable.name, levels = c(“new order”))\n\n\nShow the code\n## EX. Change the order of trans to manual\nmpg$trans <- factor(mpg$trans, levels = c(\"manual\", \"auto\"))\nlevels(mpg$trans)\n#> [1] \"manual\" \"auto\"\n\n\n\n\nConvert continuous variables to categorical variables\n\n\n\n\n\n\nTip\n\n\n\nifelse, cut, recode all are helpful functions to convert numerical variables to categorical variables.\n\n\nLet’s see the summary of the cty variable first.\n\n\nShow the code\nsummary(mpg$cty)\n#>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n#>    9.00   14.00   17.00   16.86   19.00   35.00\n\n\nsay, we may want to change continuous ‘cty’ into groups 0-14, 15-18, and 18-40. Below is an example with the cut function.\n\n\nShow the code\n## EX. change the cty into two categories (0,14], (14,18] and (18,40]\nmpg$cty.num <- cut(mpg$cty, c(0, 14, 18, 40), right = TRUE)\ntable(mpg$cty.num)\n#> \n#>  (0,14] (14,18] (18,40] \n#>      73      85      76\n\n\n\n\nShow the code\n## Try this: do you see a difference?: [0,14), [14,18) and [18,40)\nmpg$cty.num2 <- cut(mpg$cty, c(0, 14, 18, 40), right = FALSE)\ntable(mpg$cty.num2)\n#> \n#>  [0,14) [14,18) [18,40) \n#>      54      78     102\n\n\n\n\n] stands for closed interval, i.e., right = TRUE. On the other hand, ) means open interval. Hence, there will be a huge difference when setting right = TRUE vs. right = FALSE\n\n\n\nMissing value\n\n\n\n\n\n\nTip\n\n\n\nIncomplete datasets can distort analysis. Identifying and managing these missing values is thus crucial.\n\n\nWe can check how many missing values we have by: table(is.na(variable.name))\nLet’s us check whether the cty variable contains any missing values:\n\n\nShow the code\ntable(is.na(mpg$cty))\n#> \n#> FALSE \n#>   234\n\n\nIf you want to return all non-missing values, i.e., complete case values: na.omit(variable.name). For more extensive methods on handling missing values, see subsequent tutorials."
  },
  {
    "objectID": "wrangling4.html#youtube-videos",
    "href": "wrangling4.html#youtube-videos",
    "title": "Import external data",
    "section": "YouTube Videos",
    "text": "YouTube Videos\n\n\nSome helpful videos related to the R for wrangling chapter are added here as optional materials.\nYou could watch the videos describing R basics, R for loops and functions, and manipulating real datasets using R."
  },
  {
    "objectID": "wrangling5.html",
    "href": "wrangling5.html",
    "title": "Summary tables",
    "section": "",
    "text": "Medical research and epidemiology often involve large, complex datasets. Data summarization is a vital step that transforms these vast datasets into concise, understandable insights. In medical contexts, these summaries can highlight patterns, indicate data inconsistencies, and guide further research. This tutorial will teach you how to use R to efficiently summarize medical data.\nIn epidemiology and medical research, “Table 1” typically refers to the first table in a research paper or report that provides descriptive statistics of the study population. It offers a snapshot of the baseline characteristics of the study groups, whether in a cohort study, clinical trial, or any other study design.\n\n\nShow the code\nmpg <- read.csv(\"Data/wrangling/mpg.csv\", header = TRUE)\n## Ex create a summary table between manufacturer and drv\ntable(mpg$drv, mpg$manufacturer)\n#>    \n#>     audi chevrolet dodge ford honda hyundai jeep land rover lincoln mercury\n#>   4   11         4    26   13     0       0    8          4       0       4\n#>   f    7         5    11    0     9      14    0          0       0       0\n#>   r    0        10     0   12     0       0    0          0       3       0\n#>    \n#>     nissan pontiac subaru toyota volkswagen\n#>   4      4       0     14     15          0\n#>   f      9       5      0     19         27\n#>   r      0       0      0      0          0\n\n\nThe first line reads a CSV file. It uses the table() function to generate a contingency table (cross-tabulation) between two categorical variables: drv (drive) and manufacturer. It essentially counts how many times each combination of drv and manufacturer appears in the dataset.\n\n\nShow the code\n## Get the percentage summary using prop.table\nprop.table(table(mpg$drv, mpg$manufacturer), margin = 2)\n#>    \n#>          audi chevrolet     dodge      ford     honda   hyundai      jeep\n#>   4 0.6111111 0.2105263 0.7027027 0.5200000 0.0000000 0.0000000 1.0000000\n#>   f 0.3888889 0.2631579 0.2972973 0.0000000 1.0000000 1.0000000 0.0000000\n#>   r 0.0000000 0.5263158 0.0000000 0.4800000 0.0000000 0.0000000 0.0000000\n#>    \n#>     land rover   lincoln   mercury    nissan   pontiac    subaru    toyota\n#>   4  1.0000000 0.0000000 1.0000000 0.3076923 0.0000000 1.0000000 0.4411765\n#>   f  0.0000000 0.0000000 0.0000000 0.6923077 1.0000000 0.0000000 0.5588235\n#>   r  0.0000000 1.0000000 0.0000000 0.0000000 0.0000000 0.0000000 0.0000000\n#>    \n#>     volkswagen\n#>   4  0.0000000\n#>   f  1.0000000\n#>   r  0.0000000\n## margin = 1 sum across row, 2 across col\n\n\nThis code calculates the column-wise proportion (as percentages) for each combination of drv and manufacturer. The prop.table() function is used to compute the proportions. The margin = 2 argument indicates that the proportions are to be computed across columns (margin = 1 would compute them across rows).\n\ntableone package\n\n\n\n\n\n\nTip\n\n\n\nCreateTableOne function from tableone package could be a very useful function to see the summary table. Type ?tableone::CreateTableOne to see for more details.\n\n\nThis section introduces the tableone package, which offers the CreateTableOne function. This function helps in creating “Table 1” type summary tables, commonly used in epidemiological studies.\n\n\nShow the code\nrequire(tableone)\n#> Loading required package: tableone\nCreateTableOne(vars = c(\"cyl\", \"drv\", \"hwy\", \"cty\"), data = mpg, \n               strata = \"trans\", includeNA = TRUE, test = FALSE)\n#>                  Stratified by trans\n#>                   auto(av)       auto(l3)       auto(l4)      auto(l5)     \n#>   n                   5              2             83            39        \n#>   cyl (mean (SD))  5.20 (1.10)    4.00 (0.00)    6.14 (1.62)   6.56 (1.45) \n#>   drv (%)                                                                  \n#>      4                0 (  0.0)      0 (  0.0)     34 (41.0)     29 (74.4) \n#>      f                5 (100.0)      2 (100.0)     37 (44.6)      8 (20.5) \n#>      r                0 (  0.0)      0 (  0.0)     12 (14.5)      2 ( 5.1) \n#>   hwy (mean (SD)) 27.80 (2.59)   27.00 (4.24)   21.96 (5.64)  20.72 (6.04) \n#>   cty (mean (SD)) 20.00 (2.00)   21.00 (4.24)   15.94 (3.98)  14.72 (3.49) \n#>                  Stratified by trans\n#>                   auto(l6)      auto(s4)      auto(s5)      auto(s6)     \n#>   n                   6             3             3            16        \n#>   cyl (mean (SD))  7.33 (1.03)   5.33 (2.31)   6.00 (2.00)   6.00 (1.59) \n#>   drv (%)                                                                \n#>      4                2 (33.3)      2 (66.7)      1 (33.3)      7 (43.8) \n#>      f                2 (33.3)      1 (33.3)      2 (66.7)      8 (50.0) \n#>      r                2 (33.3)      0 ( 0.0)      0 ( 0.0)      1 ( 6.2) \n#>   hwy (mean (SD)) 20.00 (2.37)  25.67 (1.15)  25.33 (6.66)  25.19 (3.99) \n#>   cty (mean (SD)) 13.67 (1.86)  18.67 (2.31)  17.33 (5.03)  17.38 (3.22) \n#>                  Stratified by trans\n#>                   manual(m5)    manual(m6)   \n#>   n                  58            19        \n#>   cyl (mean (SD))  5.00 (1.30)   6.00 (1.76) \n#>   drv (%)                                    \n#>      4               21 (36.2)      7 (36.8) \n#>      f               33 (56.9)      8 (42.1) \n#>      r                4 ( 6.9)      4 (21.1) \n#>   hwy (mean (SD)) 26.29 (5.99)  24.21 (5.75) \n#>   cty (mean (SD)) 19.26 (4.56)  16.89 (3.83)\n\n\nThe CreateTableOne function is used to create a summary table for the variables cyl, drv, hwy, and cty from the mpg dataset. The strata = trans argument means that the summary is stratified by the trans variable. The includeNA = TRUE argument means that missing values (NAs) are included in the summary. The test = FALSE argument indicates that no statistical tests should be applied to the data (often tests are used to compare groups in the table).\n\n\ntable1 package\nThis section introduces another package, table1, which can also be used to create “Table 1” type summary tables.\n\n\nShow the code\nrequire(table1)\n#> Loading required package: table1\n#> \n#> Attaching package: 'table1'\n#> The following objects are masked from 'package:base':\n#> \n#>     units, units<-\ntable1(~ cyl + drv + hwy + cty | trans, data=mpg)\n\n\n\n\n\n\n\nauto(av)(N=5)\nauto(l3)(N=2)\nauto(l4)(N=83)\nauto(l5)(N=39)\nauto(l6)(N=6)\nauto(s4)(N=3)\nauto(s5)(N=3)\nauto(s6)(N=16)\nmanual(m5)(N=58)\nmanual(m6)(N=19)\nOverall(N=234)\n\n\n\n\ncyl\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n5.20 (1.10)\n4.00 (0)\n6.14 (1.62)\n6.56 (1.45)\n7.33 (1.03)\n5.33 (2.31)\n6.00 (2.00)\n6.00 (1.59)\n5.00 (1.30)\n6.00 (1.76)\n5.89 (1.61)\n\n\nMedian [Min, Max]\n6.00 [4.00, 6.00]\n4.00 [4.00, 4.00]\n6.00 [4.00, 8.00]\n6.00 [4.00, 8.00]\n8.00 [6.00, 8.00]\n4.00 [4.00, 8.00]\n6.00 [4.00, 8.00]\n6.00 [4.00, 8.00]\n4.00 [4.00, 8.00]\n6.00 [4.00, 8.00]\n6.00 [4.00, 8.00]\n\n\ndrv\n\n\n\n\n\n\n\n\n\n\n\n\n\nf\n5 (100%)\n2 (100%)\n37 (44.6%)\n8 (20.5%)\n2 (33.3%)\n1 (33.3%)\n2 (66.7%)\n8 (50.0%)\n33 (56.9%)\n8 (42.1%)\n106 (45.3%)\n\n\n4\n0 (0%)\n0 (0%)\n34 (41.0%)\n29 (74.4%)\n2 (33.3%)\n2 (66.7%)\n1 (33.3%)\n7 (43.8%)\n21 (36.2%)\n7 (36.8%)\n103 (44.0%)\n\n\nr\n0 (0%)\n0 (0%)\n12 (14.5%)\n2 (5.1%)\n2 (33.3%)\n0 (0%)\n0 (0%)\n1 (6.3%)\n4 (6.9%)\n4 (21.1%)\n25 (10.7%)\n\n\nhwy\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n27.8 (2.59)\n27.0 (4.24)\n22.0 (5.64)\n20.7 (6.04)\n20.0 (2.37)\n25.7 (1.15)\n25.3 (6.66)\n25.2 (3.99)\n26.3 (5.99)\n24.2 (5.75)\n23.4 (5.95)\n\n\nMedian [Min, Max]\n27.0 [25.0, 31.0]\n27.0 [24.0, 30.0]\n22.0 [14.0, 41.0]\n19.0 [12.0, 36.0]\n19.0 [18.0, 23.0]\n25.0 [25.0, 27.0]\n27.0 [18.0, 31.0]\n26.0 [18.0, 29.0]\n26.0 [16.0, 44.0]\n26.0 [12.0, 32.0]\n24.0 [12.0, 44.0]\n\n\ncty\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n20.0 (2.00)\n21.0 (4.24)\n15.9 (3.98)\n14.7 (3.49)\n13.7 (1.86)\n18.7 (2.31)\n17.3 (5.03)\n17.4 (3.22)\n19.3 (4.56)\n16.9 (3.83)\n16.9 (4.26)\n\n\nMedian [Min, Max]\n19.0 [18.0, 23.0]\n21.0 [18.0, 24.0]\n16.0 [11.0, 29.0]\n14.0 [9.00, 25.0]\n13.0 [12.0, 16.0]\n20.0 [16.0, 20.0]\n18.0 [12.0, 22.0]\n17.0 [12.0, 22.0]\n19.0 [11.0, 35.0]\n16.0 [9.00, 23.0]\n17.0 [9.00, 35.0]\n\n\n\n\n\n\nThe table1() function is used to generate a summary table for the specified variables. The formula-like syntax (~ cyl + drv + hwy + cty | trans) indicates that the summary should be stratified by the trans variable."
  },
  {
    "objectID": "wranglingF.html",
    "href": "wranglingF.html",
    "title": "Functions for wrangling",
    "section": "",
    "text": "This review page provides an extensive list of R functions tailored for data wrangling tasks that we have used in this chapter. Each function is systematically described, highlighting its primary package source and its specific utility.\nTo learn more about these functions, readers can:\n\nUse R’s Built-in Help System: For each function, access its documentation by prefixing the function name with a question mark in the R console, e.g., ?as.factor. This displays the function’s manual page with descriptions, usage, and examples.\nSearch Websites: Simply Google, or visit the CRAN website to search for specific function documentation. Websites like Stack Overflow and RStudio Community often have discussions related to R functions.\nTutorials and Online Courses: Platforms like DataCamp, Coursera, and edX offer R courses that cover many functions in depth. Also there are examples of dedicated R tutorial websites that you might find useful. One example is “Introduction to R for health data analysis” by Ehsan Karim, An Hoang and Qu.\nBooks: There are numerous R programming books, such as “R for Data Science” by Hadley Wickham and “The Art of R Programming” by Norman Matloff.\nWorkshops and Webinars: Institutions and organizations occasionally offer R programming workshops or webinars.\n\nWhenever in doubt, exploring existing resources can be highly beneficial.\n\n\n\n\n \n  \n    Function_name \n    Package_name \n    Use \n  \n \n\n  \n    as.factor \n    base \n    Converts a variable to factors. `as.factor` is a wrapper for the `factor` function. \n  \n  \n    cbind \n    base \n    Merges matrices. \n  \n  \n    CreateTableOne \n    tableone \n    Creates a frequency table. \n  \n  \n    data.frame \n    base \n    Creates a dataset with both numeric and character variables. Requires unique column names and equal length for all variables. \n  \n  \n    dim \n    base \n    Returns the dimensions of a data frame (rows x columns). \n  \n  \n    filter \n    dplyr \n    Subsets a dataset by selecting a sub-population. \n  \n  \n    function \n    base \n    Used to define custom functions, e.g., for calculating standard deviation. \n  \n  \n    head \n    base \n    Displays the first six elements of an object (e.g., a dataset). `tail` displays the last six. \n  \n  \n    is.na \n    base \n    Checks for missing values in a variable. \n  \n  \n    levels \n    base \n    Displays the levels of a factor variable. \n  \n  \n    list \n    base \n    Stores vectors, matrices, or lists of differing types. \n  \n  \n    mode \n    base \n    Determines the type of a variable. \n  \n  \n    na.omit \n    base/stats \n    Removes all rows with missing values from a dataset. \n  \n  \n    names \n    base \n    Displays names of objects, e.g., variable names of a data frame. \n  \n  \n    nlevels \n    base \n    Shows the number of levels in a factor variable. \n  \n  \n    nrow \n    base \n    Returns the dimensions of a data frame. `nrow` gives row count and `ncol` gives column count. \n  \n  \n    plot \n    base/graphics \n    Draws scatter plots or line graphs. \n  \n  \n    print \n    base \n    Prints the output to console. \n  \n  \n    prop.table \n    base \n    Displays percentage summary for a table. \n  \n  \n    rbind \n    base \n    Appends matrices row-wise. \n  \n  \n    read.csv \n    base/utils \n    Reads data from a CSV file. \n  \n  \n    relevel \n    base/stats \n    Changes the reference group of a factor variable. \n  \n  \n    sasxport.get \n    Hmisc \n    Loads data in the SAS format. \n  \n  \n    save \n    base \n    Saves R objects, such as datasets. \n  \n  \n    select \n    dplyr \n    Selects specified variables from a dataset. \n  \n  \n    set.seed \n    base \n    Sets a seed for random number generation ensuring reproducibility. \n  \n  \n    str \n    base/utils \n    Displays the structure of a dataset, including data type of variables. \n  \n  \n    subset \n    base, dplyr \n    Subsets a dataset by selecting a sub-population. \n  \n  \n    summary \n    base \n    Provides a summary of an object, like variable statistics. \n  \n  \n    table \n    base \n    Displays frequency counts for a variable. \n  \n  \n    write.csv \n    base/utils \n    Saves a data frame to a CSV file in a specified directory."
  },
  {
    "objectID": "wranglingQ.html",
    "href": "wranglingQ.html",
    "title": "Quiz on wrangling",
    "section": "",
    "text": "Downloading the File:\n\nNavigate to the link: See here.\nRight-click on the link and select “Save link as…” from the dropdown menu.\nAlternatively click here for downloading the quizzes on data wrangling.\nChoose a destination folder on your computer where you’d like to save the file (e.g., Desktop). Remember this location, as you’ll need to navigate to it later.\n\nSetting Up RStudio:\n\nIf you don’t have RStudio installed, see the download link in here.\nLaunch RStudio after installing.\n\nInstalling Necessary R Packages:\n\nBefore running the R Markdown file, ensure you have the required packages. In RStudio’s console (located at the bottom left by default), enter the following commands to install them:\ninstall.packages(\"learnr\")\ninstall.packages(\"xfun\")\n\nOpening and Running the File:\n\nIn RStudio, go to File > Open File....\nNavigate to the folder where you saved the Rmd file and select it to open.\nOnce the file is open in RStudio, you’ll see a “Run Document” button (green) at the top of the script editor. Click on it to run the R Markdown Quiz file."
  }
]