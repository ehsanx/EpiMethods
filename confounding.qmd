# Causal roles

This chapter delves deep into the intricate issues surrounding **causal associations**, particularly confounding, mediation, and other related biases. In this comprehensive series of tutorials, various aspects of confounding and bias are explored through the lens of Directed Acyclic Graphs (DAGs). Initially, the tutorials guide you through the process of generating large datasets based on these DAGs. They then delve into how the inclusion of different types of variables in adjustment models can skew estimates of treatment effects. We use the R package `simcausal` in these tutorials to derive empirical estimates from a large dataset.

::: {.column-margin} 
In the preceding chapter, we delved into the various types of [research questions](researchquestion.html), distinguishing between causal and predictive inquiries. This current chapter focuses primarily on the challenges and intricacies associated with causal questions. Specifically, we will explore which types of variables are most appropriate to incorporate into adjustment models when aiming to estimate treatment effects accurately. In contrast, the subsequent chapter will shift its emphasis towards [predictive](predictivefactors.html) questions, providing insights into their unique characteristics and considerations.
:::

::: callout-important
**Datasets**:

We use the R package `simcausal` in these tutorials to derive empirical estimates from a large simulated dataset. The simulation is based on data generation based on specified DAGs.
:::

::: {.column-margin} 
Directed Acyclic Graphs (DAGs) are powerful tools in the realm of causal inference. They are a type of graphical representation used to depict causal relationships between variables. This visual representation of the causal structure among variables makes it easier to understand and communicate complex causal relationships. They provide a visual framework to understand, represent, and analyze complex causal relationships, ensuring that researchers make informed decisions when trying to answer causal questions.
::: 

## [Confounding](confounding1.html)

The first tutorial provides a thorough exploration of confounding, with a particular focus on its impact on treatment effect estimates in large datasets. It emphasizes the importance of properly adjusting for confounders to arrive at accurate estimates.

## [Mediator](confounding2.html)

This tutorial focuses on the role of mediator variables in estimating treatment effects. It assesses how adjusting for the mediator influences the estimated treatment effect, exploring both scenarios where the true treatment effect is either non-null or null.

## [Collider](confounding3.html)

This tutorial serves as a practical guide for understanding how the inclusion of colliders can affect the estimation of treatment effects in causal models.

## [Z-bias](confounding4.html)

This tutorial explores the concept of Z-bias, a phenomenon that can lead to misleading estimates of treatment effects in observational studies. It demonstrates how failing to properly adjust or not adjust for instrumental variables can result in biased estimates and compares these with the true treatment effect.

## [Collapsibility](confounding5.html)

This tutorial provides a detailed guide on calculating marginal probabilities and measures of association, including Risk Difference (RD), Risk Ratio (RR), and Odds Ratio (OR). It examines the impact of adjusting for various covariates on these measures, highlighting the concept of "collapsibility."

## [Change-in-estimate](confounding6.html)

This tutorial focuses on the "Change-in-estimate" concept to understand the impact of various variables on measures of effect. For both continuous and binary outcomes, the tutorial reveals that adding a confounder to the model alters the true treatment effect estimate. Conversely, including a variable that is not a confounder but is a pure risk factor can either change or not change the effect estimate, depending on the type of outcome involved. This nuanced approach aids in understanding how different roles of variables can influence results and interpretations in causal inference.

::: callout-tip
**Optional Content**:

You'll find that some sections conclude with an optional video walkthrough that demonstrates the code. Keep in mind that the content might have been updated since these videos were recorded. Watching these videos is optional.
:::

::: callout-warning
**Bug Report**:

Fill out [this form](https://forms.gle/YSwuiebtb1E9wjHu9) to report any issues with the tutorial.
:::
