## Motivation {.unnumbered}

-   When using methods like propensity score approaches, we are making assumptions about the model specification. For example, we must specify any interaction terms.

-   With machine learning methods, these assumptions can be relaxed somewhat, as some machine learning methods allow automatic detection of data structures such as interactions.

-   However, machine learning was created for prediction modeling, not with causal inference in mind. Statistical inference such as calculating standard errors and confidence intervals is not as straightforward since the estimator given by machine learning methods does not follow a known statistical distribution. By contrast, the estimators resulting from a standard regression using maximum likelihood estimation will follow an approximately normal distribution, where it is easy to calculate standard errors and confidence intervals.

-   **Targeted maximum likelihood estimation (TMLE)** is a causal inference method that can incorporate machine learning in a way that still allows straightforward statistical inference based on theoretical development grounded in semi-parametric theory.

    -   TMLE is a **doubly robust** method. This means it uses both the exposure (AKA propensity score) model *and* the outcome model. As long as *one* of these models is correctly specified, TMLE will give a **consistent estimator**, meaning it gets closer and closer to the true value as the sample size increases.

    -   Since TMLE uses both the exposure and the outcome model, machine learning can be used in each of these intermediary modeling steps while allowing straightforward statistical inference.

-   It has been shown that TMLE outperform singly robust methods with machine learning, such as IPTW.

```{r setupTMLE, include=FALSE}
require(tableone)
require(Publish)
require(randomForest)
```

### Revisiting RHC Data {.unnumbered}

::: callout-note
This tutorial uses the same data as some of the previous tutorials, including [working with a predictive question](researchquestion1.html), [machine learning with a continuous outocome](machinelearning1.html), and [machine learning with a binary outcome](machinelearning4.html).
:::

```{r, cache=TRUE}
ObsData <- readRDS(file = 
                     "Data/machinelearningCausal/rhcAnalyticTest.RDS")
baselinevars <- names(dplyr::select(ObsData, 
                         !c(RHC.use,Length.of.Stay,Death)))
head(ObsData)
```

### Table 1 {.unnumbered}

Only for some demographic and comorbidity variables; matches with Table 1 in @connors1996effectiveness.

```{r, cache=TRUE}
tab0 <- CreateTableOne(vars = c("age", "sex", "race", 
                                "Disease.category", "Cancer"),
                       data = ObsData, 
                       strata = "RHC.use", 
                       test = FALSE)
print(tab0, showAllLevels = FALSE)
```

```{r, cache=TRUE, echo=FALSE}
save.image(file = "Data/machinelearningCausal/cl1.RData")
```

### References {.unnumbered}
