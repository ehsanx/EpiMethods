{
  "hash": "59ac38fa6d9097856f48562f480b8d46",
  "result": {
    "markdown": "## Confounding {.unnumbered}\n\nThis tutorial aims to delve into the role of confounding variables in data analysis, especially in the context of big data. We will examine each of these using simulations built on Directed Acyclic Graphs (DAGs). The objective is to understand whether a simple regression adjusting for the confounder variable can correctly estimate treatment effects in such a large sample.\n\n\n::: {.cell hash='confounding1_cache/html/setup_0722b4bfc96c3b4ed4972169888682c0'}\n\n```{.r .cell-code}\n# devtools::install_github('osofr/simcausal')\nrequire(simcausal)\n```\n:::\n\n\nBig data: **What if we had 1,000,000 (one million) observations?** Would that give us true result? Let's try to answer that using DAGs.\n\nLet us consider\n\n-   L is continuous variable\n-   A is binary treatment\n-   Y is continuous outcome\n\nAn example of A could be receiving the right heart catheterization (RHC) procedure or not, Y could be the length of hospital stay, and L could be age ([see here](researchquestion1.html)).\n\n### Non-null effect\n\n-   True treatment effect = 1.3\n\n#### Data generating process\n\nTo perform the lab, we'll need the `simcausal` R package. This package may not be available on CRAN but can be installed from the author's GitHub page.\n\n\n::: {.cell hash='confounding1_cache/html/dgm1_7eca5c16d106a0575d8305f65f87dcc5'}\n\n```{.r .cell-code}\nrequire(simcausal)\nD <- DAG.empty()\nD <- D + \n  node(\"L\", distr = \"rnorm\", mean = 10, sd = 1) + \n  node(\"A\", distr = \"rbern\", prob = plogis(-10 + 1.1*L)) +\n  node(\"Y\", distr = \"rnorm\", mean = 0.5 * L + 1.3 * A, sd = 0.1)\nDset <- set.DAG(D)\n```\n:::\n\n\nNote that `rnorm` and `rbern` generate random samples from Normal and Bernoulli distributions, respectively. In the above code chuck, we set the parameters to generate L from Normal distribution with a mean of 10 and a standard deviation of 1. Similarly, we set the parameters to generate A from the Bernoulli distribution with the probability of logit of (-10 + 1.1 $\\times$ L). Finally, we set the parameters to generate Y from the Normal distribution with a mean of (0.5 $\\times$ L + 1.3 $\\times$ A) and a standard deviation of 0.1.\n\n#### Generate DAG\n\nLet us draw a [directed acyclic graph (DAG)](https://doi.org/10.1016%2Fj.jclinepi.2021.08.001). Below we use the `plotDAG` function from the `simcausal` package. However, we can draw a DAG using [DAGitty](https://www.dagitty.net/). \n\n\n::: {.cell hash='confounding1_cache/html/dag1_6008877eeaa9cb7f84c59af3528fb3f2'}\n\n```{.r .cell-code}\nplotDAG(Dset, xjitter = 0.1, yjitter = .9,\n        edge_attrs = list(width = 0.5, arrow.width = 0.4, arrow.size = 0.7),\n        vertex_attrs = list(size = 12, label.cex = 0.8))\n#> using the following vertex attributes:\n#> 120.8NAdarkbluenone0\n#> using the following edge attributes:\n#> 0.50.40.7black1\n```\n\n::: {.cell-output-display}\n![](confounding1_files/figure-html/dag1-1.png){width=672}\n:::\n:::\n\n\nAs per the DAG, L is a confounder. When exploring the relationship between A and Y, we need to adjust our model for L to get an unbiased estimate of A on Y. \n\n#### Generate Data\n\nNow, let us simulate the data using the defined parameters and the DAG. Below, we generate data for 1,000,000 participants. We set a seed 123 so that one can reproduce the same dataset. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(simcausal)\nObs.Data <- sim(DAG = Dset, n = 1000000, rndseed = 123)\nhead(Obs.Data)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"ID\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"L\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"A\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Y\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"9.439524\",\"3\":\"1\",\"4\":\"6.165097\",\"_rn_\":\"1\"},{\"1\":\"2\",\"2\":\"9.769823\",\"3\":\"1\",\"4\":\"6.040117\",\"_rn_\":\"2\"},{\"1\":\"3\",\"2\":\"11.558708\",\"3\":\"1\",\"4\":\"7.121178\",\"_rn_\":\"3\"},{\"1\":\"4\",\"2\":\"10.070508\",\"3\":\"0\",\"4\":\"4.943313\",\"_rn_\":\"4\"},{\"1\":\"5\",\"2\":\"10.129288\",\"3\":\"1\",\"4\":\"6.438245\",\"_rn_\":\"5\"},{\"1\":\"6\",\"2\":\"11.715065\",\"3\":\"1\",\"4\":\"7.073990\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n#### Estimate effect\n\nNow we will fit the generalized linear model (glm), without and with adjusting for L. \n\n\n::: {.cell hash='confounding1_cache/html/est_8a28358019f2f9889191d6f344392927'}\n\n```{.r .cell-code}\n# Not adjusted for L\nfit0 <- glm(Y ~ A, family=\"gaussian\", data=Obs.Data)\nround(coef(fit0),2)\n#> (Intercept)           A \n#>        4.69        1.75\n\n# Adjusted for L\nfit <- glm(Y ~ A + L, family=\"gaussian\", data=Obs.Data)\nround(coef(fit),2)\n#> (Intercept)           A           L \n#>         0.0         1.3         0.5\n```\n:::\n\n\n::: callout-important\nIn this case, our true treatment effect is 1.3. When we estimate the relationship between A and Y without adjusting for L, we obtain an estimated effect of 1.75. However, this is not the true effect. The true treatment effect of 1.3 is recovered when we adjust for L.\n::: \n\n### Null effect\n\n-   True treatment effect = 0\n\nLet us see the results when there is no treatment effect, i.s., the true treatment effect is zero.\n\n#### Data generating process\n\n\n::: {.cell hash='confounding1_cache/html/dgm2_9c78b8e0b27aa75351b038f631369d50'}\n\n```{.r .cell-code}\nrequire(simcausal)\nD <- DAG.empty()\nD <- D + \n  node(\"L\", distr = \"rnorm\", mean = 10, sd = 1) + \n  node(\"A\", distr = \"rbern\", prob = plogis(-10 + 1.1*L)) +\n  node(\"Y\", distr = \"rnorm\", mean = 0.5 * L + 0 * A, sd = .1)\nDset <- set.DAG(D)\n```\n:::\n\n\n#### Generate DAG\n\n\n::: {.cell hash='confounding1_cache/html/dag2_7d1f91abc875b03ba950a9dabc791471'}\n\n```{.r .cell-code}\nplotDAG(Dset, xjitter = 0.1, yjitter = .9,\n        edge_attrs = list(width = 0.5, arrow.width = 0.4, arrow.size = 0.7),\n        vertex_attrs = list(size = 12, label.cex = 0.8))\n```\n\n::: {.cell-output-display}\n![](confounding1_files/figure-html/dag2-1.png){width=672}\n:::\n:::\n\n\n#### Generate Data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(simcausal)\nObs.Data <- sim(DAG = Dset, n = 1000000, rndseed = 123)\nhead(Obs.Data)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"ID\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"L\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"A\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Y\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"9.439524\",\"3\":\"1\",\"4\":\"4.865097\",\"_rn_\":\"1\"},{\"1\":\"2\",\"2\":\"9.769823\",\"3\":\"1\",\"4\":\"4.740117\",\"_rn_\":\"2\"},{\"1\":\"3\",\"2\":\"11.558708\",\"3\":\"1\",\"4\":\"5.821178\",\"_rn_\":\"3\"},{\"1\":\"4\",\"2\":\"10.070508\",\"3\":\"0\",\"4\":\"4.943313\",\"_rn_\":\"4\"},{\"1\":\"5\",\"2\":\"10.129288\",\"3\":\"1\",\"4\":\"5.138245\",\"_rn_\":\"5\"},{\"1\":\"6\",\"2\":\"11.715065\",\"3\":\"1\",\"4\":\"5.773990\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n#### Estimate effect\n\n\n::: {.cell hash='confounding1_cache/html/est2_c41daa00d749215ccd3e3bece663dd1c'}\n\n```{.r .cell-code}\n# Not adjusted for L\nfit0 <- glm(Y ~ A, family = \"gaussian\", data = Obs.Data)\nround(coef(fit0),2)\n#> (Intercept)           A \n#>        4.69        0.45\n\n# Adjusted for L\nfit <- glm(Y ~ A + L, family = \"gaussian\", data = Obs.Data)\nround(coef(fit),2)\n#> (Intercept)           A           L \n#>         0.0         0.0         0.5\n```\n:::\n\n\n\n::: callout-important\nIn this second scenario, the true treatment effect is zero. There is no arrow from A to Y in the DAG, but L remains a common cause for both. Upon analyzing the data without adjusting for L, we observe an induced correlation between A and Y. This correlation disappears, confirming the true null effect, when we adjust for L.\n::: \n\n### Video content (optional)\n\n::: callout-tip\nFor those who prefer a video walkthrough, feel free to watch the video below, which offers a description of an earlier version of the above content.\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/EcX7ILtp9aQ\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}