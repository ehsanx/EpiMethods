{
  "hash": "6ae9da41a09df4175ba5bf4ea8f47601",
  "result": {
    "engine": "knitr",
    "markdown": "## Concepts (R) {.unnumbered}\n\n## Confounding\n\nConfounding is a pervasive concern in epidemiology, especially in observational studies focusing on causality. Epidemiologists need to carefully select confounders to avoid biased results due to third factors affecting the relationship between exposure and outcome. Commonly used methods for selecting confounders, such as change-in-estimator or solely relying on p-value-based statistical methods, may be inadequate or even problematic.\n\nEpidemiologists need a more formalized system for confounder selection, incorporating causal diagrams [@greenland1999causal; @tennant2021use] and counterfactual reasoning. This includes an understanding of the underlying causal relationships and the potential impacts of different variables on the observed association. Understanding the temporal order and causal pathways is crucial for accurate confounder control.\n\nHowever, it is possible that epidemiologists may lack comprehensive knowledge about the causal roles of all variables and hence may need to resort to empirical criteria [@vanderweele2019principles] such as the disjunctive cause criterion, or other variable selection methods such as machine learning approaches. While these methods can provide more sophisticated analyses and help address the high dimensionality and complex structures of modern epidemiological data, epidemiologists need to understand how these approaches function, along with their benefits and limitations, to avoid introducing additional bias into the analysis.\n\n## Effect modifier\n\n**Effect modification** and **interaction** are two distinct concepts in epidemiology [@vanderweele2009distinction; @bours2021tutorial]. Effect modification occurs when the causal effect of an exposure (A) on an outcome (Y) varies based on the levels of a third factor (B).\n\nIn this scenario, the association between the exposure and the outcome differs within the strata of a second exposure, which acts as the effect modifier. For instance, the impact of alcohol (A) on oral cancer (Y) might differ based on tobacco smoking (B).\n\nOn the other hand, interaction refers to the joint causal effect of two exposures (A and B) on an outcome (Y). It examines how the combination of multiple exposures influences the outcome, such as the combined effect of alcohol (A) and tobacco smoking (B) on oral cancer (Y).\n\nIn essence, while effect modification looks at how a third factor influences the relationship between an exposure and an outcome, interaction focuses on the combined effect of two exposures on the outcome.\n\n## Table 2 fallacy\n\nThe \"Table 2 Fallacy\" in epidemiology refers to the misleading practice of presenting multiple adjusted effect estimates from a single statistical model in one table, often resulting in misinterpretation. This occurs when researchers report both the primary exposure's effects and secondary exposures' (often an adjustment variable for the primary exposure) effects without adequately distinguishing between the types of effects or considering the causal relationships among variables.\n\nThis idea highlights the potential for misunderstanding in interpreting the effects of various exposures on an outcome when they are reported together, leading to confusion over the nature and magnitude of the relationships and possibly influencing the design and interpretation of further studies [@westreich2013table]. The fallacy demonstrates the need for careful consideration of the types of effects estimated and reported in statistical models, urging researchers to be clear about the distinctions and implications of controlled direct effects, total effects, and the presence of confounding or mediating variables.\n\n## Reading list\n\nConfounding key reference: [@vanderweele2019principles; @tennant2021use]\n\nEffect modification key reference: [@vanderweele2009distinction; @bours2021tutorial]\n\nTable 2 fallacy key reference: [@westreich2013table]\n\nOptional reading:\n\n-   [@greenland1999causal]\n-   [@lederer2019control]\n-   [@etminan2020using]\n-   [@heinze2018variable]\n\n## Video Lessons\n\n::: callout-tip\n### The Counterfactual Framework for Defining Causality\n\n#### Defining the Causal Effect: Potential Outcomes\n\nTo understand causality, one must first be able to imagine a world that does not exist. The potential outcomes framework formalizes this by defining the causal effect of an exposure in terms of what *would have happened* under different exposure scenarios. Let us define the key notations:\n\n-   **A**: The exposure status of an individual (e.g., $A=1$ if a smoker, $A=0$ if a non-smoker).\n-   **Y**: The outcome of interest (e.g., hypertension).\n-   **L**: A measured covariate or potential confounder.\n-   **U**: An unmeasured variable.\n\nFor any individual, we can define two **potential outcomes**:\n\n-   **Y(A=1)**: The outcome that would be observed if the individual were a smoker.\n-   **Y(A=0)**: The outcome that would be observed if that same individual were a non-smoker at the same point in time.\n\nThe **Individual Treatment Effect (TE)** is the difference between these two potential outcomes for a single person: $TE = Y(A=1) - Y(A=0)$. For example, if a patient named John smokes ($A=1$) and develops hypertension, while he *would not have* developed hypertension had he not smoked ($A=0$), the causal effect of smoking for John is present.\n\n#### The Fundamental Problem of Causal Inference\n\nThe definition of the individual TE immediately presents a profound challenge. For any given individual, we can only ever observe one of their potential outcomes. If John smokes, we observe $Y(A=1)$, but his counterfactual outcome, $Y(A=0)$, remains unobserved forever. This is known as the **fundamental problem of causal inference**; it is a problem of missing data where half the data is always missing for every subject.\n\nBecause the individual TE is unobservable, the goal of epidemiology shifts from the individual to the population. We instead seek to estimate the **Average Treatment Effect (ATE)**, defined as the average of the individual effects across all subjects in a population: $ATE = E$.\n\n#### From Association to Causation: The Role of Confounding\n\nIn the real world, we cannot directly observe both potential outcomes for a population. Instead, we observe outcomes in two different groups of people: those who happened to be exposed (smokers) and those who were not (non-smokers). We can calculate the **associational difference** between these groups: $E - E$. A critical error is to assume this associational difference is equal to the causal ATE.\n\nThis difference arises because of **confounding**. The groups of smokers and non-smokers may differ systematically on factors that also affect the outcome. For instance, individuals with lower socioeconomic status may be more likely to smoke and also have a higher underlying risk of hypertension for reasons unrelated to smoking (e.g., diet, stress). In this case, the observed difference in outcomes is a mixture of the true treatment effect and these pre-existing, systematic differences between the groups.\n\n#### The Observational Study Solution: Conditional Exchangeability\n\n**Randomized Controlled Trials (RCTs)** are the gold standard for causal inference because the process of randomization, with a large enough sample size, ensures that the exposed and unexposed groups are, on average, identical (\"exchangeable\") on all baseline characteristics, both measured and unmeasured. In an RCT, any systematic differences are eliminated, making the associational difference a valid estimate of the causal ATE.\n\nIn observational studies, where randomization is not possible, we cannot achieve this level of exchangeability. Instead, we strive for **conditional exchangeability**. This is the assumption that, within strata of the measured confounders, the exposed and unexposed groups are exchangeable. By estimating the effect of smoking separately within each level of the confounder(s) $L$ (e.g., estimating the effect of smoking separately for different age groups) and then averaging these stratum-specific effects, we can aim to reconstruct the causal ATE. This process of stratification, or \"adjustment,\" is the conceptual basis for controlling for confounding in observational research. However, its validity rests entirely on the critical and untestable assumption that we have successfully identified and measured all important common causes of the exposure and the outcome.\n\nWhat is included in this Video Lesson:\n\n-   0:00 Introduction\n-   0:16 Notations\n-   2:40 Treatment Effect\n-   6:13 Real-world Problem of the counterfactual definition\n-   9:44 Real-world Solution in Observational Setting\n\nThe timestamps are also included in the YouTube video description.\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/6MGvEVVijQc\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n::: callout-tip\n### Visualizing Causal Assumptions with Directed Acyclic Graphs (DAGs)\n\nTo properly address confounding, researchers need a tool to translate their subject-matter knowledge and assumptions about the world into a formal structure. **Directed Acyclic Graphs (DAGs)** serve this purpose, providing a visual language and a set of rigorous rules for identifying sources of bias and guiding statistical analysis.\n\n#### The Grammar of Causal Diagrams\n\nA DAG is a graphical model of causal relationships between variables. Its components follow a simple grammar:\n\n-   **Nodes**: Represent variables (e.g., smoking, hypertension, age).\n-   **Arrows (Directed Edges)**: Represent a direct causal effect from one variable to another.\n-   **Directed**: The arrows have a single head, indicating the assumed direction of causality.\n-   **Acyclic**: A path of arrows cannot form a closed loop. This enforces the principle of temporality: a variable cannot be its own cause.\n\nCrucially, the most powerful assumptions in a DAG are the **absent arrows**. The absence of an arrow between two variables represents a strong claim of no direct causal effect.\n\n#### Paths: Causal and Non-Causal\n\nA path is any sequence of arrows connecting two variables, regardless of the direction of the arrowheads. When assessing the relationship between an exposure like smoking ($A$) and an outcome like hypertension ($Y$), paths can be categorized into two critical types:\n\n-   **Causal Paths (Front-door paths)**: These are paths that begin with an arrow originating from $A$ and moving toward $Y$ (e.g., $A \\rightarrow \\text{Stress} \\rightarrow Y$). These paths transmit the causal effect of $A$ on $Y$ that we wish to estimate.\n-   **Non-Causal Paths (Back-door paths)**: These are paths between $A$ and $Y$ that begin with an arrow pointing *into* $A$ (e.g., $A \\leftarrow \\text{Age} \\rightarrow Y$). These paths are sources of non-causal association (confounding) that can bias our estimate. The goal of adjustment is to \"block\" these backdoor paths.\n\n#### The Three Elementary Causal Structures\n\nAll complex DAGs are composed of three fundamental building blocks. Understanding how information flows through these structures is the key to using DAGs to identify and control for bias.\n\n-   **The Fork (Confounding)**: The structure is $A \\leftarrow L \\rightarrow Y$. Here, $L$ is a **common cause** of both the exposure $A$ and the outcome $Y$.\n    -   *Example*: Age ($L$) is a common cause of both smoking habits ($A$) and hypertension ($Y$).\n    -   *Rule*: The backdoor path through a common cause is **open by default**, creating a spurious association. To remove this confounding, one must **condition on the confounder** $L$, which blocks the path.\n-   **The Chain (Mediation)**: The structure is $A \\rightarrow M \\rightarrow Y$. Here, $M$ is a **mediator** that lies on the causal pathway.\n    -   *Example*: Smoking ($A$) causes chronic inflammation ($M$), which in turn causes hypertension ($Y$).\n    -   *Rule*: The causal path through a mediator is **open by default**. To estimate the *total effect* of $A$ on $Y$, one **must not condition on the mediator** $M$. Doing so would block this part of the causal effect.\n-   **The Collider (Selection/Collider Bias)**: The structure is $A \\rightarrow L \\leftarrow Y$. Here, $L$ is a **common effect** of both $A$ and $Y$.\n    -   *Example*: Both smoking ($A$) and a genetic predisposition ($Y$) can lead to a specific biomarker level ($L$).\n    -   *Rule*: The path through a collider is **blocked by default**. However, **conditioning on the collider** $L$ *opens* the path, inducing a spurious, non-causal association between $A$ and $Y$. Adjusting for a collider is a critical error that introduces bias.\n\n#### Applying the Rules with Dagitty\n\nIn practice, causal systems can be highly complex. Software such as **Dagitty.net** automates the application of these path-blocking rules. Given a user-drawn DAG, Dagitty can identify all open backdoor paths and determine the **minimal sufficient adjustment sets**: the smallest set of covariates that, if conditioned on, will block all backdoor paths and allow for an unbiased estimation of the total causal effect.\n\nThe video lesson split into 3 parts\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/hvK0VIX8kxE\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/Y_9SQznhoXo\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/9Zglfijstdk\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n::: callout-important\n### DAG codes:\n\nExample DAG codes can be accessed from [this GitHub repository folder](https://github.com/ehsanx/EpiMethods/tree/main/DAGcodes)\n:::\n\n::: callout-tip\n### When the DAG is Unknown: Empirical Criteria\n\nIn the absence of a fully specified DAG, researchers can rely on a set of empirical criteria that require less stringent assumptions.\n\n-   **Pre-treatment Criterion**: Adjust for any variable that occurs chronologically before the exposure. This approach can fail by incorrectly adjusting for a pre-exposure collider, thereby inducing M-bias.\n-   **Common Cause Criterion**: Adjust only for variables known to be common causes of both the exposure and the outcome. This is often too conservative.\n-   **Disjunctive Cause Criterion**: This is a highly recommended practical strategy. It states that one should control for any pre-exposure covariate that is a cause of the exposure, **OR** a cause of the outcome, **OR** both. This criterion strikes a robust balance, ensuring sufficient adjustment under a wide range of unknown causal structures.\n-   **Modified Disjunctive Cause Criterion**: This refines the disjunctive criterion with crucial exceptions:\n    1.  **Exclude Instrumental Variables & Z-Bias**: An instrumental variable causes the exposure but does not affect the outcome except through the exposure. One must *avoid* adjusting for known instruments, as doing so can amplify bias due to unmeasured confounding, a phenomenon known as **Z-bias**.\n    2.  **Include Proxies for Unmeasured Confounders**: If a true common cause is unmeasured, one should adjust for a measured variable that serves as a proxy for it, as this will typically reduce bias.\n-   Finally, to estimate the *total causal effect*, any known mediators on the causal pathway must also be excluded from the adjustment set.\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/snx3nD3Oyvg\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n::: callout-tip\n### Modelling criteria for variable selection\n\nStatistical methods can also be used for variable selection, but their application requires careful consideration of the research goal: prediction versus causal inference.\n\n-   **Change-in-Estimate**: This method retains a covariate if its inclusion changes the exposure effect estimate by a certain threshold (e.g., 10%). However, this approach is flawed and not valid for non-collapsible effect measures, such as odds ratios (ORs) and hazard ratios (HRs). For these measures, a change in the estimate can occur even in the absence of confounding.\n-   **Statistical Significance**: Methods like **stepwise regression** using p-values or AIC are strongly discouraged for confounder selection. They are designed for prediction, not causal inference, and result in invalid p-values and confidence intervals for the final model.\n-   **Machine Learning**: Algorithms like LASSO and Random Forests are excellent for high-dimensional **prediction**. Their primary role in causal inference is in developing **propensity score (PS) models**, which is a prediction task. The goal is to create a score that balances measured covariates between the exposed and unexposed groups, mimicking randomization.\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/Rxg-x-MZykc\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n::: callout-tip\n## Collapsibility and the Choice of Effect Measure\n\nA crucial, and often overlooked, aspect of statistical adjustment is the concept of **collapsibility**. An effect measure is said to be collapsible if the marginal (crude) measure of association is equal to a weighted average of the stratum-specific measures of association after conditioning on another variable. This property has profound implications for how we interpret adjusted estimates.\n\nIn the absence of confounding, some effect measures, like the **Risk Difference (RD)** and **Risk Ratio (RR)**, are collapsible. This means that if a variable is not a confounder, adjusting for it will not change the effect estimate. However, other common measures, most notably the **Odds Ratio (OR)**, are **non-collapsible**.\n\nThe non-collapsibility of the odds ratio is a mathematical property stemming from the non-linearity of the logistic model's link function. It means that the adjusted OR can be different from the crude OR even when there is no confounding. This phenomenon, where an association in a population differs from the association within its subgroups, is also known as **Simpson's Paradox** (in the absence of confounding). This is precisely why the change-in-estimate criterion for confounder selection is invalid when using odds ratios—a change in the OR upon adjustment does not necessarily signal the presence of confounding.\n:::\n\n::: callout-tip\n### Simpson's Paradox: A Case Study in Bias\n\n**Simpson's Paradox** is a statistical phenomenon where an association observed in a population is different from—and often in the opposite direction of—the associations observed in all of its subgroups. This paradox is a powerful illustration of how failing to account for a key third variable (a confounder or a collider) can lead to completely erroneous conclusions.\n\nA famous example is the **\"Birthweight Paradox,\"** where maternal smoking appeared to be protective against infant mortality among low-birthweight infants, a finding that contradicted the known harms of smoking. This occurred because birthweight acted as a collider. Adjusting for it induced a spurious association between smoking and other unmeasured causes of mortality (e.g., birth defects).\n:::\n\n::: callout-tip\n### Unpacking Effect Heterogeneity: Interaction vs. Effect Modification\n\nThe effect of an exposure may not be uniform across a population. A third variable can alter the exposure-outcome relationship, a phenomenon that leads to frequent confusion between two distinct concepts: interaction and effect modification.\n\n#### Formal Definitions\n\nWhile often used interchangeably, these terms address different causal questions:\n\n-   **Effect Modification**: This occurs when the causal effect of a **single exposure** (e.g., smoking) on an outcome (hypertension) differs across strata of a second variable (e.g., education level). The question is: \"Is the effect of smoking different for people with high education versus people with low education?\" This involves only **one intervention** (on smoking). The variable 'education' is treated as a baseline characteristic defining subgroups.\n-   **Interaction**: This refers to the **joint causal effect** of **two exposures** (e.g., smoking and low education) on an outcome (hypertension). The question is: \"Is the effect of intervening on both smoking and education greater than the sum of the effects of intervening on each one alone?\" This involves **two distinct interventions** and assesses synergy or antagonism.\n\n#### Implications for Confounding Control\n\nThe distinction is critical for analytical strategy:\n\n-   **To assess Effect Modification**: When investigating if education modifies the effect of smoking on hypertension, a researcher only needs to control for the set of confounders of the `smoking -> hypertension` relationship.\n-   **To assess Interaction**: When investigating the causal interaction between smoking and education, a researcher must control for **all** confounders of the `smoking -> hypertension` relationship **AND** **all** confounders of the `education -> hypertension` relationship. This is a much more demanding requirement.\n\n#### The Role of the Scale: Effect Measure Modification\n\nWhether modification is detected can depend on the statistical scale used (e.g., additive scale for Risk Difference vs. multiplicative scale for Risk Ratio). For this reason, the more precise term is **effect measure modification**. A statistical finding of interaction is a property of the chosen model and does not necessarily correspond to a specific biological mechanism.\n\n#### Reporting guideline\n\nSee @knol2012recommendations\n:::\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped table-hover table-condensed\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n<caption>Comparison of Reporting Guidelines (Knol &amp; Vanderweele, 2012)</caption>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Recommendations from Knol &amp; Vanderweele (2012)</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> Reporting Component </th>\n   <th style=\"text-align:left;\"> Guideline for Effect Modification </th>\n   <th style=\"text-align:left;\"> Guideline for Interaction </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;width: 15em; font-weight: bold;\"> Purpose </td>\n   <td style=\"text-align:left;width: 30em; \"> To show how the effect of one primary exposure (A) is modified by the strata of another factor (X). </td>\n   <td style=\"text-align:left;width: 30em; \"> To show the causal, joint effect of two distinct exposures (A and B) acting together. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 15em; font-weight: bold;\"> Step 1: Joint Effects </td>\n   <td style=\"text-align:left;width: 30em; \"> Required. \n (e.g., ORs for all A/X combinations vs. a single reference, A=0, X=0). </td>\n   <td style=\"text-align:left;width: 30em; \"> Required. \n (e.g., ORs for all A/B combinations vs. a single reference, A=0, B=0). </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 15em; font-weight: bold;\"> Step 2: Stratum-Specific Effects </td>\n   <td style=\"text-align:left;width: 30em; \"> Required (SUBSET). \n Show only the effect of A within each stratum of X. </td>\n   <td style=\"text-align:left;width: 30em; \"> Required (FULL). \n Show the effect of A within each stratum of B... \n ...AND... \n ...the effect of B within each stratum of A. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 15em; font-weight: bold;\"> Step 3: Interaction Measures </td>\n   <td style=\"text-align:left;width: 30em; \"> Required. \n Report measures for both additive (e.g., RERI) and multiplicative (e.g., ROR) scales, with CIs and p-values. </td>\n   <td style=\"text-align:left;width: 30em; \"> Required. \n Report measures for both additive (e.g., RERI) and multiplicative (e.g., ROR) scales, with CIs and p-values. </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;width: 15em; font-weight: bold;\"> Step 4: Confounder Adjustment </td>\n   <td style=\"text-align:left;width: 30em; \"> Required. \n Adjust for confounders of the primary A-D relationship. </td>\n   <td style=\"text-align:left;width: 30em; \"> Required. \n Adjust for confounders of *both* the A-D relationship *and* the B-D relationship. </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/cxfwqBD1M1c\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n::: callout-important\nTo revisit or deepen your grasp of these two concepts, consider reviewing this [external tutorial](https://ehsanx.github.io/interaction/).\n:::\n\n::: callout-tip\n### Avoiding Misinterpretation: The Table 2 Fallacy\n\nOne of the most common errors in reporting observational research is the **Table 2 Fallacy**. This fallacy is the practice of presenting a single multivariable regression model and interpreting the coefficients for all variables—the primary exposure and all adjustment covariates—as if they are equally valid estimates of the total causal effect of each variable on the outcome.\n\n#### Why A Single Model Fails: A DAG-Based Explanation\n\nA multivariable regression model is built to answer a single, specific causal question. The adjustment set required to estimate the causal effect of one variable is often different from the set required to estimate the effect of another.\n\nConsider a DAG for the effects of smoking, age, and hypertension:\n\n-   **Causal Question 1: What is the total effect of Smoking on Hypertension?**\n    -   Assume Age is a common cause of both Smoking and Hypertension. To get an unbiased estimate of the total effect of Smoking, one must adjust for Age. The appropriate model is: `Hypertension ~ Smoking + Age`. The coefficient for Smoking can be interpreted as the total causal effect.\n-   **Causal Question 2: What is the total effect of Age on Hypertension?**\n    -   In this same DAG, Smoking may be a *mediator* of the effect of Age (i.e., `Age -> Smoking -> Hypertension`). To estimate the *total* effect of Age, one must *not* adjust for the mediator, Smoking. The model built for Question 1 *does* adjust for Smoking. Therefore, the coefficient for Age in that first model is not an estimate of the total effect; it is an estimate of the **controlled direct effect**—the effect of Age on Hypertension that does not operate through the Smoking pathway.\n\n#### Best Practices for Reporting\n\nTo avoid the Table 2 Fallacy, analysis and reporting must be driven by a \"one exposure, one model\" principle:\n\n-   **Be Explicit**: Clearly state the single primary exposure of interest for each model.\n-   **Use Multiple Models**: If causal effects are desired for multiple variables, fit a separate, correctly specified model for each one.\n-   **Structure Tables Clearly**: The primary results table should only show the effect estimate for the main exposure of interest. The covariates used for adjustment should be listed in a footnote, not in the table with their own effect estimates.\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/W5nFdiP5pU4\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n## Video Lesson Slides\n\nConfounding\n\n<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vSR5-qmF6Zfyh0WjwLLdVWuIYnJ9MSYb-BjmA0ZITQOaYkl8bzGVRMsKxbJemNFyUN5krjnoxsHMUSw/embed?start=false&amp;loop=false&amp;delayms=3000\" frameborder=\"0\" width=\"672\" height=\"398\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n\n</iframe>\n\n<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vRmSc87F_iAhDO5jWlTZ6UXmBwMOSS1sIgEywkzLbIT86pWJgOBI1KxUO7h4cbQQqU8nVYbHu-cpGie/embed?start=false&amp;loop=false&amp;delayms=3000\" frameborder=\"0\" width=\"672\" height=\"398\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n\n</iframe>\n\nEffect modification\n\n<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vQLJMvwzbtNCkjMMcir5lwLfQyUAjn52IQ2KhMwQqimCuTYNmqO8UCK2j8NBR-980n21JYSDK6RW-ad/embed?start=false&amp;loop=false&amp;delayms=3000\" frameborder=\"0\" width=\"672\" height=\"398\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n\n</iframe>\n\nTable 2 fallacy\n\n<iframe src=\"https://docs.google.com/presentation/d/e/2PACX-1vTZgDExI3XV75PFJ4f75XOg6RQi0Umrqca-mZPOapBvd_z5d7UPdWsRZGo40lBJNhbx0TKb1jewcwUG/embed?start=false&amp;loop=false&amp;delayms=3000\" frameborder=\"0\" width=\"672\" height=\"398\" allowfullscreen=\"true\" mozallowfullscreen=\"true\" webkitallowfullscreen=\"true\">\n\n</iframe>\n\n## Links\n\nConfounding\n\n-   [Google Slides](https://docs.google.com/presentation/d/1q1Q_memf2MbCSFtYVQP26BDaKz_jAOHCYicxc4t2DrM/edit?usp=sharing)\n-   [PDF Slides](slides/Confounder.pdf)\n\nEffect modification\n\n-   [Google Slides](https://docs.google.com/presentation/d/1q-RTYkiQV8tCbn71BGL3V11jjlGgq1oBfZwavLuWOks/edit?usp=sharing)\n-   [PDF Slides](slides/interaction.pdf)\n\nTable 2 fallacy\n\n-   [Google Slides](https://docs.google.com/presentation/d/1XL3CXHfWpzFtawJmTsLG0ypbf-vKvZJWTM7-QJ5fohw/edit?usp=sharing)\n-   [PDF Slides](slides/table2.pdf)\n-   [External link from dagitty](https://dagitty.net/learn/graphs/table2-fallacy.html)\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}