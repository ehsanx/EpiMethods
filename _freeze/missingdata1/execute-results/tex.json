{
  "hash": "850a4113181a032e518f7561c37b3db7",
  "result": {
    "markdown": "## Imputation {.unnumbered}\n\n### What is imputation?\n\nImputation is the process of replacing missing data with substituted values. In health research, it's common to have missing data. This tutorial teaches you how to handle and replace these missing values using the mice package in R.\n\n### Why is imputation important?\n\nMissing data can lead to biased or incorrect results. Imputation helps in making the dataset complete, which can lead to more accurate analyses.\n\n### Key reference\n\nIn this discussion, our primary guide and source of information is the work titled \"Flexible Imputation of Missing Data\" by Stef van Buuren, denoted here as [@van2018flexible]. This book is an invaluable resource for anyone looking to delve deeper into the intricacies of handling missing data, especially in the context of statistical analyses. Below we also cited the relevant section numbers.\n\nFirst, you need to load the necessary libraries:\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/setup_75fdd9aa94d63607640329bc13579c98'}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(mice)\nlibrary(DataExplorer)\nlibrary(VIM)\nlibrary(mitools)\n```\n:::\n\n\n\n### Type of missing data\n\n-   Ref: [@van2018flexible], Section 1.2\n\nIn this section, we are going to introduce three types of missing data that we will encounter in data analysis.\n\n1.  **Missing Completely at Random (MCAR)**:\n\nThe reason data is missing is completely random and not related to any measured or unmeasured variables. It's often an unrealistic assumption.\n\n2.  **Missing at Random (MAR)**:\n\nThe missing data is related to variables that are observed.\n\n3.  **Missing Not at Random (MNAR)**:\n\nThe missing data is related to variables that are not observed.\n\n### Why does missingness type matter?\n\nThe type of missingness affects how you handle the missing data:\n\n-   If data is MCAR, you can still analyze the complete cases without introducing bias.\n-   If data is MAR, you can use imputation to replace the missing values.\n-   If data is MNAR, it's challenging to address, and estimates will likely be biased. We could do some sensitivity analyses to check the impact.\n\n### Video content (optional)\n\n::: callout-tip\nFor those who prefer a video walkthrough, feel free to watch the video below, which offers a description of an earlier version of the above content.\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/KnBkYkHfGG0\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n### Data imputation\n\n#### Getting to know the data\n\nBefore imputing, you should understand the data. The tutorial uses the `analytic.with.miss` dataset from NHANES. Various plots and functions are used to inspect the missing data pattern and relationships between variables.\n\n::: callout-important\n1.  Take a look here for those who are interested in how the [analytic data](https://ehsanx.github.io/SurveyDataAnalysis/) was created.\n\n2.  For the purposes of this lab, we are just going to treat the data as SRS, and not going to deal with intricacies of survey data analysis.\n:::\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/load_6053f200c9cc164254beefbafd2560ba'}\n\n```{.r .cell-code}\nrequire(VIM)\nload(\"Data/missingdata/NHANES17.RData\")\nNHANES17s <- analytic.with.miss[1:30,c(\"age\", \"bmi\", \"cholesterol\",\"diastolicBP\")]\nNHANES17s\n#>    age  bmi cholesterol diastolicBP\n#> 1   NA 17.5          NA          NA\n#> 2   NA 15.7          NA          NA\n#> 3   66 31.7         157          NA\n#> 4   NA 21.5         148          74\n#> 5   NA 18.1         189          38\n#> 6   66 23.7         209          NA\n#> 7   75 38.9         176          66\n#> 8   NA   NA          NA          NA\n#> 9   56 21.3         238          68\n#> 10  NA 19.7         182          68\n#> 11  67 23.5         184          70\n#> 12  54 39.9         230          NA\n#> 13  71 22.5         180          60\n#> 14  61 30.7         225          72\n#> 15  22 24.5         213          62\n#> 16  45 22.0         152          88\n#> 17  NA 26.0          97          62\n#> 18  NA   NA          NA          NA\n#> 19  60 35.9         122          68\n#> 20  60 23.8         184          68\n#> 21  64 22.4         202          72\n#> 22  NA 14.7          NA          NA\n#> 23  NA 16.1          NA          NA\n#> 24  67 31.1         176          52\n#> 25  70 23.9         167          NA\n#> 26  53 33.4         143          74\n#> 27  42 27.6         165          86\n#> 28  57 28.6         221          74\n#> 29  20 27.6         153          54\n#> 30  72 21.3          NA          76\nNHANES17s[complete.cases(NHANES17s),]\n#>    age  bmi cholesterol diastolicBP\n#> 7   75 38.9         176          66\n#> 9   56 21.3         238          68\n#> 11  67 23.5         184          70\n#> 13  71 22.5         180          60\n#> 14  61 30.7         225          72\n#> 15  22 24.5         213          62\n#> 16  45 22.0         152          88\n#> 19  60 35.9         122          68\n#> 20  60 23.8         184          68\n#> 21  64 22.4         202          72\n#> 24  67 31.1         176          52\n#> 26  53 33.4         143          74\n#> 27  42 27.6         165          86\n#> 28  57 28.6         221          74\n#> 29  20 27.6         153          54\nmd.pattern(NHANES17s) \n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/load-1.pdf){fig-pos='H'}\n:::\n\n```\n#>    bmi cholesterol age diastolicBP   \n#> 15   1           1   1           1  0\n#> 4    1           1   1           0  1\n#> 4    1           1   0           1  1\n#> 1    1           0   1           1  1\n#> 4    1           0   0           0  3\n#> 2    0           0   0           0  4\n#>      2           7  10          10 29\n# Inspect the missing data pattern (each row = pattern)\n# possible missingness (0,1) pattern and counts\n# last col = missing counts for each variables\n# last row = how many variable values missing in the row\n# First col: Frequency of the pattern \n# e,g, 2 cases missing for bmi\n\nrequire(DataExplorer)\nplot_missing(NHANES17s)\n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/load-2.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\n# check the missingness\n\nrequire(VIM)\nmarginplot(NHANES17s[, c(\"diastolicBP\", \"bmi\")])\n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/load-3.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\nmarginplot(NHANES17s[, c(\"diastolicBP\", \"cholesterol\")])\n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/load-4.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\nmarginplot(NHANES17s[, c(\"cholesterol\", \"bmi\")])\n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/load-5.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\n# distribution of observed data given the other variable is observed\n# for MCAR, blue and red box plots should be similar\n```\n:::\n\n\n\n#### Single imputation\n\n-   Ref: [@van2018flexible], Section 1.3\n\nImpute NA only once. Below are some examples [@van2011mice]:\n\n##### Mean imputation\n\n-   Ref: [@van2018flexible], Section 1.3.3, and [@buuren2010mice]\n\nMean imputation is a straightforward method where missing values in a dataset are replaced with the mean of the observed values. While it's simple and intuitive, this approach can reduce the overall variability of the data, leading to an underestimation of variance. This can be problematic in statistical analyses where understanding data spread is crucial.\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/meanimp_a0aa01a1bcb073ad3aa1eb507383db39'}\n\n```{.r .cell-code}\n# Replace missing values by mean \nimputation1 <- mice(NHANES17s, \n                   method = \"mean\", # Replace by mean of the other values\n                   m = 1, # Number of multiple imputations. \n                   maxit = 1) # Number of iteration; mostly useful for convergence\n#> \n#>  iter imp variable\n#>   1   1  age  bmi  cholesterol  diastolicBP\nimputation1$imp\n#> $age\n#>       1\n#> 1  57.4\n#> 2  57.4\n#> 4  57.4\n#> 5  57.4\n#> 8  57.4\n#> 10 57.4\n#> 17 57.4\n#> 18 57.4\n#> 22 57.4\n#> 23 57.4\n#> \n#> $bmi\n#>           1\n#> 8  25.12857\n#> 18 25.12857\n#> \n#> $cholesterol\n#>           1\n#> 1  178.8261\n#> 2  178.8261\n#> 8  178.8261\n#> 18 178.8261\n#> 22 178.8261\n#> 23 178.8261\n#> 30 178.8261\n#> \n#> $diastolicBP\n#>       1\n#> 1  67.6\n#> 2  67.6\n#> 3  67.6\n#> 6  67.6\n#> 8  67.6\n#> 12 67.6\n#> 18 67.6\n#> 22 67.6\n#> 23 67.6\n#> 25 67.6\ncomplete(imputation1, action = 1) # this is a function from mice\n#>     age      bmi cholesterol diastolicBP\n#> 1  57.4 17.50000    178.8261        67.6\n#> 2  57.4 15.70000    178.8261        67.6\n#> 3  66.0 31.70000    157.0000        67.6\n#> 4  57.4 21.50000    148.0000        74.0\n#> 5  57.4 18.10000    189.0000        38.0\n#> 6  66.0 23.70000    209.0000        67.6\n#> 7  75.0 38.90000    176.0000        66.0\n#> 8  57.4 25.12857    178.8261        67.6\n#> 9  56.0 21.30000    238.0000        68.0\n#> 10 57.4 19.70000    182.0000        68.0\n#> 11 67.0 23.50000    184.0000        70.0\n#> 12 54.0 39.90000    230.0000        67.6\n#> 13 71.0 22.50000    180.0000        60.0\n#> 14 61.0 30.70000    225.0000        72.0\n#> 15 22.0 24.50000    213.0000        62.0\n#> 16 45.0 22.00000    152.0000        88.0\n#> 17 57.4 26.00000     97.0000        62.0\n#> 18 57.4 25.12857    178.8261        67.6\n#> 19 60.0 35.90000    122.0000        68.0\n#> 20 60.0 23.80000    184.0000        68.0\n#> 21 64.0 22.40000    202.0000        72.0\n#> 22 57.4 14.70000    178.8261        67.6\n#> 23 57.4 16.10000    178.8261        67.6\n#> 24 67.0 31.10000    176.0000        52.0\n#> 25 70.0 23.90000    167.0000        67.6\n#> 26 53.0 33.40000    143.0000        74.0\n#> 27 42.0 27.60000    165.0000        86.0\n#> 28 57.0 28.60000    221.0000        74.0\n#> 29 20.0 27.60000    153.0000        54.0\n#> 30 72.0 21.30000    178.8261        76.0\n# there is another function in tidyr with the same name!\n# use mice::complete() to avoid conflict\n## the imputed dataset\n```\n:::\n\n\n\n##### Regression Imputation\n\n-   Ref: [@van2018flexible], Section 1.3.4\n\nRegression imputation offers a more nuanced approach, especially when dealing with interrelated variables. By building a regression model using observed data, missing values are predicted based on the relationships between variables. This method can provide more accurate estimates for missing values by leveraging the inherent correlations within the data, making it a preferred choice in many scenarios over mean imputation.\n\n$Y \\sim X$\n\n$age \\sim bmi + cholesterol + diastolicBP$\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/regimp_4928170e652a4224898e68473814b8cb'}\n\n```{.r .cell-code}\nimputation2 <- mice(NHANES17s, \n            method = \"norm.predict\", # regression imputation\n            seed = 1,\n            m = 1, \n            print = FALSE)\n\n# look at all imputed values\nimputation2$imp\n#> $age\n#>           1\n#> 1  55.32215\n#> 2  54.99604\n#> 4  55.65437\n#> 5  53.68539\n#> 8  56.70424\n#> 10 55.79329\n#> 17 54.38372\n#> 18 56.70422\n#> 22 54.81486\n#> 23 55.06851\n#> \n#> $bmi\n#>           1\n#> 8  25.12857\n#> 18 25.12857\n#> \n#> $cholesterol\n#>           1\n#> 1  183.3772\n#> 2  184.2347\n#> 8  179.7431\n#> 18 179.7431\n#> 22 184.7111\n#> 23 184.0442\n#> 30 183.4399\n#> \n#> $diastolicBP\n#>           1\n#> 1  66.48453\n#> 2  66.24254\n#> 3  68.82463\n#> 6  67.47980\n#> 8  67.51011\n#> 12 68.91318\n#> 18 67.51011\n#> 22 66.10810\n#> 23 66.29631\n#> 25 67.93401\n\n# examine the correlation between age and bmi before and after imputation\nfit1 <- lm(age ~ bmi, NHANES17s) \n\nsummary(fit1) ## original data\n#> \n#> Call:\n#> lm(formula = age ~ bmi, data = NHANES17s)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -37.383  -5.194   3.168   9.444  15.965 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)   \n#> (Intercept)  53.3482    17.1585   3.109  0.00606 **\n#> bmi           0.1462     0.6063   0.241  0.81219   \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 15.51 on 18 degrees of freedom\n#>   (10 observations deleted due to missingness)\n#> Multiple R-squared:  0.003219,\tAdjusted R-squared:  -0.05216 \n#> F-statistic: 0.05814 on 1 and 18 DF,  p-value: 0.8122\nsqrt(summary(fit1)$r.squared)\n#> [1] 0.05674047\n\nfit2 <- lm(age ~ bmi, mice::complete(imputation2)) \nsummary(fit2) ## imputed complete data\n#> \n#> Call:\n#> lm(formula = age ~ bmi, data = mice::complete(imputation2))\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -37.152  -1.407   0.000   8.026  15.989 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  52.1516     9.2485   5.639 4.86e-06 ***\n#> bmi           0.1812     0.3568   0.508    0.616    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 12.45 on 28 degrees of freedom\n#> Multiple R-squared:  0.009127,\tAdjusted R-squared:  -0.02626 \n#> F-statistic: 0.2579 on 1 and 28 DF,  p-value: 0.6155\nsqrt(summary(fit2)$r.squared)\n#> [1] 0.09553283\n## Relationship become stronger before imputation. \n# with(data=NHANES17s, cor(age, bmi, use = \"complete.obs\"))\n\nwith(data=NHANES17s, cor(age, bmi, use = \"pairwise.complete.obs\"))\n#> [1] 0.05674047\nwith(data = mice::complete(imputation2), cor(age, bmi))\n#> [1] 0.09553283\n```\n:::\n\n\n\n##### Stochastic regression imputation\n\n-   Ref: [@van2018flexible], Section 1.3.5\n\nRegression imputation, while powerful, has an inherent limitation. When it employs the fitted model to predict missing values, it does so without incorporating the error terms. This means that the imputed values are precisely on the regression line, leading to an overly perfect fit. As a result, the natural variability present in real-world data is not captured, causing the imputed dataset to exhibit biased correlations and reduced variance. Essentially, the data becomes too \"clean,\" and this lack of variability can mislead subsequent analyses, making them overly optimistic or even erroneous.\n\nRecognizing this limitation, stochastic regression imputation was introduced as an enhancement. Instead of merely using the fitted model, it adds a randomly drawn error term during the imputation process. This error term reintroduces the natural variability that the original regression imputation method missed. By doing so, the imputed values are scattered around the regression line, more accurately reflecting the true correlations and distributions in the dataset. This method, therefore, offers a more realistic representation of the data, ensuring that subsequent analyses are grounded in a dataset that mirrors genuine variability and relationships.\n\n$Y \\sim X + e$\n\n$age \\sim bmi + cholesterol + diastolicBP + error$\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/impsto_1511260d60e1c385783d6bac01829e83'}\n\n```{.r .cell-code}\nimputation3 <- mice(NHANES17s, method = \"norm.nob\", # stochastic regression imputation\n                    m = 1, maxit = 1, seed = 504, print = FALSE)\n\n# look at all imputed values\nimputation3$imp\n#> $age\n#>           1\n#> 1  79.59513\n#> 2  53.94601\n#> 4  73.76486\n#> 5  43.69817\n#> 8  49.70112\n#> 10 43.81002\n#> 17 29.72590\n#> 18 61.15172\n#> 22 58.75506\n#> 23 78.39545\n#> \n#> $bmi\n#>           1\n#> 8  27.53270\n#> 18 31.52568\n#> \n#> $cholesterol\n#>           1\n#> 1  252.2928\n#> 2  209.7680\n#> 8  169.2450\n#> 18 107.7585\n#> 22 181.8617\n#> 23 239.9008\n#> 30 131.8489\n#> \n#> $diastolicBP\n#>           1\n#> 1  75.02181\n#> 2  44.45935\n#> 3  86.69637\n#> 6  60.54256\n#> 8  63.80884\n#> 12 60.03311\n#> 18 73.94575\n#> 22 36.70323\n#> 23 73.95647\n#> 25 65.84012\n#mice::complete(imputation3)\n\n# examine the correlation between age and bmi before and after imputation\nfit1 <- lm(age ~ bmi, NHANES17s) \nsummary(fit1) \n#> \n#> Call:\n#> lm(formula = age ~ bmi, data = NHANES17s)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -37.383  -5.194   3.168   9.444  15.965 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)   \n#> (Intercept)  53.3482    17.1585   3.109  0.00606 **\n#> bmi           0.1462     0.6063   0.241  0.81219   \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 15.51 on 18 degrees of freedom\n#>   (10 observations deleted due to missingness)\n#> Multiple R-squared:  0.003219,\tAdjusted R-squared:  -0.05216 \n#> F-statistic: 0.05814 on 1 and 18 DF,  p-value: 0.8122\nfit3 <- lm(age ~ bmi, mice::complete(imputation3)) \nsummary(fit3)\n#> \n#> Call:\n#> lm(formula = age ~ bmi, data = mice::complete(imputation3))\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -37.089  -6.691   3.183  10.104  21.288 \n#> \n#> Coefficients:\n#>             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)  60.4173    11.4671   5.269 1.33e-05 ***\n#> bmi          -0.1206     0.4371  -0.276    0.785    \n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 15.53 on 28 degrees of freedom\n#> Multiple R-squared:  0.002712,\tAdjusted R-squared:  -0.03291 \n#> F-statistic: 0.07614 on 1 and 28 DF,  p-value: 0.7846\n## Fitted coefficients of bmi are much closer before and after imputation\n# with(data=NHANES17s, cor(age, bmi, use = \"complete.obs\"))\n\nwith(data=NHANES17s, cor(age, bmi, use = \"pairwise.complete.obs\"))\n#> [1] 0.05674047\nwith(data = mice::complete(imputation3), cor(age, bmi))\n#> [1] -0.05207502\n# see the direction change?\n```\n:::\n\n\n\n##### Predictive mean matching\n\nPredictive Mean Matching (PMM) is an advanced imputation technique that aims to provide more realistic imputations for missing data. Let's break it down:\n\nIn this context, we're trying to fill in missing values for the variable 'age'. To do this, we use other variables like 'bmi', 'cholesterol', and 'diastolicBP' to predict 'age'. First, a regression model is run using the available data to estimate the relationship between 'age' and the predictor variables. From this model, we get a coefficient, which is then adjusted slightly to introduce some randomness. Using this adjusted coefficient, we predict the missing 'age' values for all subjects. For example, if 'subject 19' has a missing age value, we might predict it to be 45.5 years. Instead of using this predicted value directly, we look for other subjects who have actual age values and whose predicted ages are close to 45.5 years. From these subjects, one is randomly chosen, and their real age is used as the imputed value for 'subject 19'. In this way, PMM ensures that the imputed values are based on real, observed data from the dataset.\n\n::: callout-tip\n-   Assume $Y$ = `age`, a variable with some missing values. $X$ (say, `bmi`, `cholesterol`, `diastolicBP`) are predictors of $Y$.\n-   Estimate beta coef $\\beta$ from complete case running $Y \\sim X + e$\n-   generate new $\\beta* \\sim Normal(b,se_b)$.\n-   using $\\beta*$, predict new $\\hat{Y}$ `predicted age` for all subjects (those with missing and observed `age`):\n    -   If `subject 19` (say) has missing values in `age` variable, find out his `predicted age` $\\hat{Y}$ (say, 45.5).\n    -   Find others subjects, `subjects 2, 15, 24` (say) who has their `age` measured and their predicted age $\\hat{Y}$ (say, `predicted ages` 43.9,45.7,46.1 with real ages 43,45,46 respectively) are close to `subject 19` (predicted age 45.5).\n    -   Randomly select `subject 2` with real/observed age 43, and impute 43 for `subject 19`'s missing age.\n:::\n\nThe strength of PMM lies in its approach. Instead of imputing a potentially artificial value based on a prediction, it imputes a real, observed value from the dataset. This ensures that the imputed data retains the original data's characteristics and doesn't introduce any unrealistic values. It offers a safeguard against extrapolation, ensuring that the imputed values are always within the plausible range of the dataset.\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/imppmm_41ecaf090056b8036c894e7209ca9de3'}\n\n```{.r .cell-code}\nimputation3b <- mice(NHANES17s, method = \"pmm\", \n                    m = 1, maxit = 1,\n                    seed = 504, print = FALSE)\nwith(data=NHANES17s, cor(age, bmi, use = \"pairwise.complete.obs\"))\n#> [1] 0.05674047\nwith(data = mice::complete(imputation3b), cor(age, bmi))\n#> [1] -0.08029207\n```\n:::\n\n\n\n##### Video content (optional)\n\n::: callout-tip\nFor those who prefer a video walkthrough, feel free to watch the video below, which offers a description of an earlier version of the above content.\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/TO_HlHuHbgU\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n#### Multiple imputation and workflow\n\n-   Ref: [@van2018flexible], Sections 1.4 and 5.1\n-   Ref: [@buuren2010mice]\n\nWe have learned different methods of imputation. In this section, we will introduce how to incorporate the data imputation into data analysis. In multiple imputation data analysis, three steps will be taken:\n\n-   **Step 0: Set imputation model**: Before starting the imputation process, it's crucial to determine the appropriate imputation model based on the nature of the missing data and the relationships between variables. This model will guide how the missing values are estimated. For instance, if the data is missing at random, a linear regression model might be used for continuous data, while logistic regression might be used for binary data. The choice of model can significantly impact the quality of the imputed data, so it's essential to understand the underlying mechanisms causing the missingness and select a model accordingly.\n\n-   **Step 1: The incomplete dataset will be imputed** $m$ times: In this step, the incomplete dataset is imputed multiple times, resulting in $m$ different \"complete\" datasets. The reason for creating multiple datasets is to capture the uncertainty around the missing values. Each of these datasets will have slightly different imputed values, reflecting the variability and uncertainty in the imputation process. The number of imputations, $m$, is typically chosen based on the percentage of missing data and the desired level of accuracy. Common choices for $m$ range from 5 to 50, but more imputations provide more accurate results, especially when the percentage of missing data is high.\n\n-   **Step 2: Each** $m$ complete datasets will be analyzed separately by standard analysis (e.g., regression model): Once the $m$ complete datasets are generated, each one is analyzed separately using standard statistical methods. For example, if the research question involves understanding the relationship between two variables, a regression model might be applied to each dataset. This step produces $m$ sets of analysis results, one for each imputed dataset.\n\n-   **Step 3: The analysis results will be pooled / aggregated together by Rubin's rules (1987)**: The final step involves combining the results from the $m$ separate analyses into a single set of results. This is done using Rubin's rules (1987) [@little1987multiple], which provide a way to aggregate the estimates and adjust for the variability between the imputed datasets. The pooled results give a more accurate and robust estimate than analyzing a single imputed dataset. Rubin's rules ensure that the combined results reflect both the within-imputation variability (the variability in results from analyzing each dataset separately) and the between-imputation variability (the differences in results across the imputed datasets).\n\n##### Step 0\n\n*Set imputation model*:\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/mi0_d031aec6f7a408a846412ddc7eed6967'}\n\n```{.r .cell-code}\nini <- mice(data = NHANES17s, maxit = 0, print = FALSE)\npred <- ini$pred\npred\n#>             age bmi cholesterol diastolicBP\n#> age           0   1           1           1\n#> bmi           1   0           1           1\n#> cholesterol   1   1           0           1\n#> diastolicBP   1   1           1           0\n# A value of 1 indicates that column variables (say, bmi, cholesterol, diastolicBP) \n# are used as a predictor to impute the a row variable (say, age).\npred[,\"diastolicBP\"] <- 0 \n# if you believe 'diastolicBP' should not be a predictor in any imputation model\npred\n#>             age bmi cholesterol diastolicBP\n#> age           0   1           1           0\n#> bmi           1   0           1           0\n#> cholesterol   1   1           0           0\n#> diastolicBP   1   1           1           0\n# for cholesterol: bmi and age used to predict cholesterol (diastolicBP is not a predictor)\n# for diastolicBP: bmi, age and cholesterol used to predict diastolicBP \n# (diastolicBP itself is not a predictor) \n```\n:::\n\n\n\n*Set imputation method*:\n\nSee Table 1 of [@van2011mice].\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/mi0a_93840b30c4e238ec81d96c52b8675fba'}\n\n```{.r .cell-code}\nmeth <- ini$meth\nmeth\n#>         age         bmi cholesterol diastolicBP \n#>       \"pmm\"       \"pmm\"       \"pmm\"       \"pmm\"\n# pmm is generally a good method, \n# but let's see how to work with other methods\n# just as an example.\n# Specifying imputation method:\nmeth[\"bmi\"] <- \"mean\" \n# for BMI: no predictor used in mean method \n# (only average of observed bmi)\nmeth[\"cholesterol\"] <- \"norm.predict\" \nmeth[\"diastolicBP\"] <- \"norm.nob\"\nmeth\n#>            age            bmi    cholesterol    diastolicBP \n#>          \"pmm\"         \"mean\" \"norm.predict\"     \"norm.nob\"\n```\n:::\n\n\n\n*Set imputation model based on correlation alone*:\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/mi0b_31bcdb5ac6f64be6fe24aff160ffa73a'}\n\n```{.r .cell-code}\npredictor.selection <- quickpred(NHANES17s, \n                                 mincor=0.1, # absolute correlation \n                                 minpuc=0.1) # proportion of usable cases\npredictor.selection\n#>             age bmi cholesterol diastolicBP\n#> age           0   1           1           1\n#> bmi           0   0           0           0\n#> cholesterol   1   1           0           1\n#> diastolicBP   1   1           1           0\n```\n:::\n\n\n\n##### Step 1\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/mi1_f1900d2173a4d1a754f9d8efd397d7bb'}\n\n```{.r .cell-code}\n# Step 1 Impute the incomplete data m=10 times\nimputation4 <- mice(data=NHANES17s, \n                    seed=504,\n                    method = meth,\n                    predictorMatrix = predictor.selection,\n                    m=10, # imputation will be done 10 times (i.e., 10 imputed datasets)\n                    maxit=3)\n#> \n#>  iter imp variable\n#>   1   1  age  bmi  cholesterol  diastolicBP\n#>   1   2  age  bmi  cholesterol  diastolicBP\n#>   1   3  age  bmi  cholesterol  diastolicBP\n#>   1   4  age  bmi  cholesterol  diastolicBP\n#>   1   5  age  bmi  cholesterol  diastolicBP\n#>   1   6  age  bmi  cholesterol  diastolicBP\n#>   1   7  age  bmi  cholesterol  diastolicBP\n#>   1   8  age  bmi  cholesterol  diastolicBP\n#>   1   9  age  bmi  cholesterol  diastolicBP\n#>   1   10  age  bmi  cholesterol  diastolicBP\n#>   2   1  age  bmi  cholesterol  diastolicBP\n#>   2   2  age  bmi  cholesterol  diastolicBP\n#>   2   3  age  bmi  cholesterol  diastolicBP\n#>   2   4  age  bmi  cholesterol  diastolicBP\n#>   2   5  age  bmi  cholesterol  diastolicBP\n#>   2   6  age  bmi  cholesterol  diastolicBP\n#>   2   7  age  bmi  cholesterol  diastolicBP\n#>   2   8  age  bmi  cholesterol  diastolicBP\n#>   2   9  age  bmi  cholesterol  diastolicBP\n#>   2   10  age  bmi  cholesterol  diastolicBP\n#>   3   1  age  bmi  cholesterol  diastolicBP\n#>   3   2  age  bmi  cholesterol  diastolicBP\n#>   3   3  age  bmi  cholesterol  diastolicBP\n#>   3   4  age  bmi  cholesterol  diastolicBP\n#>   3   5  age  bmi  cholesterol  diastolicBP\n#>   3   6  age  bmi  cholesterol  diastolicBP\n#>   3   7  age  bmi  cholesterol  diastolicBP\n#>   3   8  age  bmi  cholesterol  diastolicBP\n#>   3   9  age  bmi  cholesterol  diastolicBP\n#>   3   10  age  bmi  cholesterol  diastolicBP\nimputation4$pred\n#>             age bmi cholesterol diastolicBP\n#> age           0   1           1           1\n#> bmi           0   0           0           0\n#> cholesterol   1   1           0           1\n#> diastolicBP   1   1           1           0\n## look at the variables used for imputation\nmice::complete(imputation4, action = 1) # 1 imputed data  \n#>    age      bmi cholesterol diastolicBP\n#> 1   70 17.50000    181.4426    83.04193\n#> 2   72 15.70000    186.7818    74.75594\n#> 3   66 31.70000    157.0000    76.19325\n#> 4   75 21.50000    148.0000    74.00000\n#> 5   66 18.10000    189.0000    38.00000\n#> 6   66 23.70000    209.0000    60.21363\n#> 7   75 38.90000    176.0000    66.00000\n#> 8   66 25.12857    176.2946    79.70841\n#> 9   56 21.30000    238.0000    68.00000\n#> 10  70 19.70000    182.0000    68.00000\n#> 11  67 23.50000    184.0000    70.00000\n#> 12  54 39.90000    230.0000    70.54754\n#> 13  71 22.50000    180.0000    60.00000\n#> 14  61 30.70000    225.0000    72.00000\n#> 15  22 24.50000    213.0000    62.00000\n#> 16  45 22.00000    152.0000    88.00000\n#> 17  67 26.00000     97.0000    62.00000\n#> 18  66 25.12857    177.7121    68.60771\n#> 19  60 35.90000    122.0000    68.00000\n#> 20  60 23.80000    184.0000    68.00000\n#> 21  64 22.40000    202.0000    72.00000\n#> 22  66 14.70000    181.8733    52.65007\n#> 23  66 16.10000    184.4578    65.22749\n#> 24  67 31.10000    176.0000    52.00000\n#> 25  70 23.90000    167.0000    59.15340\n#> 26  53 33.40000    143.0000    74.00000\n#> 27  42 27.60000    165.0000    86.00000\n#> 28  57 28.60000    221.0000    74.00000\n#> 29  20 27.60000    153.0000    54.00000\n#> 30  72 21.30000    182.5833    76.00000\nall <- mice::complete(imputation4, action=\"long\") # combine all 5 imputed datasets\ndim(all)\n#> [1] 300   6\nhead(all)\n#>   .imp .id age  bmi cholesterol diastolicBP\n#> 1    1   1  70 17.5    181.4426    83.04193\n#> 2    1   2  72 15.7    186.7818    74.75594\n#> 3    1   3  66 31.7    157.0000    76.19325\n#> 4    1   4  75 21.5    148.0000    74.00000\n#> 5    1   5  66 18.1    189.0000    38.00000\n#> 6    1   6  66 23.7    209.0000    60.21363\n## you can change the way of displaying the data\ndata_hori <- mice::complete(imputation4, action=\"broad\") # display five imputations horizontally\n#> New names:\n#> * `age` -> `age...1`\n#> * `bmi` -> `bmi...2`\n#> * `cholesterol` -> `cholesterol...3`\n#> * `diastolicBP` -> `diastolicBP...4`\n#> * `age` -> `age...5`\n#> * `bmi` -> `bmi...6`\n#> * `cholesterol` -> `cholesterol...7`\n#> * `diastolicBP` -> `diastolicBP...8`\n#> * `age` -> `age...9`\n#> * `bmi` -> `bmi...10`\n#> * `cholesterol` -> `cholesterol...11`\n#> * `diastolicBP` -> `diastolicBP...12`\n#> * `age` -> `age...13`\n#> * `bmi` -> `bmi...14`\n#> * `cholesterol` -> `cholesterol...15`\n#> * `diastolicBP` -> `diastolicBP...16`\n#> * `age` -> `age...17`\n#> * `bmi` -> `bmi...18`\n#> * `cholesterol` -> `cholesterol...19`\n#> * `diastolicBP` -> `diastolicBP...20`\n#> * `age` -> `age...21`\n#> * `bmi` -> `bmi...22`\n#> * `cholesterol` -> `cholesterol...23`\n#> * `diastolicBP` -> `diastolicBP...24`\n#> * `age` -> `age...25`\n#> * `bmi` -> `bmi...26`\n#> * `cholesterol` -> `cholesterol...27`\n#> * `diastolicBP` -> `diastolicBP...28`\n#> * `age` -> `age...29`\n#> * `bmi` -> `bmi...30`\n#> * `cholesterol` -> `cholesterol...31`\n#> * `diastolicBP` -> `diastolicBP...32`\n#> * `age` -> `age...33`\n#> * `bmi` -> `bmi...34`\n#> * `cholesterol` -> `cholesterol...35`\n#> * `diastolicBP` -> `diastolicBP...36`\n#> * `age` -> `age...37`\n#> * `bmi` -> `bmi...38`\n#> * `cholesterol` -> `cholesterol...39`\n#> * `diastolicBP` -> `diastolicBP...40`\n\ndim(data_hori)\n#> [1] 30 40\nhead(data_hori)\n#>   age.1 bmi.1 cholesterol.1 diastolicBP.1 age.2 bmi.2 cholesterol.2\n#> 1    70  17.5      181.4426      83.04193    53  17.5      182.5155\n#> 2    72  15.7      186.7818      74.75594    53  15.7      184.2733\n#> 3    66  31.7      157.0000      76.19325    66  31.7      157.0000\n#> 4    75  21.5      148.0000      74.00000    72  21.5      148.0000\n#> 5    66  18.1      189.0000      38.00000    64  18.1      189.0000\n#> 6    66  23.7      209.0000      60.21363    66  23.7      209.0000\n#>   diastolicBP.2 age.3 bmi.3 cholesterol.3 diastolicBP.3 age.4 bmi.4\n#> 1      46.75843    61  17.5      186.8438      57.28721    60  17.5\n#> 2      63.10549    57  15.7      187.5062      58.23018    20  15.7\n#> 3      68.71696    66  31.7      157.0000      60.52996    66  31.7\n#> 4      74.00000    67  21.5      148.0000      74.00000    61  21.5\n#> 5      38.00000    54  18.1      189.0000      38.00000    20  18.1\n#> 6      70.44802    66  23.7      209.0000      84.12647    66  23.7\n#>   cholesterol.4 diastolicBP.4 age.5 bmi.5 cholesterol.5 diastolicBP.5 age.6\n#> 1      184.4672      55.46444    20  17.5      162.9816      55.71490    72\n#> 2      184.5120      37.90855    22  15.7      166.5841      69.72937    56\n#> 3      157.0000      75.44561    66  31.7      157.0000      59.98014    66\n#> 4      148.0000      74.00000    22  21.5      148.0000      74.00000    75\n#> 5      189.0000      38.00000    57  18.1      189.0000      38.00000    72\n#> 6      209.0000      57.53259    66  23.7      209.0000      86.92689    66\n#>   bmi.6 cholesterol.6 diastolicBP.6 age.7 bmi.7 cholesterol.7 diastolicBP.7\n#> 1  17.5      187.0681      69.35847    75  17.5      180.3150      60.59233\n#> 2  15.7      180.1763      68.08071    54  15.7      183.9833      91.04843\n#> 3  31.7      157.0000      53.82798    66  31.7      157.0000      62.76216\n#> 4  21.5      148.0000      74.00000    71  21.5      148.0000      74.00000\n#> 5  18.1      189.0000      38.00000    54  18.1      189.0000      38.00000\n#> 6  23.7      209.0000      76.06660    66  23.7      209.0000      63.70664\n#>   age.8 bmi.8 cholesterol.8 diastolicBP.8 age.9 bmi.9 cholesterol.9\n#> 1    42  17.5      182.0559      85.89369    71  17.5      181.8780\n#> 2    57  15.7      183.0995      61.45652    20  15.7      190.0688\n#> 3    66  31.7      157.0000      77.78881    66  31.7      157.0000\n#> 4    61  21.5      148.0000      74.00000    60  21.5      148.0000\n#> 5    57  18.1      189.0000      38.00000    70  18.1      189.0000\n#> 6    66  23.7      209.0000      73.99950    66  23.7      209.0000\n#>   diastolicBP.9 age.10 bmi.10 cholesterol.10 diastolicBP.10\n#> 1      71.72672     67   17.5       184.5682       53.77248\n#> 2      56.14070     22   15.7       182.6369       73.79396\n#> 3      62.31531     66   31.7       157.0000       64.19636\n#> 4      74.00000     64   21.5       148.0000       74.00000\n#> 5      38.00000     71   18.1       189.0000       38.00000\n#> 6      56.64013     66   23.7       209.0000       60.45355\n\n## Compare means of each imputed dataset\ncolMeans(data_hori)\n#>          age.1          bmi.1  cholesterol.1  diastolicBP.1          age.2 \n#>       61.06667       25.12857      179.47152       68.06998       58.20000 \n#>          bmi.2  cholesterol.2  diastolicBP.2          age.3          bmi.3 \n#>       25.12857      179.71210       66.61289       57.40000       25.12857 \n#>  cholesterol.3  diastolicBP.3          age.4          bmi.4  cholesterol.4 \n#>      180.28681       68.77854       54.86667       25.12857      179.58873 \n#>  diastolicBP.4          age.5          bmi.5  cholesterol.5  diastolicBP.5 \n#>       66.13461       52.80000       25.12857      179.35478       66.74254 \n#>          age.6          bmi.6  cholesterol.6  diastolicBP.6          age.7 \n#>       60.00000       25.12857      179.22499       66.76592       58.43333 \n#>          bmi.7  cholesterol.7  diastolicBP.7          age.8          bmi.8 \n#>       25.12857      178.99900       66.82760       56.20000       25.12857 \n#>  cholesterol.8  diastolicBP.8          age.9          bmi.9  cholesterol.9 \n#>      179.63656       67.31160       59.06667       25.12857      179.58295 \n#>  diastolicBP.9         age.10         bmi.10 cholesterol.10 diastolicBP.10 \n#>       66.37078       55.63333       25.12857      179.69042       67.60832\n```\n:::\n\n\n\n##### Step 2\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/mi2_1b790bc89bbd0fc000f50e423ffe1f16'}\n\n```{.r .cell-code}\nimputation4\n#> Class: mids\n#> Number of multiple imputations:  10 \n#> Imputation methods:\n#>            age            bmi    cholesterol    diastolicBP \n#>          \"pmm\"         \"mean\" \"norm.predict\"     \"norm.nob\" \n#> PredictorMatrix:\n#>             age bmi cholesterol diastolicBP\n#> age           0   1           1           1\n#> bmi           0   0           0           0\n#> cholesterol   1   1           0           1\n#> diastolicBP   1   1           1           0\n```\n:::\n\n::: {.cell hash='missingdata1_cache/pdf/mi2a_d5addd5a15a079553476750c65a6316e'}\n\n```{.r .cell-code}\nimputation4[[1]]\n#>    age  bmi cholesterol diastolicBP\n#> 1   NA 17.5          NA          NA\n#> 2   NA 15.7          NA          NA\n#> 3   66 31.7         157          NA\n#> 4   NA 21.5         148          74\n#> 5   NA 18.1         189          38\n#> 6   66 23.7         209          NA\n#> 7   75 38.9         176          66\n#> 8   NA   NA          NA          NA\n#> 9   56 21.3         238          68\n#> 10  NA 19.7         182          68\n#> 11  67 23.5         184          70\n#> 12  54 39.9         230          NA\n#> 13  71 22.5         180          60\n#> 14  61 30.7         225          72\n#> 15  22 24.5         213          62\n#> 16  45 22.0         152          88\n#> 17  NA 26.0          97          62\n#> 18  NA   NA          NA          NA\n#> 19  60 35.9         122          68\n#> 20  60 23.8         184          68\n#> 21  64 22.4         202          72\n#> 22  NA 14.7          NA          NA\n#> 23  NA 16.1          NA          NA\n#> 24  67 31.1         176          52\n#> 25  70 23.9         167          NA\n#> 26  53 33.4         143          74\n#> 27  42 27.6         165          86\n#> 28  57 28.6         221          74\n#> 29  20 27.6         153          54\n#> 30  72 21.3          NA          76\n```\n:::\n\n::: {.cell hash='missingdata1_cache/pdf/mi2b_028a184fcbee8271cd6b612ef83f0a8f'}\n\n```{.r .cell-code}\nmice::complete(imputation4, action = 1)\n#>    age      bmi cholesterol diastolicBP\n#> 1   70 17.50000    181.4426    83.04193\n#> 2   72 15.70000    186.7818    74.75594\n#> 3   66 31.70000    157.0000    76.19325\n#> 4   75 21.50000    148.0000    74.00000\n#> 5   66 18.10000    189.0000    38.00000\n#> 6   66 23.70000    209.0000    60.21363\n#> 7   75 38.90000    176.0000    66.00000\n#> 8   66 25.12857    176.2946    79.70841\n#> 9   56 21.30000    238.0000    68.00000\n#> 10  70 19.70000    182.0000    68.00000\n#> 11  67 23.50000    184.0000    70.00000\n#> 12  54 39.90000    230.0000    70.54754\n#> 13  71 22.50000    180.0000    60.00000\n#> 14  61 30.70000    225.0000    72.00000\n#> 15  22 24.50000    213.0000    62.00000\n#> 16  45 22.00000    152.0000    88.00000\n#> 17  67 26.00000     97.0000    62.00000\n#> 18  66 25.12857    177.7121    68.60771\n#> 19  60 35.90000    122.0000    68.00000\n#> 20  60 23.80000    184.0000    68.00000\n#> 21  64 22.40000    202.0000    72.00000\n#> 22  66 14.70000    181.8733    52.65007\n#> 23  66 16.10000    184.4578    65.22749\n#> 24  67 31.10000    176.0000    52.00000\n#> 25  70 23.90000    167.0000    59.15340\n#> 26  53 33.40000    143.0000    74.00000\n#> 27  42 27.60000    165.0000    86.00000\n#> 28  57 28.60000    221.0000    74.00000\n#> 29  20 27.60000    153.0000    54.00000\n#> 30  72 21.30000    182.5833    76.00000\n```\n:::\n\n::: {.cell hash='missingdata1_cache/pdf/mi2c_f1e5cacb6b0bf8c2774e820cb25ae41c'}\n\n```{.r .cell-code}\nmice::complete(imputation4, action = 10)\n#>    age      bmi cholesterol diastolicBP\n#> 1   67 17.50000    184.5682    53.77248\n#> 2   22 15.70000    182.6369    73.79396\n#> 3   66 31.70000    157.0000    64.19636\n#> 4   64 21.50000    148.0000    74.00000\n#> 5   71 18.10000    189.0000    38.00000\n#> 6   66 23.70000    209.0000    60.45355\n#> 7   75 38.90000    176.0000    66.00000\n#> 8   71 25.12857    180.9696    81.81115\n#> 9   56 21.30000    238.0000    68.00000\n#> 10  22 19.70000    182.0000    68.00000\n#> 11  67 23.50000    184.0000    70.00000\n#> 12  54 39.90000    230.0000    78.04885\n#> 13  71 22.50000    180.0000    60.00000\n#> 14  61 30.70000    225.0000    72.00000\n#> 15  22 24.50000    213.0000    62.00000\n#> 16  45 22.00000    152.0000    88.00000\n#> 17  56 26.00000     97.0000    62.00000\n#> 18  57 25.12857    179.3458    85.12129\n#> 19  60 35.90000    122.0000    68.00000\n#> 20  60 23.80000    184.0000    68.00000\n#> 21  64 22.40000    202.0000    72.00000\n#> 22  20 14.70000    183.0146    57.66811\n#> 23  71 16.10000    184.8780    62.76266\n#> 24  67 31.10000    176.0000    52.00000\n#> 25  70 23.90000    167.0000    58.62128\n#> 26  53 33.40000    143.0000    74.00000\n#> 27  42 27.60000    165.0000    86.00000\n#> 28  57 28.60000    221.0000    74.00000\n#> 29  20 27.60000    153.0000    54.00000\n#> 30  72 21.30000    182.2995    76.00000\n```\n:::\n\n::: {.cell hash='missingdata1_cache/pdf/mi2d_8e4da3680d9f667777c0d91b725b8625'}\n\n```{.r .cell-code}\n# Step 2 Analyze the imputed data\nfit4 <- with(data = imputation4, exp = lm(cholesterol ~ age + bmi + diastolicBP))\n## fit model with each of 10 datasets separately\nfit4\n#> call :\n#> with.mids(data = imputation4, expr = lm(cholesterol ~ age + bmi + \n#>     diastolicBP))\n#> \n#> call1 :\n#> mice(data = NHANES17s, m = 10, method = meth, predictorMatrix = predictor.selection, \n#>     maxit = 3, seed = 504)\n#> \n#> nmis :\n#>         age         bmi cholesterol diastolicBP \n#>          10           2           7          10 \n#> \n#> analyses :\n#> [[1]]\n#> \n#> Call:\n#> lm(formula = cholesterol ~ age + bmi + diastolicBP)\n#> \n#> Coefficients:\n#> (Intercept)          age          bmi  diastolicBP  \n#>   210.68650     -0.19085     -0.52112     -0.09498  \n#> \n#> \n#> [[2]]\n#> \n#> Call:\n#> lm(formula = cholesterol ~ age + bmi + diastolicBP)\n#> \n#> Coefficients:\n#> (Intercept)          age          bmi  diastolicBP  \n#>   185.56395      0.06366     -0.49154      0.04196  \n#> \n#> \n#> [[3]]\n#> \n#> Call:\n#> lm(formula = cholesterol ~ age + bmi + diastolicBP)\n#> \n#> Coefficients:\n#> (Intercept)          age          bmi  diastolicBP  \n#>   188.01460     -0.07922     -0.52325      0.14493  \n#> \n#> \n#> [[4]]\n#> \n#> Call:\n#> lm(formula = cholesterol ~ age + bmi + diastolicBP)\n#> \n#> Coefficients:\n#> (Intercept)          age          bmi  diastolicBP  \n#>    210.2814       0.1096      -0.4602      -0.3802  \n#> \n#> \n#> [[5]]\n#> \n#> Call:\n#> lm(formula = cholesterol ~ age + bmi + diastolicBP)\n#> \n#> Coefficients:\n#> (Intercept)          age          bmi  diastolicBP  \n#>    167.8965       0.7171      -0.7613      -0.1090  \n#> \n#> \n#> [[6]]\n#> \n#> Call:\n#> lm(formula = cholesterol ~ age + bmi + diastolicBP)\n#> \n#> Coefficients:\n#> (Intercept)          age          bmi  diastolicBP  \n#>    187.4324       0.1727      -0.3452      -0.1482  \n#> \n#> \n#> [[7]]\n#> \n#> Call:\n#> lm(formula = cholesterol ~ age + bmi + diastolicBP)\n#> \n#> Coefficients:\n#> (Intercept)          age          bmi  diastolicBP  \n#>   203.45344     -0.22713     -0.37039     -0.02806  \n#> \n#> \n#> [[8]]\n#> \n#> Call:\n#> lm(formula = cholesterol ~ age + bmi + diastolicBP)\n#> \n#> Coefficients:\n#> (Intercept)          age          bmi  diastolicBP  \n#>  213.721570    -0.003491    -0.517870    -0.310132  \n#> \n#> \n#> [[9]]\n#> \n#> Call:\n#> lm(formula = cholesterol ~ age + bmi + diastolicBP)\n#> \n#> Coefficients:\n#> (Intercept)          age          bmi  diastolicBP  \n#>   205.74248     -0.16224     -0.46983     -0.07188  \n#> \n#> \n#> [[10]]\n#> \n#> Call:\n#> lm(formula = cholesterol ~ age + bmi + diastolicBP)\n#> \n#> Coefficients:\n#> (Intercept)          age          bmi  diastolicBP  \n#>    181.2751       0.0698      -0.5425       0.1208\n```\n:::\n\n\n\n##### Step 3\n\n###### Understanding the pooled results\n\nWe will show the result of entire pool later. First we want to show the pooled results for the `age` variable only an an example.\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/mi3a_e1a8b8decc84d80bf429048e1cdb6ab3'}\n\n```{.r .cell-code}\nrequire(dplyr)\nres10 <- summary(fit4) %>% as_tibble %>% print(n=40)\n#> # A tibble: 40 x 6\n#>    term         estimate std.error statistic   p.value  nobs\n#>    <chr>           <dbl>     <dbl>     <dbl>     <dbl> <int>\n#>  1 (Intercept) 211.         53.6     3.93    0.000561     30\n#>  2 age          -0.191       0.452  -0.422   0.676        30\n#>  3 bmi          -0.521       0.943  -0.553   0.585        30\n#>  4 diastolicBP  -0.0950      0.563  -0.169   0.867        30\n#>  5 (Intercept) 186.         47.9     3.88    0.000644     30\n#>  6 age           0.0637      0.459   0.139   0.891        30\n#>  7 bmi          -0.492       0.939  -0.524   0.605        30\n#>  8 diastolicBP   0.0420      0.533   0.0787  0.938        30\n#>  9 (Intercept) 188.         48.9     3.85    0.000694     30\n#> 10 age          -0.0792      0.470  -0.169   0.867        30\n#> 11 bmi          -0.523       0.926  -0.565   0.577        30\n#> 12 diastolicBP   0.145       0.547   0.265   0.793        30\n#> 13 (Intercept) 210.         38.6     5.44    0.0000105    30\n#> 14 age           0.110       0.372   0.295   0.771        30\n#> 15 bmi          -0.460       0.950  -0.485   0.632        30\n#> 16 diastolicBP  -0.380       0.534  -0.712   0.483        30\n#> 17 (Intercept) 168.         39.6     4.24    0.000253     30\n#> 18 age           0.717       0.299   2.39    0.0241       30\n#> 19 bmi          -0.761       0.898  -0.848   0.404        30\n#> 20 diastolicBP  -0.109       0.500  -0.218   0.829        30\n#> 21 (Intercept) 187.         57.1     3.28    0.00294      30\n#> 22 age           0.173       0.437   0.395   0.696        30\n#> 23 bmi          -0.345       0.943  -0.366   0.717        30\n#> 24 diastolicBP  -0.148       0.569  -0.260   0.797        30\n#> 25 (Intercept) 203.         48.5     4.20    0.000278     30\n#> 26 age          -0.227       0.390  -0.583   0.565        30\n#> 27 bmi          -0.370       0.921  -0.402   0.691        30\n#> 28 diastolicBP  -0.0281      0.536  -0.0523  0.959        30\n#> 29 (Intercept) 214.         51.5     4.15    0.000313     30\n#> 30 age          -0.00349     0.450  -0.00776 0.994        30\n#> 31 bmi          -0.518       0.927  -0.559   0.581        30\n#> 32 diastolicBP  -0.310       0.525  -0.590   0.560        30\n#> 33 (Intercept) 206.         47.8     4.30    0.000213     30\n#> 34 age          -0.162       0.392  -0.414   0.682        30\n#> 35 bmi          -0.470       0.921  -0.510   0.614        30\n#> 36 diastolicBP  -0.0719      0.523  -0.137   0.892        30\n#> 37 (Intercept) 181.         44.4     4.08    0.000379     30\n#> 38 age           0.0698      0.353   0.198   0.845        30\n#> 39 bmi          -0.543       0.970  -0.559   0.581        30\n#> 40 diastolicBP   0.121       0.558   0.216   0.830        30\nm10 <- res10[res10$term == \"age\",]\nm10\n#> # A tibble: 10 x 6\n#>    term  estimate std.error statistic p.value  nobs\n#>    <chr>    <dbl>     <dbl>     <dbl>   <dbl> <int>\n#>  1 age   -0.191       0.452  -0.422    0.676     30\n#>  2 age    0.0637      0.459   0.139    0.891     30\n#>  3 age   -0.0792      0.470  -0.169    0.867     30\n#>  4 age    0.110       0.372   0.295    0.771     30\n#>  5 age    0.717       0.299   2.39     0.0241    30\n#>  6 age    0.173       0.437   0.395    0.696     30\n#>  7 age   -0.227       0.390  -0.583    0.565     30\n#>  8 age   -0.00349     0.450  -0.00776  0.994     30\n#>  9 age   -0.162       0.392  -0.414    0.682     30\n#> 10 age    0.0698      0.353   0.198    0.845     30\n```\n:::\n\n\n\nLet us describe the components of a pool for the `age` variable only:\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/mi3b_3d33104af9a86ec5e89839a7c9bc7711'}\n\n```{.r .cell-code}\nm.number <- 10\n# estimate = pooled estimate \n# = sum of (m “beta-hat” estimates) / m (mean of m estimated statistics)\nestimate <- mean(m10$estimate)\nestimate\n#> [1] 0.04699243\n# ubar = sum of (m variance[beta] estimates) / m \n# = within-imputation variance (mean of estimated variances)\nubar.var <- mean(m10$std.error^2)\nubar.var\n#> [1] 0.1686837\n# b =  variance of (m “beta-hat” estimates) \n# = between-imputation variance \n# (degree to which estimated statistic / \n# “beta-hat” varies across m imputed datasets). \n# This b is not available for single imputation when m = 1.\nb.var <- var(m10$estimate)\nb.var\n#> [1] 0.07372796\n# t = ubar + b + b/m = total variance according to Rubin’s rules \n# (within-imputation & between imputation variation)\nt.var <- ubar.var + b.var + b.var/m.number\nt.var\n#> [1] 0.2497845\n# riv = relative increase in variance\nriv = (b.var + b.var/m.number)/ubar.var\nriv\n#> [1] 0.4807859\n# lambda = proportion of variance to due nonresponse\nlambda = (b.var + b.var/m.number)/t.var\nlambda\n#> [1] 0.3246829\n# df (approximate for large sample without correction)\ndf.large.sample <- (m.number - 1)/lambda^2\ndf.large.sample\n#> [1] 85.37359\n# df (hypothetical complete data)\ndfcom <- m10$nobs[1] - 4 # n = 30, # parameters = 4\ndfcom\n#> [1] 26\n# df (Barnard-Rubin correction)\ndf.obs <- (dfcom + 1)/(dfcom + 3) * dfcom * (1 - lambda)\ndf.c <- df.large.sample * df.obs/(df.large.sample + df.obs)\ndf.c\n#> [1] 13.72019\n# fmi = fraction of missing information per parameter\nfmi = (riv + 2/(df.large.sample +3)) / (1 + riv)\nfmi # based on large sample approximation\n#> [1] 0.3399662\nfmi = (riv + 2/(df.c +3)) / (1 + riv)\nfmi # Barnard-Rubin correction\n#> [1] 0.4054616\n```\n:::\n\n\n\n###### Pooled estimate\n\nCompare above results with the pooled table from `mice` below. Note that `df` is based on Barnard-Rubin correction and `fmi` value is calculated based on that corrected `df`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Step 3 pool the analysis results\nest1 <- mice::pool(fit4)\n## pool all estimated together using Rubin's rule \nest1\n```\n:::\n\n\n\n`Class: mipo    m = 10` (transposed version to accommodate space)\n\n| Term      | (Intercept)  | age        | bmi         | diastolicBP |\n|-----------|--------------|------------|-------------|-------------|\n| m         | 10           | 10         | 10          | 10          |\n| Estimate  | 195.40679314 | 0.04699243 | -0.50032666 | -0.08347279 |\n| $\\bar{u}$ | 2313.6362339 | 0.1686837  | 0.8722547   | 0.2909291   |\n| b         | 237.04075365 | 0.07372796 | 0.01274940  | 0.02857675  |\n| t         | 2574.3810629 | 0.2497845  | 0.8862790   | 0.3223635   |\n| df_com    | 26           | 26         | 26          | 26          |\n| df        | 21.22870     | 13.72019   | 23.80807    | 21.35356    |\n| RIV       | 0.11269915   | 0.48078595 | 0.01607826  | 0.10804843  |\n| $\\lambda$ | 0.10128447   | 0.32468295 | 0.01582384  | 0.09751237  |\n| FMI       | 0.17547051   | 0.40546159 | 0.08924771  | 0.17162783  |\n\nHere:\n\n-   dfcom = df for complete data\n-   df = df with Barnard-Rubin correction\n\n##### Video content (optional)\n\n::: callout-tip\nFor those who prefer a video walkthrough, feel free to watch the video below, which offers a description of an earlier version of the above content.\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/izQB-n-euro\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n### Special case: Variable selection\n\n#### Variable selection in analyzing missing data\n\n-   Ref: [@van2018flexible], Section 5.4\n\nThe common workflow for analyzing missing data are (as mentioned above):\n\n1.  Imputing the data $m$ times\n\n2.  Analyzing the $m$ dataset\n\n3.  Pool all analysis together\n\nWe could apply variable selection in step 2, especially when we have no idea what is the best model to analyze the data. Howevere, it may become challenging when we pull all data together. With different dataset, the final model may or may not be the same.\n\nWe present the three method of variable selection on each imputed dataset presented by Buuren:\n\n1.  Majority: perform the model selection separately with m dataset and choose the variables that appears at least m/2 times\n2.  Stack: combine m datasets into a single dataset, and perform variable selection on this dataset\n3.  Wald (Rubin's rule): model selection was performed at model fitting step and combine the estimates using Rubin's rules. This is considered as gold standard.\n\n##### Majority using NHANES17s\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/varselect0_378431deedb9371d47399ceb6cc6ce43'}\n\n```{.r .cell-code}\ndata <- NHANES17s\nimp <- mice(data, seed = 504, m = 100, print = FALSE)\n## Multiple imputation with 100 imputations, resulting in 100 imputed datasets\nscope0 <- list(upper = ~ age + bmi + cholesterol, lower = ~1)\nexpr <- expression(f1 <- lm(diastolicBP ~ age),\n                   f2 <- step(f1, scope = scope0, trace = FALSE))\nfit5 <- with(imp, expr)\n\n## apply stepwise on each of the imputed dataset separately\nformulas <- lapply(fit5$analyses, formula)\n## fit5$analyses returns the selection result for each imputed dataset\nterms <- lapply(formulas, terms)\nvotes <- unlist(lapply(terms, labels))\n## look at the terms on each models\ntable(votes)\n#> votes\n#>         age         bmi cholesterol \n#>           6          12           1\n```\n:::\n\n::: {.cell hash='missingdata1_cache/pdf/varselect1_63b509d3bde386f182e93ca877eb4175'}\n\n```{.r .cell-code}\n## Set up the stepwise variable selection, from null model to full model\nscope <- list(upper = ~ age + bmi + cholesterol, lower = ~ age)\n\n## Set up the stepwise variable selection, from important only model to full model\nexpr <- expression(f1 <- lm(diastolicBP ~ age),\n                   f2 <- step(f1, scope = scope, trace = FALSE))\nfit5 <- with(imp, expr)\n## apply stepwise on each of the imputed dataset separately\nformulas <- lapply(fit5$analyses, formula)\n## fit5$analyses returns the selection result for each imputed dataset\nterms <- lapply(formulas, terms)\nvotes <- unlist(lapply(terms, labels))\n## look at the terms on each models\ntable(votes)\n#> votes\n#>         age         bmi cholesterol \n#>         100          11           1\n```\n:::\n\n\n\n##### Stack using NHANES17s\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/varselect2_0ac027710365807be24635b9e9e7deed'}\n\n```{.r .cell-code}\nStack.data <- mice::complete(imp, action=\"long\")\nhead(Stack.data)\n#>   .imp .id age  bmi cholesterol diastolicBP\n#> 1    1   1  64 17.5         153          62\n#> 2    1   2  67 15.7         152          60\n#> 3    1   3  66 31.7         157          70\n#> 4    1   4  67 21.5         148          74\n#> 5    1   5  72 18.1         189          38\n#> 6    1   6  66 23.7         209          54\ntail(Stack.data)\n#>      .imp .id age  bmi cholesterol diastolicBP\n#> 2995  100  25  70 23.9         167          68\n#> 2996  100  26  53 33.4         143          74\n#> 2997  100  27  42 27.6         165          86\n#> 2998  100  28  57 28.6         221          74\n#> 2999  100  29  20 27.6         153          54\n#> 3000  100  30  72 21.3         152          76\nfitx <- lm(diastolicBP ~ age + bmi + cholesterol, data = Stack.data)\nfity <- step(fitx, scope = scope0, trace = FALSE)\nrequire(Publish)\n#> Loading required package: Publish\n#> Loading required package: prodlim\npublish(fity)\n#>     Variable Units Coefficient         CI.95 p-value \n#>  (Intercept)             63.70 [62.12;65.28] < 1e-04 \n#>          bmi              0.14   [0.08;0.20] < 1e-04\n```\n:::\n\n\n\n##### Wald using NHANES17s\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/varselect3_d7cfc7b3f24d8bdd7368c80233f08450'}\n\n```{.r .cell-code}\n# m = 100\nfit7 <- with(data=imp, expr=lm(diastolicBP ~ 1))\nnames(fit7)\n#> [1] \"call\"     \"call1\"    \"nmis\"     \"analyses\"\nfit7$analyses[[1]]\n#> \n#> Call:\n#> lm(formula = diastolicBP ~ 1)\n#> \n#> Coefficients:\n#> (Intercept)  \n#>       68.47\nfit7$analyses[[100]]\n#> \n#> Call:\n#> lm(formula = diastolicBP ~ 1)\n#> \n#> Coefficients:\n#> (Intercept)  \n#>       65.47\nfit8 <- with(data=imp, expr=lm(diastolicBP ~ bmi))\nfit8$analyses[[45]]\n#> \n#> Call:\n#> lm(formula = diastolicBP ~ bmi)\n#> \n#> Coefficients:\n#> (Intercept)          bmi  \n#>    63.93092      0.09209\nfit8$analyses[[99]]\n#> \n#> Call:\n#> lm(formula = diastolicBP ~ bmi)\n#> \n#> Coefficients:\n#> (Intercept)          bmi  \n#>    68.34740      0.01797\n# The D1-statistics is the multivariate Wald test.\nstat <- D1(fit8, fit7)\n## use Wald test to see if we should add bmi into the model\nstat\n#>    test statistic df1      df2 dfcom   p.value       riv\n#>  1 ~~ 2 0.1215668   1 22.70437    28 0.7305539 0.5550013\n# which indicates that adding bmi into our model might not be useful\n```\n:::\n\n::: {.cell hash='missingdata1_cache/pdf/varselect4_916eb567a34701119edee3bd6be8c72d'}\n\n```{.r .cell-code}\nfit9 <- with(data=imp, expr=lm(diastolicBP ~ age + bmi))\nstat <- D1(fit9, fit8)\n## use Wald test to see if we should add age into the model\nstat\n#>    test   statistic df1      df2 dfcom   p.value       riv\n#>  1 ~~ 2 0.006608523   1 22.46746    27 0.9359289 0.4545242\n# which indicates that adding age into our model might not be useful\n```\n:::\n\n::: {.cell hash='missingdata1_cache/pdf/varselect5_c57ed00ac4f8109aa58f3cec682724cf'}\n\n```{.r .cell-code}\nfit10 <- with(data=imp, expr=lm(diastolicBP ~ age + bmi + cholesterol))\nstat <- D1(fit10, fit9)\n## use Wald test to see if we should add cholesterol into the model\nstat\n#>    test    statistic df1      df2 dfcom   p.value       riv\n#>  1 ~~ 2 0.0003547819   1 22.14158    26 0.9851409 0.3615345\n# which indicates that adding cholesterol into our model might not be useful\n```\n:::\n\n\n\nTry `method=\"likelihood\"` as well.\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/varselect6_e13c0502958659b7e9d0842b6bccd4d8'}\n\n```{.r .cell-code}\nstat <- pool.compare(fit10, fit7, method = \"likelihood\", data=imp)\n## test to see if we should add all 3 variables into the model\nstat$pvalue\n#> [1] 0.9432629\n# which indicates that adding none of the variables into our model might be useful\n```\n:::\n\n\n\n##### Video content (optional)\n\n::: callout-tip\nFor those who prefer a video walkthrough, feel free to watch the video below, which offers a description of an earlier version of the above content.\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/cOGP_dELgyo\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n#### Assess the impact of missing values in model fitting\n\nWhen working with datasets, missing values are a common challenge. These gaps in data can introduce biases and uncertainties, especially when we try to fit models to the data. To address this, researchers often use imputation methods to fill in the missing values based on the observed information. However, imputation itself can introduce uncertainties. Therefore, it's essential to assess the impact of these missing values on model fitting. Buuren, as referenced in [@van2018flexible] Section 5.4.3, provides methods to do this. Out of the four methods presented by Buuren, the following two are the most commonly used:\n\n1.  Multiple imputation with more number of imputations (i.e., 200). Perform variable selection on each imputed dataset. The differences are attributed to the missing values\n\n2.  Bootstrapping the data from a single imputed dataset and do variable selection for each bootstrapping sample. We could evaluate sampling variation using this method\n\n##### Bootstrap using NHANES17s\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/impact1_efb580ea47f1982495647e79671c27d8'}\n\n```{.r .cell-code}\nimpx <- mice(NHANES17s, seed = 504, m=1, print=FALSE)\ncompletedata <- mice::complete(impx)\n  \nset.seed(504) \nvotes <-c()\nformula0 <- as.formula(\"diastolicBP ~ age + bmi + cholesterol\")\nscope <- list(upper = ~ age + bmi + cholesterol, lower = ~ age)\n\nfor (i in 1:200){\n     ind <- sample(1:nrow(completedata),replace = TRUE)\n     newdata <- completedata[ind,]\n     full.model <- glm(formula0, data = newdata)\n     f2 <- MASS::stepAIC(full.model, \n                   scope = scope, trace = FALSE)\n     formulas <- as.formula(f2)\n     temp <- unlist(labels(terms(formulas)))\n     votes <- c(votes,temp)\n }\n table(votes)\n#> votes\n#>         age         bmi cholesterol \n#>         200          59          17\n ## among 200 bootstrap samples how many times that each \n ## variable appears in the final model. Models have different\n ## variables are attributed to sampling variation\n```\n:::\n\n\n\n### Convergence and diagnostics\n\n#### Convergence\n\nWhen an algorithm converges, it means that the sequence of estimates generated by the algorithm stabilizes and reaches a distribution that does not depend on the initial values. This is crucial for imputation and other statistical analyses because it indicates that the estimates are representative of the true underlying statistical properties and are not biased by initial assumptions or specific starting conditions.\n\n-   Ref: [@van2018flexible], Section 6.5.2\n\n-   **MCMC Algorithm in MICE**: The MICE package implements a MCMC algorithm for imputation. The coefficients should be converged and irrelevant to the order which variable is imputed first.\n\n-   **Understanding pattern**: For convergence to be achieved, these chains should mix well with each other, meaning their paths should overlap and crisscross freely. If they show distinct, separate trends or paths, it indicates a lack of convergence, suggesting that the imputation may not be reliable.\n\n-   **Visualizing Convergence**: We could plot the imputation object to see the streams.\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/convergence_1d99a7d9f53b4123416417db5a48f975'}\n\n```{.r .cell-code}\n## Recall the imputation we have done before\nimputation5 <- mice(NHANES17s, seed = 504, \n                   m=10,\n                   maxit = 5,\n                   print=FALSE) \nplot(imputation5)\n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/convergence-1.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/convergence-2.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\n## We hope to see no pattern in the trace lines\n## Sometimes to comfirm this we may want to run with more iterations\nimputation5_2 <- mice(NHANES17s, seed = 504, \n                    m=10,\n                    maxit = 50,\n                    print=FALSE) \nplot(imputation5_2)\n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/convergence-3.pdf){fig-pos='H'}\n:::\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/convergence-4.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n#### Diagnostics\n\nModel diagnostics plays a pivotal role in ensuring the robustness and accuracy of model fitting. Particularly in the realm of missing value imputations, where observed data serves as the foundation for estimating absent values, it becomes imperative to rigorously assess the imputation process. A straightforward diagnostic technique involves comparing the distributions of the observed data with the imputed values, especially when segmented or conditioned based on the variables that originally had missing entries. This comparison helps in discerning any discrepancies or biases introduced during the imputation, ensuring that the filled values align well with the inherent patterns of the observed data.\n\n-   Ref: [@van2018flexible], Section 6.6\n\n\n\n::: {.cell hash='missingdata1_cache/pdf/diagnostics_fcc0ac0072b039529c581a21bb74ccd7'}\n\n```{.r .cell-code}\n## We could compare the imputed and observed data using Density plots\ndensityplot(imputation5, layout = c(2, 2))\n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/diagnostics-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\nimputation5_3 <- mice(NHANES17s, seed = 504, \n                    m=50,\n                    maxit = 50,\n                    print=FALSE)\ndensityplot(imputation5_3)\n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/diagnostics-2.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\n## a subjective judgment on whether you think if there is significant discrepancy\nbwplot(imputation5, age + bmi + cholesterol +diastolicBP ~ .imp, layout = c(2, 2))\n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/diagnostics-3.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\nbwplot(imputation5_3)\n```\n\n::: {.cell-output-display}\n![](missingdata1_files/figure-pdf/diagnostics-4.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\n## Plot a box plot to compare the imputed and observed values\n```\n:::\n\n\n\n#### Video content (optional)\n\n::: callout-tip\nFor those who prefer a video walkthrough, feel free to watch the video below, which offers a description of an earlier version of the above content.\n:::\n\n::: {style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"}\n<iframe src=\"https://www.youtube.com/embed/umY1gmMhriA\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" allowfullscreen>\n\n</iframe>\n:::\n\n### References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}