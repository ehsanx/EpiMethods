{
  "hash": "2fd093196da6516098bd2acfdf1ecca2",
  "result": {
    "markdown": "## Cross-validation {.unnumbered}\n\nCross-validation is another important technique used to assess the performance of machine learning models and mitigate the risk of overfitting. This tutorial focuses on k-fold cross-validation as a strategy to obtain a more generalized and robust assessment of the model's performance. It shows both manual calculations for individual folds and an automated approach using the caret package. This ensures that you aren't simply fitting your model well to a specific subset of your data but are achieving good performance in a general sense.\n\n\n::: {.cell hash='predictivefactors6_cache/html/setup_ec9c221bb6832a8180448bba38b1d39a'}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(caret)\nlibrary(knitr)\nlibrary(Publish)\nlibrary(car)\nlibrary(DescTools)\n```\n:::\n\n\n### Load data\n\nLoad the data saved at the end of previous part of the lab.\n\n\n::: {.cell hash='predictivefactors6_cache/html/load_2fce3a0f1779fc5cc61ea9ff09dd9a3f'}\n\n```{.r .cell-code}\nload(file=\"Data/predictivefactors/cholesterolNHANES15part2.RData\")\n```\n:::\n\n\n### k-fold cross-vaildation\n\n::: column-margin\nSee @Cross-validation\n:::\n\nWe can set the number of folds to 5 (k = 5). A random seed is used for reproducibility. We use the function `createFolds` to create the folds. The data is divided based on the cholesterol levels, with each fold having approximately equal numbers of data points. The resulting structure contains training indices for each fold.\n\nWe can also examine the approximate size of training and test sets for each fold. The dimensions are displayed to understand the partitioning, and you can examine the length of indices in each fold to confirm the size of the training sets.\n\n\n::: {.cell hash='predictivefactors6_cache/html/kcv_801a2743ce158edec51b3a4595f353a1'}\n\n```{.r .cell-code}\nk = 5\ndim(analytic3)\n#> [1] 2632   35\nset.seed(567)\n\n# Create folds (based on the outcome)\nfolds <- createFolds(analytic3$cholesterol, k = k, list = TRUE, \n                     returnTrain = TRUE)\nmode(folds)\n#> [1] \"list\"\n\n# Approximate training data size\ndim(analytic3)*4/5\n#> [1] 2105.6   28.0\n\n# Approximate test data size\ndim(analytic3)/5  \n#> [1] 526.4   7.0\n\nlength(folds[[1]])\n#> [1] 2105\nlength(folds[[2]])\n#> [1] 2107\nlength(folds[[3]])\n#> [1] 2106\nlength(folds[[4]])\n#> [1] 2105\nlength(folds[[5]])\n#> [1] 2105\n\nstr(folds[[1]])\n#>  int [1:2105] 1 3 5 6 8 10 11 12 13 14 ...\nstr(folds[[2]])\n#>  int [1:2107] 1 2 3 4 5 6 7 8 9 12 ...\nstr(folds[[3]])\n#>  int [1:2106] 2 4 5 7 8 9 10 11 12 14 ...\nstr(folds[[4]])\n#>  int [1:2105] 1 2 3 4 6 7 8 9 10 11 ...\nstr(folds[[5]])\n#>  int [1:2105] 1 2 3 4 5 6 7 9 10 11 ...\n```\n:::\n\n\n#### Calculation for Fold 1\n\nThe first fold is used as an example. The indices for the training data in the first fold are extracted and used to subset the main data set into training and test sets for that fold. Then a linear regression model is fitted using the training data, and predictions are made on the test set. The model's performance is evaluated using the same performance function as before.\n\n\n::: {.cell hash='predictivefactors6_cache/html/fold1_0b2eff4b6782f9d9ff701b4a7373aff0'}\n\n```{.r .cell-code}\nfold.index <- 1\nfold1.train.ids <- folds[[fold.index]]\nhead(fold1.train.ids)\n#> [1]  1  3  5  6  8 10\n\nfold1.train <- analytic3[fold1.train.ids,]\nfold1.test <- analytic3[-fold1.train.ids,]\nformula4\n#> cholesterol ~ gender + age + born + race + education + married + \n#>     income + diastolicBP + systolicBP + bmi + triglycerides + \n#>     uric.acid + protein + bilirubin + phosphorus + sodium + potassium + \n#>     globulin + calcium + physical.work + physical.recreational + \n#>     diabetes\n\nmodel.fit <- lm(formula4, data = fold1.train)\npredictions <- predict(model.fit, newdata = fold1.test)\n\nperform(new.data=fold1.test, y.name = \"cholesterol\", \n        model.fit = model.fit)\n#>        n  p df.residual      SSE      SST    R2 adjR2  sigma    logLik      AIC\n#> [1,] 527 29         498 637317.5 830983.2 0.233  0.19 35.774 -2618.471 5296.942\n#>           BIC\n#> [1,] 5424.958\n```\n:::\n\n\n#### Calculation for Fold 2\n\nThe same process is repeated for the second fold. This way, you can manually evaluate how the model performs on different subsets of the data, making the performance assessment more robust.\n\n\n::: {.cell hash='predictivefactors6_cache/html/fold2_d8004124206ba86579d26e274b335115'}\n\n```{.r .cell-code}\nfold.index <- 2\nfold1.train.ids <- folds[[fold.index]]\nhead(fold1.train.ids)\n#> [1] 1 2 3 4 5 6\n\nfold1.train <- analytic3[fold1.train.ids,]\nfold1.test <- analytic3[-fold1.train.ids,]\n\nmodel.fit <- lm(formula4, data = fold1.train)\n\npredictions <- predict(model.fit, newdata = fold1.test)\nperform(new.data=fold1.test, y.name = \"cholesterol\", \n        model.fit = model.fit)\n#>        n  p df.residual    SSE      SST    R2 adjR2  sigma    logLik      AIC\n#> [1,] 525 29         496 615243 785326.6 0.217 0.172 35.219 -2600.282 5260.564\n#>           BIC\n#> [1,] 5388.466\n```\n:::\n\n\n#### Using caret package to automate\n\n::: column-margin\nSee @tuning\n:::\n\nInstead of manually running the process for each fold, the caret package can be used to automate k-fold cross-validation. A control object is set up specifying that 5-fold cross-validation should be used. Then, the train function from the caret package can be used to fit the linear regression model on each fold.\n\nAfter fitting, you can access summary results for each fold in the resampling results. This summary provides performance metrics such as R-squared for each fold. You can calculate the mean and standard deviation of these metrics to get an overall sense of the model's performance.\n\nAdditionally, an adjusted R-squared can be calculated to consider the number of predictors in the model, giving a more accurate sense of the model's explanatory power when you have multiple predictors.\n\n\n::: {.cell hash='predictivefactors6_cache/html/caret_ca4a7f7119ebc05ba80d10e648598984'}\n\n```{.r .cell-code}\n# Using Caret package\nset.seed(567)\n\n# make a 5-fold CV\nctrl<-trainControl(method = \"cv\",number = 5)\n\n# fit the model with formula = formula4\n# use training method lm\nfit4.cv<-train(formula4, trControl = ctrl,\n               data = analytic3, method = \"lm\")\nfit4.cv\n#> Linear Regression \n#> \n#> 2632 samples\n#>   22 predictor\n#> \n#> No pre-processing\n#> Resampling: Cross-Validated (5 fold) \n#> Summary of sample sizes: 2106, 2105, 2106, 2105, 2106 \n#> Resampling results:\n#> \n#>   RMSE      Rsquared   MAE     \n#>   35.62758  0.2194187  27.85731\n#> \n#> Tuning parameter 'intercept' was held constant at a value of TRUE\n\n# extract results from each test data \nsummary.res <- fit4.cv$resample\nsummary.res\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"RMSE\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Rsquared\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"MAE\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Resample\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"36.85337\",\"2\":\"0.2050676\",\"3\":\"28.48951\",\"4\":\"Fold1\"},{\"1\":\"34.99024\",\"2\":\"0.2660231\",\"3\":\"27.57746\",\"4\":\"Fold2\"},{\"1\":\"35.25756\",\"2\":\"0.2056371\",\"3\":\"26.85106\",\"4\":\"Fold3\"},{\"1\":\"35.48300\",\"2\":\"0.1979601\",\"3\":\"28.44168\",\"4\":\"Fold4\"},{\"1\":\"35.55372\",\"2\":\"0.2224055\",\"3\":\"27.92683\",\"4\":\"Fold5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nmean(fit4.cv$resample$Rsquared)\n#> [1] 0.2194187\nsd(fit4.cv$resample$Rsquared)\n#> [1] 0.02755561\n\n# # extract adj R2\n# k <- 5\n# p <- 2\n# n <- round(nrow(analytic3)/k)\n# summary.res$adjR2 <- 1-(1-fit4.cv$resample$Rsquared)*\n#  ((n-1)/(n-p))\n# summary.res\n```\n:::\n\n\n### References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}