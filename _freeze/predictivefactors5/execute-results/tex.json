{
  "hash": "de7e2b28c78e744e13ec11468a2597f8",
  "result": {
    "markdown": "## Data spliting {.unnumbered}\n\nThis tutorial is focused on a crucial aspect of model building: splitting your data into training and test sets to avoid overfitting. Overfitting occurs when your model learns the noise in the data rather than the underlying trend. As a result, the model performs well on the training data but poorly on new, unseen data. To mitigate this, you often split your data.\n\n### Load data anf files\n\nInitially, several libraries are loaded to facilitate data manipulation and analysis.\n\n\n\n::: {.cell hash='predictivefactors5_cache/pdf/setup_6c46d212ddc63bec41ec53c4a4b72b29'}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(caret)\nlibrary(knitr)\nlibrary(Publish)\nlibrary(car)\nlibrary(DescTools)\n```\n:::\n\n\n\nThen, previously saved dataset related to cholesterol and other factors is loaded for further use.\n\n\n\n::: {.cell hash='predictivefactors5_cache/pdf/load_7fd520bdc5b62c603aa8ea807d322583'}\n\n```{.r .cell-code}\nload(file=\"Data/predictivefactors/cholesterolNHANES15part2.RData\")\n```\n:::\n\n\n\n### Data spliting to avoid model overfitting\n\nYou start by setting a random seed to ensure that the random splitting of data is reproducible. A specified function is then used to partition the data, taking as arguments the outcome variable (cholesterol level in this case) and the percentage of data that you want to allocate to the training set (70% in this example).\n\n::: column-margin\n@datasplit\n:::\n\n::: column-margin\n@datasplit2\n:::\n\n::: callout-tip\nWe can use the `createDataPartition` function to split a dataset into training and testing datasets. The function will return the row indices that should go into the training set. These indices are stored in a variable, and its dimensions are displayed to provide an understanding of the size of the training set that will be created. Additionally, you can calculate what 70% of your entire dataset would look like to verify the approximation of the training data size, as well as what the remaining 30% (for the test set) would look like.\n:::\n\n\n\n::: {.cell hash='predictivefactors5_cache/pdf/split0_8450898724a2e4d85cdd32dfe51b392c'}\n\n```{.r .cell-code}\n# Using a seed to randomize in a reproducible way \nset.seed(123)\nsplit <- createDataPartition(y = analytic3$cholesterol, p = 0.7, list = FALSE)\nstr(split)\n#>  int [1:1844, 1] 3 4 5 8 9 13 14 16 20 21 ...\n#>  - attr(*, \"dimnames\")=List of 2\n#>   ..$ : NULL\n#>   ..$ : chr \"Resample1\"\ndim(split)\n#> [1] 1844    1\n\n# Approximate train data\ndim(analytic3)*.7 \n#> [1] 1842.4   24.5\n\n# Approximate test data\ndim(analytic3)*(1-.7) \n#> [1] 789.6  10.5\n```\n:::\n\n\n\n#### Split the data\n\nAfter determining how to partition the data, the next step is actually creating the training and test datasets. The indices are used to subset the original dataset into these two new datasets. The dimensions of each dataset are displayed to confirm their sizes.\n\n\n\n::: {.cell hash='predictivefactors5_cache/pdf/split1_1cb69284307ff92624cccd9a5a60c64a'}\n\n```{.r .cell-code}\n# Create train data\ntrain.data <- analytic3[split,]\ndim(train.data)\n#> [1] 1844   35\n\n# Create test data\ntest.data <- analytic3[-split,]\ndim(test.data)\n#> [1] 788  35\n```\n:::\n\n\n\nOur next task is to fit the model (e.g., linear regression) on the training set and evaluate the performance on the test set.\n\n#### Train the model\n\nOnce the training dataset is created, you can proceed to train the model using the training data. A previously defined formula containing the predictor variables is used in a linear regression model. After fitting the model, a summary is generated to display key statistics that help in evaluating the model's performance.\n\n\n\n::: {.cell hash='predictivefactors5_cache/pdf/split2_f3d315ca275b8c38c32d716c711cb9b1'}\n\n```{.r .cell-code}\nformula4\n#> cholesterol ~ gender + age + born + race + education + married + \n#>     income + diastolicBP + systolicBP + bmi + triglycerides + \n#>     uric.acid + protein + bilirubin + phosphorus + sodium + potassium + \n#>     globulin + calcium + physical.work + physical.recreational + \n#>     diabetes\nfit4.train1 <- lm(formula4, data = train.data)\nsummary(fit4.train1)\n#> \n#> Call:\n#> lm(formula = formula4, data = train.data)\n#> \n#> Residuals:\n#>     Min      1Q  Median      3Q     Max \n#> -91.973 -23.719  -1.563  20.586 178.542 \n#> \n#> Coefficients:\n#>                             Estimate Std. Error t value Pr(>|t|)    \n#> (Intercept)                72.716792  59.916086   1.214  0.22504    \n#> genderMale                -11.293629   2.136545  -5.286 1.40e-07 ***\n#> age                         0.306235   0.066376   4.614 4.23e-06 ***\n#> bornOthers                  7.220858   2.300658   3.139  0.00172 ** \n#> raceHispanic               -6.727473   2.709718  -2.483  0.01313 *  \n#> raceOther                  -4.865771   3.237066  -1.503  0.13298    \n#> raceWhite                  -1.468522   2.494981  -0.589  0.55621    \n#> educationHigh.School        1.626097   1.920289   0.847  0.39722    \n#> educationSchool            -4.853095   3.585185  -1.354  0.17602    \n#> marriedNever.married       -5.298265   2.332033  -2.272  0.02321 *  \n#> marriedPreviously.married   1.202448   2.305191   0.522  0.60199    \n#> incomeBetween.25kto54k     -1.736495   2.360385  -0.736  0.46202    \n#> incomeBetween.55kto99k      0.170505   2.565896   0.066  0.94703    \n#> incomeOver100k              1.712359   2.860226   0.599  0.54946    \n#> diastolicBP                 0.355813   0.074380   4.784 1.86e-06 ***\n#> systolicBP                  0.037464   0.059848   0.626  0.53140    \n#> bmi                        -0.282881   0.139160  -2.033  0.04222 *  \n#> triglycerides               0.123797   0.007613  16.261  < 2e-16 ***\n#> uric.acid                   1.006499   0.712871   1.412  0.15815    \n#> protein                     1.721623   3.468969   0.496  0.61975    \n#> bilirubin                  -6.143411   3.006858  -2.043  0.04118 *  \n#> phosphorus                  0.093824   1.575489   0.060  0.95252    \n#> sodium                     -0.604286   0.400694  -1.508  0.13170    \n#> potassium                  -0.583525   2.715189  -0.215  0.82986    \n#> globulin                   -0.278970   3.614404  -0.077  0.93849    \n#> calcium                    15.679677   3.054968   5.133 3.17e-07 ***\n#> physical.workYes           -1.099540   1.960321  -0.561  0.57494    \n#> physical.recreationalYes    0.834737   1.953960   0.427  0.66928    \n#> diabetesYes               -19.932101   2.580138  -7.725 1.83e-14 ***\n#> ---\n#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#> \n#> Residual standard error: 34.68 on 1815 degrees of freedom\n#> Multiple R-squared:  0.2433,\tAdjusted R-squared:  0.2316 \n#> F-statistic: 20.84 on 28 and 1815 DF,  p-value: < 2.2e-16\n```\n:::\n\n\n\n#### Extract performance measures\n\nYou can use a saved function to measure the performance of the trained model. The function will return performance metrics like R-squared, RMSE, etc. This function is applied not just to the training data but also to the test data, the full dataset, and a separate, fictitious dataset.\n\n::: callout-tip\nBelow we use the `perform` function that we saved to evaluate the model performances\n:::\n\n\n\n::: {.cell hash='predictivefactors5_cache/pdf/perf_3ae966128cd8a74f5c0da371f6912b74'}\n\n```{.r .cell-code}\nperform(new.data = train.data,y.name = \"cholesterol\", model.fit = fit4.train1)\n#>         n  p df.residual     SSE     SST    R2 adjR2  sigma   logLik      AIC\n#> [1,] 1844 29        1815 2182509 2884109 0.243 0.232 34.677 -9140.98 18341.96\n#>           BIC\n#> [1,] 18507.55\nperform(new.data = test.data,y.name = \"cholesterol\", model.fit = fit4.train1)\n#>        n  p df.residual     SSE     SST    R2 adjR2  sigma    logLik      AIC\n#> [1,] 788 29         759 1057454 1372214 0.229 0.201 37.326 -3955.936 7971.873\n#>           BIC\n#> [1,] 8111.958\nperform(new.data = analytic3,y.name = \"cholesterol\", model.fit = fit4.train1)\n#>         n  p df.residual     SSE     SST    R2 adjR2 sigma    logLik      AIC\n#> [1,] 2632 29        2603 3239962 4256586 0.239 0.231 35.28 -13098.82 26257.64\n#>           BIC\n#> [1,] 26433.91\nperform(new.data = fictitious.data,y.name = \"cholesterol\", model.fit = fit4.train1)\n#>         n  p df.residual     SSE     SST    R2 adjR2  sigma    logLik      AIC\n#> [1,] 4121 29        4092 5306559 6912485 0.232 0.227 36.011 -20601.92 41263.84\n#>           BIC\n#> [1,] 41453.55\n```\n:::\n\n\n\nEvaluating the model's performance on the test data provides insights into how well the model will generalize to new, unseen data. Comparing the performance metrics across different datasets can give you a robust view of your model's predictive power and reliability.\n\n::: column-margin\nFor more on model training and tuning, see @tuning\n:::\n\n### References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}