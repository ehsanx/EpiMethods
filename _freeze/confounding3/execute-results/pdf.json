{
  "hash": "30211458027ccb611a4c2cbd27dfb8a7",
  "result": {
    "markdown": "## Collider {.unnumbered}\n\nIn causal inference, understanding the role of colliders is crucial. A collider is a variable that is a common effect of two or more variables. Adjusting for a collider can introduce bias into your estimates. \n\n\n\n\n::: {.cell hash='confounding3_cache/pdf/setup_9aa2ee7f5dbc3d25058a1ae806f07b6f'}\n\n```{.r .cell-code}\n# Load required packages\nlibrary(simcausal)\n```\n:::\n\n\n\nIn a DAG, a collider is a variable influenced by two or more other variables. In our case, L is a collider because it is affected by both A (the treatment) and Y (the outcome). When you adjust for a collider like L, you could introduce bias into your estimates, as demonstrated in the examples below.\n\nLet us consider\n\n-   L is continuous variable\n-   A is binary treatment\n-   Y is continuous outcome\n\n### Non-null effect\n\n-   True treatment effect = 1.3\n\n#### Data generating process\n\n\n\n::: {.cell hash='confounding3_cache/pdf/dgm3_c477ad483c92054b3af710389b7bf32b'}\n\n```{.r .cell-code}\nD <- DAG.empty()\nD <- D + \n  node(\"A\", distr = \"rbern\", prob = plogis(-10)) +\n  node(\"Y\", distr = \"rnorm\", mean = 1.3 * A, sd = .1) +\n  node(\"L\", distr = \"rnorm\", mean = 10 * Y + 1.3 * A, sd = 1)\nDset <- set.DAG(D)\n```\n:::\n\n\n\n#### Generate DAG\n\n\n\n::: {.cell hash='confounding3_cache/pdf/dag3_799b04dc3fcffef5cfcdf42f3f822e66'}\n\n```{.r .cell-code}\nplotDAG(Dset, xjitter = 0.1, yjitter = .9,\n        edge_attrs = list(width = 0.5, arrow.width = 0.4, arrow.size = 0.7),\n        vertex_attrs = list(size = 12, label.cex = 0.8))\n```\n\n::: {.cell-output-display}\n![](confounding3_files/figure-pdf/dag3-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n#### Generate data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(simcausal)\nObs.Data <- sim(DAG = Dset, n = 1000000, rndseed = 123)\nhead(Obs.Data)\n#>   ID A           Y          L\n#> 1  1 0  0.02620001  1.7153509\n#> 2  2 0 -0.15209594 -2.9689005\n#> 3  3 0  0.02366280  0.6548666\n#> 4  4 0  0.06603038 -0.2591076\n#> 5  5 0 -0.02140063  0.5220096\n#> 6  6 0  0.01928270 -0.6426011\n```\n:::\n\n\n\n#### Estimate effect\n\n\n\n::: {.cell hash='confounding3_cache/pdf/est3_8b868c5bfbcd93fe486044a3ad4862eb'}\n\n```{.r .cell-code}\n# Not adjusted for L\nfit0 <- glm(Y ~ A, family=\"gaussian\", data=Obs.Data)\nround(coef(fit0),2)\n#> (Intercept)           A \n#>        0.00        1.29\n\n# Adjusted for L\nfit <- glm(Y ~ A + L, family=\"gaussian\", data=Obs.Data)\nround(coef(fit),2)\n#> (Intercept)           A           L \n#>        0.00        0.58        0.05\n```\n:::\n\n\n\n::: callout-important\nWhen not adjusting for L, we recover the true effect close to 1.3. Adjusting for L introduces bias, making the estimate unreliable.\n::: \n\n\n### Null effect\n\n-   True treatment effect = 0\n\n#### Data generating process\n\n\n\n::: {.cell hash='confounding3_cache/pdf/dgm4_4c221709977897839b907f15aa78f5ea'}\n\n```{.r .cell-code}\nD <- DAG.empty()\nD <- D + \n  node(\"A\", distr = \"rbern\", prob = plogis(-10)) +\n  node(\"Y\", distr = \"rnorm\", mean = 0, sd = .1) +\n  node(\"L\", distr = \"rnorm\", mean = 10 * Y + 1.3 * A, sd = 1)\nDset <- set.DAG(D)\n```\n:::\n\n\n\n#### Generate DAG\n\n\n\n::: {.cell hash='confounding3_cache/pdf/dag4_7acea97fe64a196244df7ab066055a9e'}\n\n```{.r .cell-code}\nplotDAG(Dset, xjitter = 0.1, yjitter = .9,\n        edge_attrs = list(width = 0.5, arrow.width = 0.4, arrow.size = 0.7),\n        vertex_attrs = list(size = 12, label.cex = 0.8))\n```\n\n::: {.cell-output-display}\n![](confounding3_files/figure-pdf/dag4-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n#### Generate data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrequire(simcausal)\nObs.Data <- sim(DAG = Dset, n = 1000000, rndseed = 123)\nhead(Obs.Data)\n#>   ID A           Y          L\n#> 1  1 0  0.02620001  1.7153509\n#> 2  2 0 -0.15209594 -2.9689005\n#> 3  3 0  0.02366280  0.6548666\n#> 4  4 0  0.06603038 -0.2591076\n#> 5  5 0 -0.02140063  0.5220096\n#> 6  6 0  0.01928270 -0.6426011\n```\n:::\n\n\n\n#### Estimate effect\n\n\n\n::: {.cell hash='confounding3_cache/pdf/est4_1aad00edd7904dd911fb78f8e6898de2'}\n\n```{.r .cell-code}\n# Not adjusted for L\nfit0 <- glm(Y ~ A, family=\"gaussian\", data=Obs.Data)\nround(coef(fit0),2)\n#> (Intercept)           A \n#>        0.00       -0.01\n\n# Adjusted for L\nfit <- glm(Y ~ A + L, family=\"gaussian\", data=Obs.Data)\nround(coef(fit),2)\n#> (Intercept)           A           L \n#>        0.00       -0.07        0.05\n```\n:::\n\n\n\n::: callout-important\nWhen the true effect is null, not adjusting for L shows an estimate close to zero. Adjusting for L moves the estimate away from the null value, introducing bias.\n::: \n\n\nEven 1,000,000 observations were not enough to recover true treatment effect! But we are close enough.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}