{
  "hash": "257fd444dd6d54d0bc2619608d1511e8",
  "result": {
    "markdown": "## Exercise 1 Solution (L)  {.unnumbered}\n\n\n\n\n\nWe will revisit the article by [Flegal et al. (2016)](https://jamanetwork.com/journals/jama/article-abstract/2526639). We will use the same dataset as in the previous lab exercise on [survey data analysis](https://ehsanx.github.io/EpiMethods/surveydataE.html), with some additional predictors in predicting obesity.\n\nOur primary aim is to predict **grade 3 obesity** with the following predictors:\n\n-   Age: Age in years at screening\n-   Gender\n-   Race: Race/ethnicity\n-   Education: Education level\n-   Smoking: Smoking status\n-   Physical activity: Level of vigorous work activity\n-   Sleep: Hours of sleep\n-   High blood pressure: Ever doctor told a high blood pressure\n-   General health: General health condition\n\n## Question 1: Creating data\n\n### 1(a) Downloading the datasets\n\nYou can see how datasets are downloaded and merged:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nhanesA)\nlibrary(SASxport)\nlibrary(plyr)\n\n# Demographic data\ndemo <- nhanes('DEMO_H') # Both males and females: 0 - 150 YEARS\ndemo1 <- demo[c(\"SEQN\", # Respondent sequence number\n                \"RIDAGEYR\", # Age in years at screening\n                \"RIAGENDR\", # gender\n                \"DMDEDUC2\", # Education level - Adults 20+\n                \"RIDRETH3\", # Race/Hispanic origin w/ NH Asian\n                \"RIDEXPRG\", # Pregnancy status at exam\n                \"WTINT2YR\", #  Full sample 2 year weights\n                \"SDMVPSU\", # Masked variance pseudo-PSU\n                \"SDMVSTRA\")] # Masked variance pseudo-stratum\ndemo_vars <- names(demo1)\ndemo2 <- nhanesTranslate('DEMO_H', demo_vars, data = demo1)\n\n# BMI\nbmx <- nhanes('BMX_H')\nbmx1 <- bmx[c(\"SEQN\", # Respondent sequence number\n              \"BMXBMI\")] # Body Mass Index (kg/m**2): 2 YEARS - 150 YEARS\nbmx_vars <- names(bmx1)\nbmx2 <- nhanesTranslate('BMX_H', bmx_vars, data = bmx1)\n\n# Smoking\nsmq <- nhanes('SMQ_H')\nsmq1 <- smq[c(\"SEQN\", # Respondent sequence number\n              \"SMQ020\", # Smoked at least 100 cigarettes in life\n              \"SMQ040\")] # Do you now smoke cigarettes?: 18 YEARS - 150 YEARS\nsmq_vars <- names(smq1)\nsmq2 <- nhanesTranslate('SMQ_H', smq_vars, data = smq1)\n\n# Physical activity\npaq <- nhanes('PAQ_H')\npaq1 <- paq[c(\"SEQN\", # Respondent sequence number\n              \"PAQ605\")] # Vigorous work activity\npaq_vars <- names(paq1)\npaq2 <- nhanesTranslate('PAQ_H', paq_vars, data = paq1)\n\n# Sleep\nslq <- nhanes('SLQ_H')\nslq1 <- slq[c(\"SEQN\", # Respondent sequence number\n              \"SLD010H\")] # Hours of sleep\nslq_vars <- names(slq1)\nslq2 <- nhanesTranslate('SLQ_H', slq_vars, data = slq1)\n\n# High blood pressure\nbpq <- nhanes('BPQ_H')\nbpq1 <- bpq[c(\"SEQN\", # Respondent sequence number\n              \"BPQ020\")] # Ever told you had high blood pressure\nbpq_vars <- names(bpq1)\nbpq2 <- nhanesTranslate('BPQ_H', bpq_vars, data = bpq1)\n\n# General health condition\nhuq <- nhanes('HUQ_H')\nhuq1 <- huq[c(\"SEQN\", # Respondent sequence number\n              \"HUQ010\")] # General health condition\nhuq_vars <- names(huq1)\nhuq2 <- nhanesTranslate('HUQ_H', huq_vars, data = huq1)\n\n# Combined data\ndat.full <- join_all(list(demo2, bmx2, smq2, paq2, slq2, bpq2, huq2), by = \"SEQN\",\n                     type='full') \ndim(dat.full) # N = 10,175\n```\n:::\n\n\n### 1(b) Recoding\n\nLet us recode the outcome and predictors to make them suitable for analysis:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Survey design\ndat.full$survey.weight <- dat.full$WTINT2YR\ndat.full$psu <- dat.full$SDMVPSU\ndat.full$strata <- dat.full$SDMVSTRA\n\n# Class 3 obesity - BMI >= 40 kg/m^2\nsummary(dat.full$BMXBMI)\ndat.full$obesity <- ifelse(dat.full$BMXBMI >= 40, 1, 0)\ntable(dat.full$obesity, useNA = \"always\")\n\n# Age\ndat.full$age.cat <- cut(dat.full$RIDAGEYR, c(20, 40, 60, Inf), right = FALSE)\ntable(dat.full$age.cat, useNA = \"always\")\n\n# Gender\ndat.full$gender <- dat.full$RIAGENDR\ntable(dat.full$gender, useNA = \"always\")\n\n# Race/Hispanic origin group\ndat.full$race <- dat.full$RIDRETH3\ntable(dat.full$age.cat, dat.full$race, useNA = \"always\")\ndat.full$race <- car::recode(dat.full$race, \n                             \" 'Non-Hispanic White'='White'; \n                             'Non-Hispanic Black' = 'Black'; \n                             c('Mexican American','Other Hispanic')='Hispanic'; \n                             c('Non-Hispanic Asian', \n                             'Other Race - Including Multi-Rac')= 'Other';\n                             else=NA\", \n                             levels = c(\"White\", \"Black\", \"Hispanic\", \"Other\"))\ntable(dat.full$race, useNA = \"always\")\n\n# Education\ndat.full$education <- dat.full$DMDEDUC2\ndat.full$education <- car::recode(dat.full$education, \n                                  \" c('Some college or AA degree', \n                                  'College graduate or above') = '>High school'; \n                                  'High school graduate/GED or equi' = 'High school';\n                                  c('Less than 9th grade',\n                                  '9-11th grade (Includes 12th grad') = \n                                  '<High school'; \n                                  else = NA\", \n                                  levels = c(\"<High school\", \"High school\", \n                                                    \">High school\"))\ntable(dat.full$education, useNA = \"always\")\n\n# Smoking status\ndat.full$smoking <- dat.full$SMQ020\ntable(dat.full$smoking, useNA = \"always\")\ndat.full$smoking <- car::recode(dat.full$smoking, \" 'Yes'='Current smoker'; \n                                'No'='Never smoker'; else=NA  \",\n                                levels = c(\"Never smoker\", \"Former smoker\", \n                                           \"Current smoker\"))\ndat.full$smoking[dat.full$SMQ040 == \"Not at all\"] <- \"Former smoker\"\ntable(dat.full$smoking, useNA = \"always\")\n\n# Physical activity\ndat.full$physical.activity <- dat.full$PAQ605\ntable(dat.full$physical.activity, useNA = \"always\")\ndat.full$physical.activity <- car::recode(dat.full$physical.activity, \n                                          \" 'Yes'='Yes'; 'No'='No'; else=NA \", \n                                          levels = c(\"No\", \"Yes\"))\ntable(dat.full$physical.activity, useNA = \"always\")\n\n# Sleep\ndat.full$sleep <- dat.full$SLD010H\ndat.full$sleep <- car::recode(dat.full$sleep, \" 1:6 = 'Less than 7'; 7:9 = '7-9'; \n                              10:24 = 'More than 9';  else=NA \",\n                              levels = c(\"Less than 7\", \"7-9\", \"More than 9\"))\ntable(dat.full$sleep, useNA = \"always\")\n\n# High blood pressure\ndat.full$high.blood.pressure <- dat.full$BPQ020\ntable(dat.full$high.blood.pressure, useNA = \"always\")\ndat.full$high.blood.pressure <- car::recode(dat.full$high.blood.pressure, \n                                            \" 'Yes'='Yes'; 'No'='No'; else=NA \",\n                                            levels = c(\"No\", \"Yes\"))\ntable(dat.full$high.blood.pressure, useNA = \"always\")\n\n# General health condition\ndat.full$general.health <- dat.full$HUQ010\ntable(dat.full$general.health, useNA = \"always\")\ndat.full$general.health <- car::recode(dat.full$general.health, \n                                       \"c('Excellent,', 'Very good,')=\n                                       'Very good or Excellent'; \n                                       'Good,'='Good';\n                                       c('Fair, or', 'Poor?') ='Poor or Fair'; \n                                       else=NA  \",\n                                       levels = c(\"Poor or Fair\", \"Good\", \n                                                  \"Very good or Excellent\"))\ntable(dat.full$general.health, useNA = \"always\")\n```\n:::\n\n\n### 1(c) Keep relevant variables\n\nLet's keep only the relevant variables for this exercise:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Keep relevant variables\nvars <- c(\n  # Unique identifier\n  \"SEQN\", \n  \n  # Survey features\n  \"survey.weight\", \"psu\", \"strata\", \n  \n  # Eligibility\n  \"RIDAGEYR\", \"BMXBMI\", \"RIDEXPRG\",\n  \n  # Outcome\n  \"obesity\", \n  \n  # Predictors\n  \"age.cat\", \"gender\", \"race\", \"education\", \"smoking\", \"physical.activity\", \n  \"sleep\", \"high.blood.pressure\", \"general.health\")\n\ndat.full2 <- dat.full[,vars]\n```\n:::\n\n\n### 1(d) Weight normalization\n\nLarge weights can cause issues when evaluating model performance. Let's normalize the survey weights to address this problem:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.full2$wgt <- dat.full2$survey.weight * nrow(dat.full2)/sum(dat.full2$survey.weight)\nsummary(dat.full2$wgt)\n```\n:::\n\n\n### 1(e) Analytic dataset\n\nThe authors restricted their study to - adults aged 20 years and more, - non-missing body mass index, and - non-pregnant\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Aged 20 years or more\ndat.analytic <- subset(dat.full2, RIDAGEYR>=20) # N = 5,769\n\n# Non-missing outcome\ndat.analytic <- subset(dat.analytic, !is.na(BMXBMI)) # N = 5,520\n\n# Non-pregnant\ntable(dat.analytic$RIDEXPRG)\ndat.analytic <- subset(dat.analytic, is.na(RIDEXPRG) | RIDEXPRG != \n                         \"Yes, positive lab pregnancy test\") # N = 5,455\nnrow(dat.analytic)\n\n# Drop irrelevant variables\ndat.analytic$RIDAGEYR <- dat.analytic$BMXBMI <- dat.analytic$RIDEXPRG <- NULL\n```\n:::\n\n\n### 1(f) Complete case data\n\nBelow is the code for creating the complete case dataset (no missing for the outcome or predictors):\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Drop missing values\ndat.complete <- dat.analytic[complete.cases(dat.analytic),] # N = 5,433\n```\n:::\n\n\n### 1(g) Save daatsets\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsave(dat.full, dat.full2, dat.analytic, dat.complete, file = \"Data/machinelearning/Flegal2016_v2.RData\")\n```\n:::\n\n\n## Question 2: Importing data and creating Table 1\n\n### 2(a) Importing dataset\n\nLet's load the dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nload(\"Data/machinelearning/Flegal2016_v2.RData\")\nls()\n#> [1] \"dat.analytic\" \"dat.complete\" \"dat.full\"     \"dat.full2\"\n```\n:::\n\n\nHere,\n\n-   dat.full: the full dataset with all variables\n-   dat.full2: the full dataset with only relevant variables for this exercise\n-   dat.analytic: the analytic dataset with only adults aged 20 years and more, non-missing BMI, and non-pregnant\n-   dat.complete: the complete case dataset without missing values in the outcome and predictors\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(dat.full2)\n#>  [1] \"SEQN\"                \"survey.weight\"       \"psu\"                \n#>  [4] \"strata\"              \"RIDAGEYR\"            \"BMXBMI\"             \n#>  [7] \"RIDEXPRG\"            \"obesity\"             \"age.cat\"            \n#> [10] \"gender\"              \"race\"                \"education\"          \n#> [13] \"smoking\"             \"physical.activity\"   \"sleep\"              \n#> [16] \"high.blood.pressure\" \"general.health\"      \"wgt\"\n```\n:::\n\n\n### 2(b) Creating Table 1\n\nLet's create Table 1 for the complete case dataset with unweighted frequencies:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tableone)\npredictors <- c(\"age.cat\", \"gender\", \"race\", \"education\", \"smoking\", \n                \"physical.activity\", \"sleep\", \"high.blood.pressure\", \n                \"general.health\")\ntab1 <- CreateTableOne(vars = predictors, strata = \"obesity\", \n                       data = dat.complete, test = F, addOverall = T)\nprint(tab1, format=\"f\") # Showing only frequencies \n#>                            Stratified by obesity\n#>                             Overall 0    1  \n#>   n                         5433    5023 410\n#>   age.cat                                   \n#>      [20,40)                1806    1659 147\n#>      [40,60)                1892    1728 164\n#>      [60,Inf)               1735    1636  99\n#>   gender = Female           2807    2531 276\n#>   race                                      \n#>      White                  2333    2157 176\n#>      Black                  1109     976 133\n#>      Hispanic               1208    1125  83\n#>      Other                   783     765  18\n#>   education                                 \n#>      <High school           1171    1092  79\n#>      High school            1216    1116 100\n#>      >High school           3046    2815 231\n#>   smoking                                   \n#>      Never smoker           3054    2828 226\n#>      Former smoker          1261    1159 102\n#>      Current smoker         1118    1036  82\n#>   physical.activity = Yes    984     917  67\n#>   sleep                                     \n#>      7-9                    3174    2971 203\n#>      Less than 7            2084    1896 188\n#>      More than 9             175     156  19\n#>   high.blood.pressure = Yes 2037    1810 227\n#>   general.health                            \n#>      Poor or Fair           1260    1084 176\n#>      Good                   2065    1911 154\n#>      Very good or Excellent 2108    2028  80\n```\n:::\n\n\n## Question 3: Prediction using split sample approach\n\nIn this exercise, we will use the split-sample approach to predict obesity. We will create our training and test data using a 60-40 split for the training and test data. We will use the following two methods to predict obesity:\n\n-   Design-adjusted logistic with all survey features (psu, strata, and survey weights)\n-   LASSO with survey weights\n\n### 3(a) Split the data into training and test\n\nLet us create our training and test data using the split-sample approach:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(900)\ndat.complete$datasplit <- rbinom(nrow(dat.complete), size = 1, prob = 0.6) \ntable(dat.complete$datasplit)\n#> \n#>    0    1 \n#> 2130 3303\n\n# Training data\ndat.train <- dat.complete[dat.complete$datasplit == 1,]\ndim(dat.train)\n#> [1] 3303   16\n\n# Test data\ndat.test <- dat.complete[dat.complete$datasplit == 0,]\ndim(dat.test)\n#> [1] 2130   16\n```\n:::\n\n\n### 3(b) Prediction with design-adjusted logistic \n\nWe will use the design-adjusted logistic regression to predict obesity with the following predictors:\n\n-   age.cat, gender, race, education, smoking, physical.activity, sleep, high.blood.pressure, general.health\n\nInstructions:\n\n-   1: Create the survey design on the full data and subset the design for those individuals in the training data.\n-   2: Use the **training data design** created in step 1 to fit the model\n-   3: Use the test data to predict the probability of obesity.\n-   4: Calculate AUC on the test data.\n-   5: Calculate calibration slope with 95% confidence interval on the test data.\n\nHints:\n\n-   `WeightedAUC` and `WeightedROC` are helpful functions in calculating AUC.\n-   The `Logit` function from the `DescTools` package is helpful in calculating the logit of predicted probabilities for calculating calibration slope.\n-   Use the **normalized weight** variable to calculate the AUC and calibration slope.\n\n#### Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survey)\nlibrary(DescTools)\nlibrary(WeightedROC)\nlibrary(Publish)\n\n# Design\ndat.full2$miss <- 1\ndat.full2$miss[dat.full2$SEQN %in% dat.train$SEQN] <- 0\nsvy.design0 <- svydesign(strata = ~strata, id = ~psu, weights = ~survey.weight,\n                         data = dat.full2, nest = TRUE)\nsvy.design <- subset(svy.design0, miss == 0)\n\n# Formula\nFormula <- formula(paste(\"obesity ~ \", paste(predictors, collapse=\" + \")))\n\n# Model\nfit.glm <- svyglm(Formula, design = svy.design, family = binomial)\n\n# Prediction on the test set\ndat.test$pred.glm <- predict(fit.glm, newdata = dat.test, type = \"response\")\n\n# AUC on the test set with sampling weights\nauc.glm <- WeightedAUC(WeightedROC(dat.test$pred.glm, dat.test$obesity, \n                                   weight = dat.test$wgt))\nauc.glm\n#> [1] 0.6813118\n\n# Weighted calibration slope\ndat.test$pred.glm.logit <- DescTools::Logit(dat.test$pred.glm)\nslope.glm <- glm(obesity ~ pred.glm.logit, data = dat.test, family = quasibinomial,\n                 weights = wgt)\npublish(slope.glm)\n#>        Variable Units Coefficient       CI.95 p-value \n#>  pred.glm.logit              0.74 [0.56;0.92] < 1e-04\n```\n:::\n\n\n#### Interpretation \\[optional\\]\n\nInterpret the AUC and calibration slope based on the following criteria:\n\n| AUC       | Interpretation                     |\n|-----------|------------------------------------|\n| 0.50      | No better than a random chance     |\n| 0.51-0.70 | Poor discrimination ability        |\n| 0.71-0.80 | Acceptable discrimination ability  |\n| 0.81-0.90 | Excellent discrimination ability   |\n| 0.90-1.00 | Outstanding discrimination ability |\n\n| Calibration slope            | Interpretation   |\n|------------------------------|------------------|\n| 1 and 95% CI includes 1      | Well-calibration |\n| Significantly less than 1    | Overfitting      |\n| Significantly greater than 1 | Underfitting     |\n\n### 3(c) Prediction with LASSO \n\nNow we will use the LASSO method to predict obesity. We will incorporate sampling weights in the model to account for survey data (no psu or strata). Note that we are not interested in the statistical significance of the beta coefficients. Hence, not utilizing psu and strata should not be an issue in this prediction problem.\n\nInstructions:\n\n-   1: Use the training data with normalized weight to fit the model.\n-   2: Find the optimum lambda using 5-fold cross-validation. Consider the lambda value that gives the minimum prediction error.\n-   3: Predict the probability of obesity on the test set\n-   3: Calculate AUC on the test data.\n-   4: Calculate calibration slope with 95% confidence interval on the test data.\n\n#### Model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(glmnet)\nlibrary(DescTools)\nlibrary(WeightedROC)\n\n# Training data - X: predictor, y: outcome\nX.train <- model.matrix(Formula, dat.train)[,-1] \ny.train <- as.matrix(dat.train$obesity) \n\n# Test data - X: predictor, y: outcome\nX.test <- model.matrix(Formula, dat.test)[,-1] \ny.test <- as.matrix(dat.test$obesity)\n\n# Find the best lambda using 5-fold CV\nfit.cv.lasso <- cv.glmnet(x = X.train, y = y.train, nfolds = 5, alpha = 1, \n                          family = \"binomial\", weights = dat.train$wgt)\n\n# Prediction on the test set\ndat.test$pred.lasso <- predict(fit.cv.lasso, newx = X.test, type = \"response\", \n                               s = fit.cv.lasso$lambda.min)\n\n# AUC on the test set with sampling weights\nauc.lasso <- WeightedAUC(WeightedROC(dat.test$pred.lasso, dat.test$obesity, \n                                     weight = dat.test$wgt))\nauc.lasso\n#> [1] 0.6875668\n\n# Weighted calibration slope\ndat.test$pred.lasso.logit <- DescTools::Logit(dat.test$pred.lasso)\nslope.lasso <- glm(obesity ~ pred.lasso.logit, data = dat.test, \n                   family = quasibinomial, weights = wgt)\npublish(slope.lasso)\n#>          Variable Units Coefficient       CI.95 p-value \n#>  pred.lasso.logit              0.88 [0.67;1.08] < 1e-04\n```\n:::\n\n\n#### Interpretation \\[optional\\]\n\nInterpret the AUC and calibration slope based on the following criteria:\n\n| AUC       | Interpretation                     |\n|-----------|------------------------------------|\n| 0.50      | No better than a random chance     |\n| 0.51-0.70 | Poor discrimination ability        |\n| 0.71-0.80 | Acceptable discrimination ability  |\n| 0.81-0.90 | Excellent discrimination ability   |\n| 0.90-1.00 | Outstanding discrimination ability |\n\n| Calibration slope            | Interpretation   |\n|------------------------------|------------------|\n| 1 and 95% CI includes 1      | Well-calibration |\n| Significantly less than 1    | Overfitting      |\n| Significantly greater than 1 | Underfitting     |\n\n## Question 4: Prediction using croos-validation approach \\[optional\\]\n\nUse LASSO with 5-fold cross-validation to predict obesity with the same set of predictors used in Question 2. Report the average AUC and average calibration slope with 95% confidence interval over 5 folds.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(glmnet)\nlibrary(DescTools)\nlibrary(WeightedROC)\n\nk <- 5\nset.seed(604)\nnfolds <- sample(1:k, size = nrow(dat.complete), replace = T)\ntable(nfolds)\n#> nfolds\n#>    1    2    3    4    5 \n#> 1090 1074 1130 1083 1056\n\nauc.lasso <- cal.slope.lasso <- cal.slope.se.lasso <- NULL\nfor (fold in 1:k) {\n  # Training data\n  dat.train <- dat.complete[nfolds != fold, ]\n  X.train <- model.matrix(Formula, dat.train)[,-1]\n  y.train <- as.matrix(dat.train$obesity)\n  \n  # Test data\n  dat.test <- dat.complete[nfolds == fold, ]\n  X.test <- model.matrix(Formula, dat.test)[,-1]\n  y.test <- as.matrix(dat.test$obesity)\n  \n  # Find the optimum lambda using 5-fold CV\n  fit.cv.lasso <- cv.glmnet(x = X.train, y = y.train, nfolds = 5, alpha = 1, \n                            family = \"binomial\", weights = dat.train$wgt)\n\n  # Prediction on the test set\n  dat.test$pred.lasso <- predict(fit.cv.lasso, newx = X.test, type = \"response\", \n                                 s = fit.cv.lasso$lambda.min)\n  \n  # AUC on the test set with sampling weights\n  auc.lasso[fold] <- WeightedAUC(WeightedROC(dat.test$pred.lasso,dat.test$obesity, \n                                             weight = dat.test$wgt))\n  \n  # Weighted calibration slope\n  dat.test$pred.lasso.logit <- DescTools::Logit(dat.test$pred.lasso)\n  mod.cal <- glm(obesity ~ pred.lasso.logit, data = dat.test, family = binomial, \n                 weights = wgt)\n  cal.slope.lasso[fold] <- summary(mod.cal)$coef[2,1]\n  cal.slope.se.lasso[fold] <- summary(mod.cal)$coef[2,2]\n}\n\n# Average AUC\nmean(auc.lasso)\n#> [1] 0.7055226\n\n# Average calibration slope\nmean(cal.slope.lasso)\n#> [1] 0.9994\n\n# 95% CI for calibration slope\ncbind(mean(cal.slope.lasso) - 1.96 * mean(cal.slope.se.lasso), \n      mean(cal.slope.lasso) + 1.96 * mean(cal.slope.se.lasso))\n#>           [,1]     [,2]\n#> [1,] 0.7299176 1.268882\n```\n:::\n",
    "supporting": [
      "machinelearningEsolution_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}