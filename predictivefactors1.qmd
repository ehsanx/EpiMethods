## Collinear predictors {.unnumbered}

In this tutorial, we'll continue with the data analysis. We'll focus on an analysis of an NHANES data. This data contains over 1200 observations and 33 variables. These variables come in various types: numeric, categorical, and binary. Our primary goal is to fit a linear regression model to predict cholesterol levels.


```{r setup, warning=FALSE, cache=TRUE, message=FALSE}
# Load required packages
library(rms)
library(Hmisc)
```

### Load data

Let us load the dataset and see structure of the variables:

```{r load, warning=FALSE, cache=TRUE}
load(file = "Data/predictivefactors/cholesterolNHANES15.RData")
#head(analytic)
str(analytic)
```

### Describe the data

```{r data, warning=FALSE, cache=TRUE}
require(rms)
describe(analytic) 
```

### Collinearity

Avoiding collinear variables can result in a more interpretable, stable, and efficient predictive model. Collinearity refers to a situation in which two or more predictor variables in a multiple regression model are highly correlated, meaning that one can be linearly predicted from the others with substantial accuracy. Collinearity poses several issues for predictive analysis:

**Reduced Interpretability**:
When predictor variables are highly correlated, it becomes challenging to isolate the impact of individual predictors on the response variable. In other words, it is difficult to determine which predictor is genuinely influential in explaining variance in the response variable. This reduces the interpretability of the model.

**Unstable Coefficients**:
Collinearity can lead to inflated standard errors of the regression coefficients. This means that the coefficients can be very sensitive to small changes in the data, making the model unstable and less generalizable to new, unseen data.

**Overfitting**:
When predictors are collinear, the model is more likely to fit to the noise in the data rather than the actual signal. This is a manifestation of overfitting, where the model becomes too complex and captures random noise. Overfit models will perform poorly on new, unseen data.

**Inefficiency**:
Including redundant variables (collinear variables) does not add additional information to the model. This could be inefficient, especially when dealing with large datasets, as it increases computational costs without improving model performance.

#### Multicollinearity Diagnostics
Several techniques are available for diagnosing multicollinearity, including:

- Variance Inflation Factor (VIF)
- Eigenvalues and Eigenvectors of the correlation/covariance matrix
- Pairwise correlation matrices

#### Remedies

Some common ways to handle collinearity include:

- Removing one of the correlated predictors
- Combining correlated predictors into a single composite predictor
- Using regularization techniques like Ridge Regression, which can help handle collinearity by adding a penalty term

### Identify collinear predictors

::: callout-tip
We can also use `hclust` and `varclus` or variable clustering, i.e., to identify collinear predictors
:::

::: column-margin
`hclust` is the hierarchical clustering function where default is squared Spearman correlation coefficients to detect monotonic but nonlinear relationships.
:::

```{r collinear, warning=FALSE, cache=TRUE}
require(Hmisc)
sel.names <- c("gender", "age", "born", "race", "education", "married", 
               "income", "diastolicBP", "systolicBP", 
               "bodyweight", "bodyheight", "bmi", "waist", "smoke", "alcohol", 
               "cholesterol", "triglycerides", "uric.acid", 
               "protein", "bilirubin", "phosphorus", "sodium", "potassium", 
               "globulin", "calcium", "physical.work", "physical.recreational", 
               "diabetes")
var.cluster <- varclus(~., data = analytic[sel.names])
# var.cluster
plot(var.cluster)
```

### Video content (optional)

::: callout-tip
For those who prefer a video walkthrough, feel free to watch the video below, which offers a description of an earlier version of the above content.
:::

::: {style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;"}
<iframe src="https://www.youtube.com/embed/5nNZpsuQ_Fg" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen>

</iframe>
:::
