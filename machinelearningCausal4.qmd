## Continuous Outcomes  {.unnumbered}

```{r, echo=FALSE, warning=FALSE, message=FALSE}
require(tableone)
require(Publish)
require(randomForest)
require(tmle)
require(xgboost)
require(kableExtra)
load(file = "Data/machinelearningCausal/cl2.RData")
```

We will now go through an example of using TMLE for a continuous outcome. The setup for SuperLearner in this case is similar to that for binary outcomes, so rather than going through the SuperLearner steps again, we will instead focus on the additional steps that are necessary for running the `tmle` method on continuous outcomes.

::: callout-note
Only outcome variable (Length of stay); slightly different than Table 2 in @connors1996effectiveness (means were 20.5 vs. 25.7; and medians were 16 vs. 17).
:::

```{r tab1, cache=TRUE, echo = TRUE}
tab1 <- CreateTableOne(vars = c("Length.of.Stay"),
                       data = ObsData, 
                       strata = "RHC.use", 
                       test = FALSE)
print(tab1, showAllLevels = FALSE, )
```


```{r tab1x, cache=TRUE, echo = TRUE}
median(ObsData$Length.of.Stay[ObsData$RHC.use==0])
median(ObsData$Length.of.Stay[ObsData$RHC.use==1])
```

### Constructing SuperLearner {-}

Just as we did for a binary outcome, we will need to specify two SuperLearners, one for the exposure and one for the outcome model.

The effective sample size for a continuous outcome is just $n_{eff}=n=5735$. We calculated the effective sample size for the exposure model earlier, which also turned out to be $n_{eff}=n=5735$. So once again we will use *10 folds* because $500 \leq n_{eff} \leq 5000$ [@phillips2023ConsiderationsSL].

Similarly to our example with the binary outcome, the key considerations for the library of learners are:

-   We have some continuous covariates, and should therefore include learners that allow non-linear/monotonic relationships.

-   We have a large $n$, so should include as many learners as is computationally feasible.

-   We have 49 covariates and 5735 observations, so we do not have high-dimensional data and including screeners is optional.

Again the requirements for the exposure and outcome models are the same and we can use the same library for both models. Note that even though one model will have a binary dependent variable, and one will have a continuous dependent variable, most of the available learners automatically adapt to binary and continuous dependent variables.

For this example, we will use the same SuperLearner library as for the binary outcome example.

```{r, cache=TRUE}
# Construct the SuperLearner library
SL.library <- c("SL.mean", 
                "SL.glm", 
                "SL.glmnet", 
                "SL.xgboost", 
                "SL.randomForest", 
                "tmle.SL.dbarts2", 
                "SL.svm")
```

### Dealing with continuous outcomes {-}

For this example, we will be examining the length of stay in hospital outcome.

The key difference between running TMLE on a continuous outcome in comparison to running it with a binary outcome, is that we must **transform** the outcome to fall within the range of 0 to 1, so that the modeled outcomes fall within the range of the outcome's true distribution [@gruber2010targeted].

To transform the outcome, we can use min-max normalization:

$$
Y_{transformed} = \frac{Y-Y_{min}}{Y_{max}-Y_{min}}
$$

```{r tmlepkgdefault, message=FALSE, warning=FALSE}
set.seed(1444) 
# transform the outcome to fall within the range [0,1]
min.Y <- min(ObsData$Length.of.Stay)
max.Y <- max(ObsData$Length.of.Stay)
ObsData$Length.of.Stay_transf <- 
  (ObsData$Length.of.Stay-min.Y)/
  (max.Y-min.Y)
```

Once we have transformed the outcome to fall within the range of 0 to 1, we can run TMLE as before, using the `tmle` method in the `tmle` package:

```{r tmlepkg33default, message=FALSE, warning=FALSE, eval=FALSE}
# create data frame containing only covariates
ObsData.noYA <- dplyr::select(ObsData, 
                              !c(Length.of.Stay_transf, 
                                 Length.of.Stay, 
                                 RHC.use))
```


```{r tmlepkg33defaultb, message=FALSE, warning=FALSE, eval=FALSE}
# run tmle
tmle.fit.cont <- tmle::tmle(Y = ObsData$Length.of.Stay_transf, 
                       A = ObsData$RHC.use, 
                       W = ObsData.noYA, 
                       family = "gaussian", 
                       V = 10,
                       Q.SL.library = SL.library,
                       g.SL.library = SL.library)
```


```{r tmlepkg33defaultx, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}
saveRDS(tmle.fit.cont, 
        file="Data/machinelearningCausal/tmlefitcont.RDS")
```

Once the `tmle` method has run, we still have one step to complete to get our final estimate. At this point, we must transform the average treatment effect generated by the `tmle` method ($\widehat{ATE}$) back to the outcome's original scale:

$$
\widehat{ATE}_{rescaled} = (Y_{max}-Y_{min})*\widehat{ATE}
$$

```{r tmlepkg33defaultx2, message=FALSE, warning=FALSE, echo=FALSE}
tmle.fit.cont <- readRDS(file="Data/machinelearningCausal/tmlefitcont.RDS")
```


```{r tmlepkg33defaultx3, message=FALSE, warning=FALSE}
# transform back the ATE estimate
tmle.est.cont <- (max.Y-min.Y)*
  tmle.fit.cont$estimates$ATE$psi
tmle.est.cont
```


```{r tmlepkg33defaultx3b, message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}
saveRDS(tmle.est.cont, file = "Data/machinelearningCausal/tmlecontinuous.RDS")
```

We also have to transform the confidence interval back to the original scale:

```{r tmlepkg2default, results='hide', message=FALSE, warning=FALSE, eval=FALSE}
tmle.ci.cont <- (max.Y-min.Y)*
  tmle.fit.cont$estimates$ATE$CI
```


```{r tmlepkg2defaultx, results='hide', message=FALSE, warning=FALSE, echo=FALSE, eval=FALSE}
saveRDS(tmle.ci.cont, file = "Data/machinelearningCausal/tmlecontinuousci.RDS")
```

```{r, echo=FALSE}
tmle.est.cont <- readRDS(file = "Data/machinelearningCausal/tmlecontinuous.RDS")
tmle.ci.cont <- readRDS(file = "Data/machinelearningCausal/tmlecontinuousci.RDS")
```

ATE for continuous outcome: `r tmle.est.cont`, and 95 % CI is `r tmle.ci.cont`.

The results indicate that if all participants had received RHC, the average length of stay in hospital would be 2.95 (1.99, 3.91) days longer than if no participants had received RHC.

### Understanding defaults {-}

Transform outcome:

```{r tmlepkgdefault1, message=FALSE, warning=FALSE, eval=FALSE}
set.seed(1444) 
# transform the outcome to fall within the range [0,1]
min.Y <- min(ObsData$Length.of.Stay)
max.Y <- max(ObsData$Length.of.Stay)
ObsData$Length.of.Stay_transf <- 
  (ObsData$Length.of.Stay-min.Y)/
  (max.Y-min.Y)
```

Run TMLE, using the `tmle` package's default SuperLearner library:

```{r tmlepkg33default1, message=FALSE, warning=FALSE, eval=FALSE}
# create data frame containing only covariates
ObsData.noYA <- dplyr::select(ObsData, 
                              !c(Length.of.Stay_transf, 
                                 Length.of.Stay, 
                                 RHC.use))
```


```{r tmlepkg33default1bb, message=FALSE, warning=FALSE, eval=FALSE}
# run tmle
tmle.fit.cont.def <- tmle::tmle(
  Y = ObsData$Length.of.Stay_transf, 
  A = ObsData$RHC.use, 
  W = ObsData.noYA,
  family = "gaussian",
  V = 10)
# Q.SL.library = SL.library.test,  
## removed this line
# g.SL.library = SL.library.test)  
## removed this line
```


```{r tmlepkg33default1bbc, message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}
saveRDS(tmle.fit.cont.def, file = "Data/machinelearningCausal/tmlefitcontdef.RDS")
```

Transform the average treatment effect generated by the `tmle` method ($\widehat{ATE}$) back to the outcome's original scale:

$$
\widehat{ATE}_{rescaled} = (Y_{max}-Y_{min})*\widehat{ATE}
$$

```{r, cache=TRUE, echo=FALSE}
tmle.fit.cont.def <- readRDS(file = "Data/machinelearningCausal/tmlefitcontdef.RDS")
```


```{r, cache=TRUE}
# transform back the ATE estimate
tmle.est.cont.def <- (max.Y-min.Y)*
  tmle.fit.cont.def$estimates$ATE$psi
tmle.est.cont.def
```


```{r, echo=FALSE, eval=FALSE}
saveRDS(tmle.est.cont.def, file = "Data/machinelearningCausal/tmlecontinuousdef.RDS")
```

Transform the confidence interval back to the original scale:

```{r tmlepkg2default1, results='hide', message=FALSE, warning=FALSE, eval=FALSE}
tmle.ci.cont.def <- (max.Y-min.Y)*
  tmle.fit.cont.def$estimates$ATE$CI
```


```{r tmlepkg2default1x, results='hide', message=FALSE, warning=FALSE, eval=FALSE, echo=FALSE}
saveRDS(tmle.ci.cont.def, file = "Data/machinelearningCausal/tmlecontinuouscidef.RDS")
```

```{r, echo=FALSE}
tmle.est.cont.def <- readRDS(file = "Data/machinelearningCausal/tmlecontinuousdef.RDS")
tmle.ci.cont.def <- readRDS(file = "Data/machinelearningCausal/tmlecontinuouscidef.RDS")
```


ATE for continuous outcome using default library: `r tmle.est.cont.def`, and 95% CI `r tmle.ci.cont.def`.

The estimate using the default SuperLearner library (2.18) is similar to the estimate we got when using our user-specified SuperLearner library (2.95). However, the confidence interval using the default SuperLearner library (1.25, 4.37) was much wider than that using our user-specified SuperLearner library (1.99, 3.91).

### Comparison of results {-}

Adjusted regression:

```{r reg1cont, cache=TRUE, results='hide', echo=FALSE}
# adjust the exposure variable (primary interest)
fit0.cont <- lm(Length.of.Stay~RHC.use, data = ObsData)
require(Publish)
crude.fit.cont <- publish(fit0.cont, 
                          digits=1)$regressionTable[2,]
```

```{r reg2cont, cache=TRUE, results='hide'}
# adjust the exposure variable 
# (primary interest) + covariates
baselineVars.LoS <- c(baselinevars, "Death")
out.formula.cont <- as.formula(
  paste("Length.of.Stay~ RHC.use +", 
        paste(baselineVars.LoS,
              collapse = "+")))
fit1.cont <- lm(out.formula.cont, data = ObsData)
publish(fit1.cont, digits=1)$regressionTable[2,]
```

```{r, cache=TRUE, echo=FALSE, cache=TRUE}
saveRDS(fit1.cont, file = "Data/machinelearningCausal/adjregcont.RDS")
```

@connors1996effectiveness conducted a propensity score matching analysis. Table 5 showed that, after propensity score pair (1-to-1) matching, means of length of stay ($Y$), when stratified by RHC ($A$) were not significantly different ($p = 0.14$).

```{r summarytable0cont, echo=TRUE, results='hold', warning=FALSE, message=FALSE, echo=FALSE, cache=TRUE}
fit.reg.cont <- readRDS(file = "Data/machinelearningCausal/adjregcont.RDS")
TEr <- fit.reg.cont$coefficients[2]
CIr <- as.numeric(confint(fit.reg.cont, 'RHC.use'))
tmlecont <- readRDS(file = "Data/machinelearningCausal/tmlecontinuous.RDS")
tmlecontci <- readRDS(file = "Data/machinelearningCausal/tmlecontinuousci.RDS")
tmlesl <- readRDS(file = "Data/machinelearningCausal/tmlecontinuousdef.RDS")
tmlecisl <- readRDS(file = "Data/machinelearningCausal/tmlecontinuouscidef.RDS")
ci.b <- rep(NA,2)
ks <- 2.01
ci.ks <- c(0.6,3.41)
point <- as.numeric(c(TEr, tmlecont, tmlesl, ks))
CIs <- cbind(CIr, tmlecontci, tmlecisl, ci.ks)    
```

```{r summarytablecont, cache=TRUE, echo=FALSE}
method.list <- c("Adjusted Regression", 
                 "TMLE (user-specified SL library)",
                 "TMLE (default SL library)",
                 "Keele and Small (2021) paper") 
results <- data.frame(method.list) 
results$Estimate <- round(point,2)
results$`2.5 %` <- CIs[1,] 
results$`97.5 %` <- CIs[2,]

require(kableExtra)
kab <- kable(results,digits = 2)
row_spec(kab, 1:4)
```

### References {-}
